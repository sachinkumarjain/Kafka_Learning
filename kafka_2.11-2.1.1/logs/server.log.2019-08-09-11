[2019-08-08 11:00:14,602] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-08 11:00:14,609] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-08 11:00:14,609] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-08 11:00:14,609] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-08-08 11:00:14,609] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-08-08 11:00:14,629] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-08-08 11:00:14,630] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-08-08 11:00:14,641] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,641] INFO Server environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,642] INFO Server environment:java.version=1.8.0_211 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,642] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,642] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,642] INFO Server environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,643] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,644] INFO Server environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,644] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,645] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,645] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,646] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,647] INFO Server environment:user.name=Sachin_Kumar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,653] INFO Server environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,655] INFO Server environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,664] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,664] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,673] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:14,701] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-08-08 11:00:14,706] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:00:39,633] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:00:40,019] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:00:40,020] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:00:40,036] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:00:40,045] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,045] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,045] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,045] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,045] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,045] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,047] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,048] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,049] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,049] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,050] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,051] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,051] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,052] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,052] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,055] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:00:40,081] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:00:40,082] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:00:40,087] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53369 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:00:40,087] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:00:40,101] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53369 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:40,118] INFO Creating new log file: log.97 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-08-08 11:00:40,146] INFO Established session 0x10005432d980000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:53369 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:00:40,148] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:00:40,152] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:00:40,219] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x1 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,231] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x2 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,234] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x3 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,236] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x4 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,238] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x5 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,240] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x6 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,244] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x7 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,247] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x8 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,253] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0x9 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,255] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0xa zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,258] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0xb zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,265] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0xc zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,268] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:create cxid:0xd zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:40,413] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:00:40,469] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:00:40,480] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:00:40,509] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:00:40,510] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:00:40,513] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:00:40,556] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:00:40,620] WARN [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-1-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-1-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565180185902}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 11:00:40,621] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,698] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-08 11:00:40,705] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:40,707] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,763] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-08 11:00:40,812] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,817] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:00:40,832] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 244 ms (kafka.log.Log)
[2019-08-08 11:00:40,853] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:40,853] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,915] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,921] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-08-08 11:00:40,935] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:40,935] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,987] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:40,993] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-08 11:00:41,006] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,006] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,053] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,058] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:41,072] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,072] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,121] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,127] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-08 11:00:41,140] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,140] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,189] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,194] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 11:00:41,207] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,207] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,255] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,260] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-08 11:00:41,273] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,273] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,322] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,327] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 11:00:41,339] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,340] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,386] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,392] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:41,405] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,405] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,452] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,457] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:41,470] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,470] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,517] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,522] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:41,539] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,539] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,586] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,591] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 11:00:41,603] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,603] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,649] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,654] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-08 11:00:41,666] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,666] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,717] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,722] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-08 11:00:41,734] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,734] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,777] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,783] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-08-08 11:00:41,802] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,803] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,848] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,853] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-08 11:00:41,866] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,866] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,921] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,926] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-08-08 11:00:41,938] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,938] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,983] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:41,987] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 11:00:41,998] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:41,998] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,049] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,053] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 11:00:42,064] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,064] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,114] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,118] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-08 11:00:42,130] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,130] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,184] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,188] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-08 11:00:42,201] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,201] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,244] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,248] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-08-08 11:00:42,258] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,260] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,304] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,310] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-08-08 11:00:42,321] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,322] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,367] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,372] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-08-08 11:00:42,384] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,385] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,434] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,438] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-08 11:00:42,449] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,450] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,501] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,505] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-08-08 11:00:42,517] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,517] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,562] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,567] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-08 11:00:42,582] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,582] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,622] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 11:00:42,639] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,642] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:00:42,647] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 73 ms (kafka.log.Log)
[2019-08-08 11:00:42,658] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,658] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,701] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,705] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 11:00:42,717] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,718] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,761] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,765] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-08-08 11:00:42,783] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,783] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,833] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,838] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 11:00:42,850] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,850] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,900] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,904] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 11:00:42,916] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,916] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,971] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:42,976] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-08 11:00:42,987] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:42,987] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,034] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,039] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:43,052] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,053] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,107] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,113] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-08-08 11:00:43,126] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,126] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,176] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,181] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 11:00:43,193] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,194] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,237] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,241] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-08-08 11:00:43,250] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,251] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,295] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,301] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 11:00:43,316] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,317] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,373] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,378] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-08-08 11:00:43,391] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,391] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,441] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,446] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-08 11:00:43,457] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,458] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,506] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,511] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-08 11:00:43,521] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,523] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,569] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,574] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:43,585] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,586] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,636] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,642] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 11:00:43,656] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,656] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,711] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,717] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-08-08 11:00:43,737] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,737] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,790] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,794] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-08 11:00:43,804] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,805] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,852] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,856] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-08 11:00:43,868] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,868] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,916] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,920] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 11:00:43,931] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,932] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,984] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:43,988] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 11:00:43,998] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:43,999] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,057] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,063] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-08-08 11:00:44,079] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:44,079] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,140] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,145] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-08-08 11:00:44,158] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 11:00:44,159] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,225] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:00:44,229] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-08-08 11:00:44,233] INFO Logs loading complete in 3676 ms. (kafka.log.LogManager)
[2019-08-08 11:00:44,256] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:00:44,258] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:00:44,500] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 11:00:44,536] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:00:44,569] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,572] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,572] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,588] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:00:44,666] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:00:44,674] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:00:44,678] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:00:44,752] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,757] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,765] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:00:44,792] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:00:44,794] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:00:44,798] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:44,817] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:00:44,851] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:00:44,854] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:00:44,854] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:00:44,905] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:00:44,939] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:00:44,945] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:00:44,952] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:00:44,957] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 11:00:44,981] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:multi cxid:0x65 zxid:0xa8 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:45,005] INFO Got user-level KeeperException when processing sessionid:0x10005432d980000 type:multi cxid:0x67 zxid:0xa9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:00:45,043] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:00:45,059] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-08-08 11:00:45,065] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,069] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,100] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,100] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,124] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-08-08 11:00:45,124] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,127] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,147] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,148] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,177] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-08-08 11:00:45,177] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,178] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,199] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,199] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,224] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-08-08 11:00:45,225] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,226] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,244] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-08-08 11:00:45,244] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,260] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,277] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-08-08 11:00:45,277] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,278] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,303] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-08-08 11:00:45,303] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,305] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,321] INFO [Partition topic-1-0 broker=0] No checkpointed highwatermark is found for partition topic-1-0 (kafka.cluster.Partition)
[2019-08-08 11:00:45,321] INFO Replica loaded for partition topic-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,323] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 0 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,335] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,336] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,353] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-08-08 11:00:45,353] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,355] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,368] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-08-08 11:00:45,368] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,375] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,393] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-08-08 11:00:45,393] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,394] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,419] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-08-08 11:00:45,419] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,421] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,434] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-08-08 11:00:45,434] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,441] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,460] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-08-08 11:00:45,460] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,461] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,487] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-08-08 11:00:45,487] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,488] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,503] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-08-08 11:00:45,504] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,509] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,526] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-08-08 11:00:45,545] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,546] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,577] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-08-08 11:00:45,578] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,580] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,607] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-08-08 11:00:45,607] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,610] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,625] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-08-08 11:00:45,626] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,628] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,657] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-08-08 11:00:45,657] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,659] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,674] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-08-08 11:00:45,674] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,677] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,706] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,706] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,728] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-08-08 11:00:45,728] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,746] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,767] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-08-08 11:00:45,767] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,772] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,795] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,796] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,813] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-08-08 11:00:45,813] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,822] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,852] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-08-08 11:00:45,855] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,861] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,893] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,893] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,906] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-08-08 11:00:45,906] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,907] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,930] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-08-08 11:00:45,930] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,938] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,955] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-08-08 11:00:45,955] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,956] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,983] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-08-08 11:00:45,983] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,984] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:45,995] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-08-08 11:00:45,996] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:45,996] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,017] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-08-08 11:00:46,018] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,022] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,035] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-08-08 11:00:46,035] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,039] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,057] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-08-08 11:00:46,057] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,058] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,082] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-08-08 11:00:46,082] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,089] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,104] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-08-08 11:00:46,105] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,105] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,130] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-08-08 11:00:46,130] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,139] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,157] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-08-08 11:00:46,157] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,158] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,185] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-08-08 11:00:46,185] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,186] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,200] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-08-08 11:00:46,200] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,205] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,222] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-08-08 11:00:46,222] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,223] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,248] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 11:00:46,249] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,252] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-08-08 11:00:46,252] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,253] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,273] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-08-08 11:00:46,273] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:00:46,274] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:00:46,304] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,306] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,312] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,320] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,323] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,327] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,337] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,342] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,356] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,364] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,368] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,377] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,380] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,394] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,406] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,411] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,422] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,425] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,436] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,438] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,439] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,447] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,451] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,460] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,464] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,472] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,476] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,477] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,489] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,492] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,503] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,506] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,519] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,530] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,541] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,545] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,545] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,557] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,560] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,561] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,574] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,585] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,588] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,597] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,602] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,602] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,639] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,642] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,656] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,668] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,671] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,681] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,686] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,708] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,713] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,725] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,732] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-36462 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:00:46,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,744] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 49 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,744] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,774] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,786] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,801] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,811] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,850] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,851] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,858] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,873] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,875] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,876] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:00:46,886] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:01:32,451] INFO Accepted socket connection from /127.0.0.1:53404 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:01:32,454] INFO Client attempting to establish new session at /127.0.0.1:53404 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:01:32,457] INFO Established session 0x10005432d980001 with negotiated timeout 30000 for client /127.0.0.1:53404 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:01:32,675] INFO Got user-level KeeperException when processing sessionid:0x10005432d980001 type:setData cxid:0x4 zxid:0xab txntype:-1 reqpath:n/a Error Path:/config/topics/topic-2 Error:KeeperErrorCode = NoNode for /config/topics/topic-2 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:01:32,723] INFO Processed session termination for sessionid: 0x10005432d980001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:01:32,726] INFO Closed socket connection for client /127.0.0.1:53404 which had sessionid 0x10005432d980001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:01:32,749] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-2-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:01:32,762] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:01:32,767] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-08-08 11:01:32,768] INFO Created log for partition topic-2-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:01:32,769] INFO [Partition topic-2-0 broker=0] No checkpointed highwatermark is found for partition topic-2-0 (kafka.cluster.Partition)
[2019-08-08 11:01:32,770] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:01:32,774] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:08:56,862] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:08:57,145] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:08:57,146] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:08:57,160] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:08:57,168] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,169] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,169] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,169] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,169] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,169] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,170] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,171] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,172] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,172] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,177] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,178] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,180] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,181] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,181] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,183] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:08:57,205] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:08:57,206] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:08:57,221] INFO Accepted socket connection from /127.0.0.1:53640 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:08:57,221] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:08:57,225] INFO Client attempting to establish new session at /127.0.0.1:53640 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:08:57,244] INFO Established session 0x10005432d980002 with negotiated timeout 6000 for client /127.0.0.1:53640 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:08:57,245] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:08:57,249] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:08:57,301] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x1 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,311] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x2 zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,313] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x3 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,315] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x4 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,317] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x5 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,319] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x6 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,326] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x7 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,335] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x8 zxid:0xba txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,338] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0x9 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,347] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0xa zxid:0xbc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,350] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0xb zxid:0xbd txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,358] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0xc zxid:0xbe txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,368] INFO Got user-level KeeperException when processing sessionid:0x10005432d980002 type:create cxid:0xd zxid:0xbf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:08:57,504] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:08:57,507] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:08:57,546] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:08:57,554] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:08:57,579] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:08:57,582] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:08:57,582] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:08:57,608] INFO Log directory C:\tmp\kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-08-08 11:08:57,626] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:08:57,635] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-08-08 11:08:57,649] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:08:57,651] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:08:57,910] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-08-08 11:08:57,946] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:08:57,964] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:57,964] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:57,965] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:57,982] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:08:58,030] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:08:58,037] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:08:58,039] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:08:58,044] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:08:58,107] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:58,111] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:58,119] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:08:58,128] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:08:58,130] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:08:58,136] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:08:58,150] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:08:58,176] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:08:58,179] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:08:58,179] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:08:58,215] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:08:58,233] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:08:58,235] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:08:58,237] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:08:58,239] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-08-08 11:10:13,720] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53692 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:10:13,723] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53692 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:10:13,734] INFO Established session 0x10005432d980003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53692 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:10:13,941] INFO Got user-level KeeperException when processing sessionid:0x10005432d980003 type:setData cxid:0x5 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/config/topics/topic-3 Error:KeeperErrorCode = NoNode for /config/topics/topic-3 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:10:13,994] INFO Processed session termination for sessionid: 0x10005432d980003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:10:13,996] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53692 which had sessionid 0x10005432d980003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:10:14,008] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:14,019] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:14,023] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:10:14,027] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 11:10:14,040] INFO Created log for partition topic-3-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:10:14,053] INFO [Partition topic-3-1 broker=0] No checkpointed highwatermark is found for partition topic-3-1 (kafka.cluster.Partition)
[2019-08-08 11:10:14,056] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,058] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,065] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:10:14,086] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,087] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:10:14,098] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:10:14,101] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-08 11:10:14,104] INFO Created log for partition topic-3-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:10:14,103] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-08-08 11:10:14,112] INFO Created log for partition topic-3-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:10:14,112] INFO [Partition topic-3-0 broker=1] No checkpointed highwatermark is found for partition topic-3-0 (kafka.cluster.Partition)
[2019-08-08 11:10:14,122] INFO [Partition topic-3-0 broker=0] No checkpointed highwatermark is found for partition topic-3-0 (kafka.cluster.Partition)
[2019-08-08 11:10:14,134] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,133] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,135] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,144] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:10:14,142] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:14,175] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:10:14,193] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,181] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-3-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:14,206] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:10:14,220] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:10:14,226] INFO Created log for partition topic-3-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:10:14,237] INFO [Partition topic-3-1 broker=1] No checkpointed highwatermark is found for partition topic-3-1 (kafka.cluster.Partition)
[2019-08-08 11:10:14,241] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:10:14,243] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:14,279] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:10:14,285] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-3-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:10:15,196] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-3-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:10:15,199] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:10:15,293] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-3-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:10:15,295] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:10:44,796] INFO [GroupMetadataManager brokerId=0] Group console-consumer-36462 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:10:44,821] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:11:20,525] INFO Accepted socket connection from /127.0.0.1:53718 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:11:20,528] INFO Client attempting to establish new session at /127.0.0.1:53718 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:11:20,540] INFO Established session 0x10005432d980004 with negotiated timeout 30000 for client /127.0.0.1:53718 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:11:20,580] INFO Processed session termination for sessionid: 0x10005432d980004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:11:20,583] INFO Closed socket connection for client /127.0.0.1:53718 which had sessionid 0x10005432d980004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:11:35,369] INFO Accepted socket connection from /127.0.0.1:53728 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:11:35,372] INFO Client attempting to establish new session at /127.0.0.1:53728 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:11:35,383] INFO Established session 0x10005432d980005 with negotiated timeout 30000 for client /127.0.0.1:53728 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:11:35,945] INFO Processed session termination for sessionid: 0x10005432d980005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:11:35,948] INFO Closed socket connection for client /127.0.0.1:53728 which had sessionid 0x10005432d980005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:14:21,940] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-25012 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member consumer-1-14eff17a-e153-4c01-b1d1-eb3170d3d1b7) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:14:21,957] INFO [GroupCoordinator 0]: Stabilized group console-consumer-25012 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:14:21,968] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-25012 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:15:36,459] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-08-08 11:15:36,460] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 11:15:36,493] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,493] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,493] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:15:36,504] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,517] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:15:36,511] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,518] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-08 11:15:36,523] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,525] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,524] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,552] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:15:36,583] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,570] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:15:36,601] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:15:36,575] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:15:36,575] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:15:36,602] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,637] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 11:15:36,643] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=902462201, epoch=640) to node 0: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 11:15:36,655] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,655] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 11:15:36,655] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:15:36,661] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 11:15:36,674] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:36,674] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:15:36,685] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 11:15:36,689] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 11:15:36,696] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,762] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,762] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,783] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:15:36,785] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:15:36,797] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 11:15:36,809] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:15:36,812] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:15:36,812] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:15:36,825] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:15:36,828] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:15:36,838] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,963] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,963] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:36,973] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,043] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,043] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,046] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:15:37,056] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 11:15:37,058] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:15:37,059] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:15:37,059] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:15:37,074] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:37,096] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:15:37,097] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:15:37,102] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:15:37,102] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,116] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,116] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,125] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,256] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,256] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,258] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,401] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,401] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:15:37,424] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 11:15:37,425] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 11:15:37,449] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 11:15:37,503] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 11:15:37,565] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 11:15:37,569] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:15:37,571] INFO Processed session termination for sessionid: 0x10005432d980002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:15:37,573] INFO Session: 0x10005432d980002 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:15:37,574] INFO Closed socket connection for client /127.0.0.1:53640 which had sessionid 0x10005432d980002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:15:37,573] INFO EventThread shut down for session: 0x10005432d980002 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:15:37,578] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:15:37,624] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:37,883] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:37,883] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:37,886] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,893] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,893] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,895] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,916] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,916] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:15:38,919] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 11:15:38,935] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 11:15:38,939] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-08-08 11:16:04,456] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-08 11:16:04,457] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 11:16:04,474] INFO [KafkaServer id=0] Remaining partitions to move: topic-3-1,topic-3-0 (kafka.server.KafkaServer)
[2019-08-08 11:16:04,474] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 11:16:09,476] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 11:16:09,482] INFO [KafkaServer id=0] Remaining partitions to move: topic-3-1,topic-3-0 (kafka.server.KafkaServer)
[2019-08-08 11:16:09,482] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 11:16:14,489] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 11:16:14,496] INFO [KafkaServer id=0] Remaining partitions to move: topic-3-1,topic-3-0 (kafka.server.KafkaServer)
[2019-08-08 11:16:14,496] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 11:16:19,502] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 11:16:19,505] WARN [KafkaServer id=0] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2019-08-08 11:16:19,507] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:16:19,515] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:16:19,515] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:16:19,529] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 11:16:19,547] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 11:16:19,548] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 11:16:19,551] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 11:16:19,564] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 11:16:19,565] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,727] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,727] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,730] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:16:19,740] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:16:19,742] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 11:16:19,742] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:16:19,753] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:16:19,753] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:16:19,766] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:16:19,778] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:16:19,781] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,947] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,947] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:19,959] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,077] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,077] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,080] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:16:20,090] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 11:16:20,091] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:16:20,092] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:16:20,092] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:16:20,107] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:16:20,118] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:16:20,129] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:16:20,131] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 11:16:20,132] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,260] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,260] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,263] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,411] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,411] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,414] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,595] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,595] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:20,617] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 11:16:20,617] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 11:16:20,746] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 11:16:20,931] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 11:16:21,443] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 11:16:22,207] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 11:16:22,345] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 11:16:22,353] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:16:22,354] INFO Processed session termination for sessionid: 0x10005432d980000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:22,356] INFO Session: 0x10005432d980000 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:22,357] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53369 which had sessionid 0x10005432d980000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:16:22,358] INFO EventThread shut down for session: 0x10005432d980000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:16:22,360] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:16:22,402] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,240] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,240] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,242] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,277] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,277] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,280] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,312] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,312] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:23,314] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 11:16:23,335] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 11:16:23,339] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-08-08 11:16:39,774] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:16:40,063] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:16:40,064] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:16:40,081] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:16:40,091] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,091] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,103] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,106] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,116] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,120] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,130] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,135] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,136] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,140] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,140] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,141] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,142] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,143] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,143] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,145] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:16:40,172] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:16:40,174] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:16:40,192] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:54023 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:16:40,193] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:16:40,198] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:54023 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:16:40,220] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980006, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:16:40,218] INFO Established session 0x10005432d980006 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:54023 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:16:40,223] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:16:40,282] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x1 zxid:0xd5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,292] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x2 zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,297] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x3 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,300] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x4 zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,303] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x5 zxid:0xd9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,310] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x6 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,315] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x7 zxid:0xdb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,322] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x8 zxid:0xdc txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,325] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0x9 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,328] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0xa zxid:0xde txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,335] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0xb zxid:0xdf txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,344] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0xc zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,346] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:create cxid:0xd zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:40,485] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:16:40,530] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:16:40,538] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:16:40,561] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:40,565] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:40,565] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:16:40,598] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:16:40,696] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 11:16:40,712] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:16:40,724] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 108 ms (kafka.log.Log)
[2019-08-08 11:16:40,771] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 11:16:40,776] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-1\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:16:40,778] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 33 ms (kafka.log.Log)
[2019-08-08 11:16:40,790] INFO Logs loading complete in 192 ms. (kafka.log.LogManager)
[2019-08-08 11:16:40,801] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:16:40,803] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:16:41,039] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-08-08 11:16:41,075] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:16:41,094] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,097] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,098] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,111] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:16:41,152] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:16:41,165] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:16:41,166] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:16:41,200] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,213] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,213] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:16:41,230] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:16:41,231] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:16:41,233] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:16:41,245] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:16:41,275] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:16:41,279] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:16:41,279] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:16:41,324] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:16:41,344] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:16:41,348] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:16:41,349] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:16:41,351] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-08-08 11:16:41,398] INFO Replica loaded for partition topic-3-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 11:16:41,402] INFO Replica loaded for partition topic-3-1 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 11:16:41,411] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:16:41,463] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:multi cxid:0xdc zxid:0xe5 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:16:41,474] INFO Got user-level KeeperException when processing sessionid:0x10005432d980006 type:multi cxid:0xde zxid:0xe6 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,184] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:17:30,507] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:17:30,508] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:17:30,528] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:17:30,538] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,538] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,550] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,553] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,565] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,567] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,568] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,580] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,585] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,588] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,589] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,590] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,591] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,592] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,592] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,594] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:17:30,624] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:17:30,624] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:17:30,636] INFO Accepted socket connection from /127.0.0.1:54095 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:17:30,636] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:17:30,666] INFO Client attempting to establish new session at /127.0.0.1:54095 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:17:30,669] INFO Established session 0x10005432d980007 with negotiated timeout 6000 for client /127.0.0.1:54095 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:17:30,670] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:17:30,682] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:17:30,749] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x1 zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,761] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x2 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,763] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x3 zxid:0xea txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,765] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x4 zxid:0xeb txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,768] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x5 zxid:0xec txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,770] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x6 zxid:0xed txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,775] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x7 zxid:0xee txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,780] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x8 zxid:0xef txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,782] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0x9 zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,785] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0xa zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,787] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0xb zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,793] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0xc zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,796] INFO Got user-level KeeperException when processing sessionid:0x10005432d980007 type:create cxid:0xd zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:17:30,935] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:17:30,978] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:17:30,987] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:17:31,011] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:17:31,025] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:17:31,026] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:17:31,053] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:17:31,166] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,180] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:17:31,205] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 124 ms (kafka.log.Log)
[2019-08-08 11:17:31,238] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,244] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-08-08 11:17:31,283] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,288] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:17:31,289] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 40 ms (kafka.log.Log)
[2019-08-08 11:17:31,340] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,345] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:17:31,347] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 46 ms (kafka.log.Log)
[2019-08-08 11:17:31,378] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,380] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 11:17:31,405] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,407] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:31,453] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,455] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:17:31,476] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,477] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 11:17:31,503] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,505] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:31,558] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,560] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:17:31,583] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,584] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:31,606] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,607] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:31,635] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,637] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:31,659] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,660] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 11:17:31,687] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,688] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:17:31,729] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,730] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:31,780] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,782] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:17:31,807] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,808] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:17:31,845] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,852] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:17:31,853] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 37 ms (kafka.log.Log)
[2019-08-08 11:17:31,885] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,887] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:17:31,920] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,922] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 11:17:31,962] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:31,965] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 11:17:32,008] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,010] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-08-08 11:17:32,034] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,037] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 11:17:32,078] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,079] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:17:32,104] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,106] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:17:32,150] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,152] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:17:32,177] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,180] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 11:17:32,207] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,210] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 11:17:32,253] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,255] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 11:17:32,295] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,299] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 11:17:32,300] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-08-08 11:17:32,326] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,327] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 11:17:32,354] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,356] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:32,391] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,392] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 11:17:32,414] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,415] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 11:17:32,435] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,436] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:32,465] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,467] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 11:17:32,483] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,484] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 11:17:32,501] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,503] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 11:17:32,523] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,524] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:32,551] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,553] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:32,574] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,575] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:32,611] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,613] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:17:32,635] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,637] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:32,682] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,683] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:17:32,718] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,720] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-08-08 11:17:32,753] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,755] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 11:17:32,776] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,778] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:32,815] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,817] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:17:32,841] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,843] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 11:17:32,887] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,890] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:17:32,916] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,918] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 11:17:32,944] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,947] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 11:17:32,988] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:17:32,991] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:17:32,996] INFO Logs loading complete in 1942 ms. (kafka.log.LogManager)
[2019-08-08 11:17:33,011] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:17:33,015] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:17:33,227] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 11:17:33,262] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:17:33,281] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,284] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,284] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,297] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:17:33,355] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:17:33,360] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:17:33,361] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:17:33,427] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,430] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,449] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:17:33,470] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:17:33,472] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,472] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:17:33,474] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,483] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:33,487] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:17:33,506] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:17:33,534] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:33,535] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-3-0 -> (offset=1, leaderEpoch=2), topic-3-1 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:17:33,553] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:17:33,557] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:17:33,574] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:17:33,609] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:17:33,628] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:17:33,630] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:17:33,631] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:17:33,633] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 11:17:33,666] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:33,666] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:33,735] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:17:33,757] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,763] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,793] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,794] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,817] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,817] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,859] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,862] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,882] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,882] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,900] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,901] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,918] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,919] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,949] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,958] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:33,987] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:33,988] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,009] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,009] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,030] INFO Replica loaded for partition topic-1-0 with initial high watermark 111 (kafka.cluster.Replica)
[2019-08-08 11:17:34,031] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 0 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,037] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,047] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,064] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,065] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,081] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,082] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,105] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,105] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,127] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,128] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,145] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,146] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,165] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,165] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,180] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,181] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,203] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,204] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,229] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,229] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,243] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,243] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,263] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,263] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,277] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,277] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,297] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,297] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,317] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,317] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,336] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,336] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,353] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 11:17:34,353] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,367] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,367] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,381] INFO Replica loaded for partition topic-3-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 11:17:34,383] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,383] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,398] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,398] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,422] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,423] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,446] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,446] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,461] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,462] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,478] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,478] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,489] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,489] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,508] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,508] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,527] INFO Replica loaded for partition topic-3-1 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 11:17:34,528] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,533] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,557] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,558] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,575] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,576] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,593] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,594] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,607] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,607] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,626] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,627] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,644] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,645] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,660] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,660] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,676] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,676] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,682] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:34,694] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,683] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:34,695] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,725] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,730] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,745] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,745] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,763] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,764] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,778] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 11:17:34,779] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,782] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,791] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,807] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,807] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,829] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:17:34,830] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:17:34,847] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,849] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,851] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,853] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,863] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,878] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,867] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,881] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,891] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,894] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,903] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,916] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,919] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,931] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,945] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,948] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,959] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,961] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,962] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,975] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,978] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,986] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,990] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:34,999] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,012] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,016] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,027] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,030] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,039] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,042] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,043] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,052] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,055] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,065] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,068] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,069] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,081] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,085] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,085] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,098] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,109] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,112] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,121] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,125] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,135] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,151] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,164] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,167] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,168] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,178] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,183] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,193] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,196] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,211] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,232] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,235] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,235] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,250] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,263] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,275] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,278] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,287] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,302] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,315] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,318] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,329] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,332] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,332] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,343] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,346] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,355] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,359] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,369] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,380] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,389] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-25012 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:17:35,395] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,399] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,403] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,414] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,424] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:17:35,425] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,427] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,437] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,449] WARN [LeaderEpochCache __consumer_offsets-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,465] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,469] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,470] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:17:35,474] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,484] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,506] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,506] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,524] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,524] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,542] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,543] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,560] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,560] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,574] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,574] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,587] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,587] WARN [LeaderEpochCache __consumer_offsets-42] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,609] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,610] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,624] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,624] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,656] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 1 from offset 111. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,668] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,669] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,682] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,682] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,695] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,696] WARN [LeaderEpochCache __consumer_offsets-39] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,708] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,710] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:35,710] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,711] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:17:35,724] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,733] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,767] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,770] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,795] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,795] WARN [LeaderEpochCache __consumer_offsets-33] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,808] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,808] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,826] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,827] WARN [LeaderEpochCache __consumer_offsets-11] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,845] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,846] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,860] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,861] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,875] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,875] WARN [LeaderEpochCache __consumer_offsets-27] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,890] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,890] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,910] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,910] WARN [LeaderEpochCache __consumer_offsets-24] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,925] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,926] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,945] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,945] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,957] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,970] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,970] WARN [LeaderEpochCache __consumer_offsets-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:35,983] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 11:17:35,998] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:35,998] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,011] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,013] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,026] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,028] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,042] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,042] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,054] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,055] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,076] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,076] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,090] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,091] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,110] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 11:17:36,111] WARN [LeaderEpochCache topic-3-1] New epoch entry EpochEntry(epoch=2, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,124] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,124] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,142] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,142] WARN [LeaderEpochCache __consumer_offsets-47] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,156] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,157] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,175] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,175] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,192] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,192] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,209] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,209] WARN [LeaderEpochCache __consumer_offsets-35] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,224] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,224] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,242] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,242] WARN [LeaderEpochCache __consumer_offsets-44] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,256] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,256] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,276] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,277] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,290] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,291] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,308] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,309] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,324] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,338] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,338] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,359] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,359] WARN [LeaderEpochCache topic-2-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,376] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 11:17:36,377] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 11:17:36,737] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 11:17:36,738] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 11:17:36,747] INFO [Partition topic-3-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 11:17:36,800] INFO [Partition topic-3-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 11:21:46,502] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:21:46,505] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:21:46,506] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 11:21:46,539] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:21:46,544] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-3-0 -> (offset=3, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:21:46,569] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 11:24:39,431] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:24:39,733] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:24:39,733] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:24:39,749] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:24:39,758] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,758] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,758] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,758] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,758] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,758] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,759] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,760] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,765] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,767] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,768] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,768] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,770] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,771] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,771] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,773] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:24:39,796] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:24:39,797] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:24:39,801] INFO Accepted socket connection from /127.0.0.1:54445 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:24:39,801] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:24:39,815] INFO Client attempting to establish new session at /127.0.0.1:54445 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:24:39,827] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:24:39,825] INFO Established session 0x10005432d980008 with negotiated timeout 6000 for client /127.0.0.1:54445 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:24:39,838] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:24:39,897] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x1 zxid:0x133 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,908] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x2 zxid:0x134 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,911] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x3 zxid:0x135 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,913] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x4 zxid:0x136 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,916] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x5 zxid:0x137 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,919] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x6 zxid:0x138 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,925] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x7 zxid:0x139 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,928] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x8 zxid:0x13a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,931] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0x9 zxid:0x13b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,935] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0xa zxid:0x13c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,938] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0xb zxid:0x13d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,944] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0xc zxid:0x13e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:39,948] INFO Got user-level KeeperException when processing sessionid:0x10005432d980008 type:create cxid:0xd zxid:0x13f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:24:40,086] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:24:40,089] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:24:40,133] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:24:40,145] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:24:40,167] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:24:40,172] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:24:40,172] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:24:40,197] INFO Log directory C:\tmp\kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2019-08-08 11:24:40,212] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:24:40,221] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-08-08 11:24:40,232] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:24:40,237] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:24:40,502] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-08-08 11:24:40,537] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:24:40,558] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,561] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,561] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,575] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:24:40,624] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:24:40,636] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:24:40,637] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:24:40,639] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:24:40,691] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,695] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,704] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:24:40,710] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:24:40,711] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:24:40,717] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:24:40,731] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:24:40,754] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:24:40,757] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:24:40,771] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:24:40,798] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:24:40,814] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:24:40,816] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:24:40,817] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:24:40,819] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-08-08 11:24:59,885] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 11:25:00,202] INFO starting (kafka.server.KafkaServer)
[2019-08-08 11:25:00,203] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 11:25:00,216] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:25:00,225] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,225] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,225] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,226] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,226] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,226] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,227] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,227] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,228] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,229] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,234] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,235] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,238] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,239] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,239] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,241] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 11:25:00,264] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:25:00,265] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:25:00,269] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:54477 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:25:00,270] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:25:00,283] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:54477 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:25:00,295] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980009, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 11:25:00,294] INFO Established session 0x10005432d980009 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:54477 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:25:00,307] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 11:25:00,365] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x1 zxid:0x143 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,375] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x2 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,378] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x3 zxid:0x145 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,383] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x4 zxid:0x146 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,386] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x5 zxid:0x147 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,393] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x6 zxid:0x148 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,397] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x7 zxid:0x149 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,405] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x8 zxid:0x14a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,408] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0x9 zxid:0x14b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,411] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0xa zxid:0x14c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,418] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0xb zxid:0x14d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,429] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0xc zxid:0x14e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,431] INFO Got user-level KeeperException when processing sessionid:0x10005432d980009 type:create cxid:0xd zxid:0x14f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:25:00,569] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 11:25:00,572] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:25:00,612] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:25:00,620] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 11:25:00,644] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:25:00,647] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:25:00,647] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 11:25:00,674] INFO Log directory C:\tmp\kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2019-08-08 11:25:00,690] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 11:25:00,699] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-08-08 11:25:00,720] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 11:25:00,723] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 11:25:01,004] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2019-08-08 11:25:01,042] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 11:25:01,061] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,065] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,065] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,080] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 11:25:01,128] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 11:25:01,140] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 11:25:01,142] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 11:25:01,144] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-08-08 11:25:01,195] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,199] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,208] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 11:25:01,221] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:25:01,223] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 11:25:01,233] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:25:01,250] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 11:25:01,270] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:25:01,273] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 11:25:01,292] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 11:25:01,319] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 11:25:01,339] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 11:25:01,341] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:25:01,342] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 11:25:01,344] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-08-08 11:26:32,907] INFO Accepted socket connection from /127.0.0.1:54560 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:26:32,910] INFO Client attempting to establish new session at /127.0.0.1:54560 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:26:32,921] INFO Established session 0x10005432d98000a with negotiated timeout 30000 for client /127.0.0.1:54560 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:26:33,106] INFO Processed session termination for sessionid: 0x10005432d98000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:26:33,116] INFO Closed socket connection for client /127.0.0.1:54560 which had sessionid 0x10005432d98000a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:26:41,239] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:26:58,320] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:54571 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:26:58,322] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:54571 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:26:58,333] INFO Established session 0x10005432d98000b with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:54571 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:26:58,547] INFO Got user-level KeeperException when processing sessionid:0x10005432d98000b type:setData cxid:0x7 zxid:0x155 txntype:-1 reqpath:n/a Error Path:/config/topics/topic-4 Error:KeeperErrorCode = NoNode for /config/topics/topic-4 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:26:58,591] INFO Processed session termination for sessionid: 0x10005432d98000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:26:58,593] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54571 which had sessionid 0x10005432d98000b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:26:58,634] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-10, topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:26:58,637] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-9, topic-4-1, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:26:58,667] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:26:58,672] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,672] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,676] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-3, topic-4-7, topic-4-11) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:26:58,697] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-08-08 11:26:58,693] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-08-08 11:26:58,712] INFO Created log for partition topic-4-9 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,712] INFO Created log for partition topic-4-6 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,726] INFO [Partition topic-4-6 broker=1] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-08 11:26:58,727] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,725] INFO [Partition topic-4-9 broker=0] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-08 11:26:58,733] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,733] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,741] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,741] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,741] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,743] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,749] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,751] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,745] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:58,743] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,769] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-08 11:26:58,769] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-08 11:26:58,756] INFO [Partition topic-4-9 broker=0] topic-4-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:58,772] INFO Created log for partition topic-4-3 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,786] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,784] INFO Created log for partition topic-4-0 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,788] INFO [Partition topic-4-3 broker=2] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-08 11:26:58,805] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:58,812] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 11:26:58,818] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:26:58,806] INFO [Partition topic-4-0 broker=3] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-08 11:26:58,817] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,830] INFO Created log for partition topic-4-10 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,832] INFO Created log for partition topic-4-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:58,834] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,835] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,870] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,869] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,869] INFO [Partition topic-4-10 broker=1] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-08 11:26:58,869] INFO [Partition topic-4-1 broker=0] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-08 11:26:58,896] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,902] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,902] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,896] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,931] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,929] INFO [Partition topic-4-3 broker=2] topic-4-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:58,926] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,931] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,939] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:58,971] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:58,969] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,008] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,010] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,017] INFO [Partition topic-4-1 broker=0] topic-4-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,033] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,032] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,036] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,044] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 11:26:59,073] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,074] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,051] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-08-08 11:26:59,066] INFO Created log for partition topic-4-7 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,094] INFO Created log for partition topic-4-4 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,081] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:26:59,104] INFO [Partition topic-4-7 broker=2] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-08 11:26:59,081] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:26:59,109] INFO [Partition topic-4-4 broker=3] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-08 11:26:59,126] INFO Created log for partition topic-4-5 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,127] INFO Created log for partition topic-4-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,127] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,127] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,137] INFO [Partition topic-4-5 broker=0] No checkpointed highwatermark is found for partition topic-4-5 (kafka.cluster.Partition)
[2019-08-08 11:26:59,137] INFO [Partition topic-4-2 broker=1] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-08 11:26:59,164] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,166] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,174] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,169] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,200] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,198] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,198] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,201] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,231] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,231] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,238] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,239] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,268] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,268] INFO [Partition topic-4-7 broker=2] topic-4-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,271] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,271] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,306] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,312] INFO [Partition topic-4-5 broker=0] topic-4-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,345] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,346] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,347] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,348] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,346] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,353] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 11:26:59,347] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,375] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,374] INFO Created log for partition topic-4-11 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,355] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 11:26:59,383] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 11:26:59,393] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,390] INFO [Partition topic-4-11 broker=2] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-08 11:26:59,390] INFO Created log for partition topic-4-8 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,413] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 11:26:59,410] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,394] INFO Created log for partition topic-4-9 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,418] INFO Created log for partition topic-4-6 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,418] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,420] INFO [Partition topic-4-9 broker=1] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-08 11:26:59,417] INFO [Partition topic-4-8 broker=3] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-08 11:26:59,444] INFO [Partition topic-4-6 broker=0] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-08 11:26:59,442] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,442] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,442] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,447] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,455] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,455] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,453] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,478] INFO [Partition topic-4-11 broker=2] topic-4-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,457] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,478] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,478] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,496] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,494] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,527] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,517] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,513] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,527] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,518] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,562] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,551] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,546] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 11:26:59,587] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-08-08 11:26:59,596] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,596] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,603] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,607] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 11:26:59,602] INFO Created log for partition topic-4-3 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,628] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-08-08 11:26:59,642] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,625] INFO Created log for partition topic-4-3 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,647] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 11:26:59,627] INFO [Partition topic-4-3 broker=0] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-08 11:26:59,640] INFO Created log for partition topic-4-9 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,647] INFO [Partition topic-4-3 broker=1] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-08 11:26:59,648] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,650] INFO [Partition topic-4-9 broker=2] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-08 11:26:59,649] INFO Created log for partition topic-4-9 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,665] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,659] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,666] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,670] INFO [Partition topic-4-9 broker=3] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-08 11:26:59,680] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,686] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,680] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,684] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,702] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,715] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,705] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,727] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,736] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:26:59,744] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,728] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,758] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,761] INFO Created log for partition topic-4-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,770] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 11:26:59,779] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,789] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,800] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-08-08 11:26:59,789] INFO [Partition topic-4-0 broker=0] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-08 11:26:59,792] INFO Created log for partition topic-4-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,813] INFO Created log for partition topic-4-6 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,815] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,829] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,816] INFO [Partition topic-4-0 broker=1] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-08 11:26:59,837] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,847] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 11:26:59,843] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,850] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,837] INFO [Partition topic-4-6 broker=2] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-08 11:26:59,858] INFO Created log for partition topic-4-6 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,865] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,863] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,864] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,868] INFO [Partition topic-4-6 broker=3] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-08 11:26:59,886] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,893] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,886] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,906] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,915] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,915] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,915] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,927] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 11:26:59,961] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:26:59,954] INFO Created log for partition topic-4-10 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:26:59,949] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,949] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,983] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-08-08 11:26:59,978] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:26:59,978] INFO [Partition topic-4-10 broker=0] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-08 11:26:59,996] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,010] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,021] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,004] INFO Created log for partition topic-4-7 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,024] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-08-08 11:27:00,020] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,033] INFO [Partition topic-4-7 broker=1] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-08 11:27:00,035] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 11:27:00,034] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,033] INFO Created log for partition topic-4-0 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,062] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,063] INFO Created log for partition topic-4-3 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,066] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,066] INFO [Partition topic-4-0 broker=2] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-08 11:27:00,110] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,093] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,095] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,096] INFO [Partition topic-4-3 broker=3] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-08 11:27:00,129] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:00,123] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,135] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,134] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,135] INFO Created log for partition topic-4-7 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,165] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,156] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,157] INFO [Partition topic-4-7 broker=0] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-08 11:27:00,150] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,186] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 11:27:00,197] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,182] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,182] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,215] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:00,208] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,207] INFO Created log for partition topic-4-4 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,208] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,235] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,236] INFO [Partition topic-4-4 broker=1] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-08 11:27:00,233] INFO Created log for partition topic-4-10 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,241] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,249] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,251] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,253] INFO [Partition topic-4-10 broker=2] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-08 11:27:00,286] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,272] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,275] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,306] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 11:27:00,296] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,298] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,300] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,331] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,324] INFO Created log for partition topic-4-10 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,323] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,349] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,331] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,360] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,340] INFO [Partition topic-4-10 broker=3] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-08 11:27:00,369] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:00,378] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,390] INFO Created log for partition topic-4-4 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,389] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,389] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,397] INFO [Partition topic-4-4 broker=0] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-08 11:27:00,400] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-08-08 11:27:00,430] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,413] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,416] INFO Created log for partition topic-4-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,415] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,450] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 11:27:00,445] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,442] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,446] INFO [Partition topic-4-1 broker=1] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-08 11:27:00,475] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,475] INFO Created log for partition topic-4-4 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,475] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,480] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,515] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,517] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,501] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,534] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-08-08 11:27:00,500] INFO [Partition topic-4-4 broker=2] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-08 11:27:00,532] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:00,534] INFO Created log for partition topic-4-7 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,534] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,532] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,535] INFO Created log for partition topic-4-8 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,546] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,546] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,546] INFO [Partition topic-4-7 broker=3] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-08 11:27:00,547] INFO [Partition topic-4-8 broker=0] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-08 11:27:00,571] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,565] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,570] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,588] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,588] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,591] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,591] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,634] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,639] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,634] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,622] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,639] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,642] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 11:27:00,660] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 11:27:00,654] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,657] INFO Created log for partition topic-4-8 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,673] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,685] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,686] INFO Created log for partition topic-4-1 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,694] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-08-08 11:27:00,689] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,689] INFO [Partition topic-4-8 broker=1] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-08 11:27:00,713] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,710] INFO Created log for partition topic-4-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,723] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,707] INFO [Partition topic-4-1 broker=2] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-08 11:27:00,742] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-08-08 11:27:00,732] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,738] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,733] INFO [Partition topic-4-1 broker=3] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-08 11:27:00,758] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,760] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,755] INFO Created log for partition topic-4-11 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,771] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,774] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,789] INFO [Partition topic-4-11 broker=0] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-08 11:27:00,788] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,795] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,792] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,807] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,821] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,830] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-08-08 11:27:00,835] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,824] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,855] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 11:27:00,847] INFO Created log for partition topic-4-5 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,846] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,863] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,874] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,879] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 11:27:00,871] INFO [Partition topic-4-5 broker=1] No checkpointed highwatermark is found for partition topic-4-5 (kafka.cluster.Partition)
[2019-08-08 11:27:00,870] INFO Created log for partition topic-4-8 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,884] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,895] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,884] INFO Created log for partition topic-4-5 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,896] INFO [Partition topic-4-8 broker=2] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-08 11:27:00,906] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 11:27:00,900] INFO [Partition topic-4-5 broker=3] No checkpointed highwatermark is found for partition topic-4-5 (kafka.cluster.Partition)
[2019-08-08 11:27:00,906] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,900] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,923] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,926] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,923] INFO Created log for partition topic-4-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,945] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:00,954] INFO [Partition topic-4-2 broker=0] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-08 11:27:00,960] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:00,954] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,951] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,976] INFO Created log for partition topic-4-11 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:00,975] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,985] INFO [Partition topic-4-11 broker=1] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-08 11:27:00,983] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:00,983] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,011] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,006] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-10, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,028] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:01,008] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,033] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:01,044] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-08-08 11:27:01,038] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,048] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-11 -> (offset=0, leaderEpoch=0), topic-4-3 -> (offset=0, leaderEpoch=0), topic-4-7 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,049] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-08-08 11:27:01,061] INFO Created log for partition topic-4-5 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:01,066] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,066] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,073] INFO [Partition topic-4-5 broker=2] No checkpointed highwatermark is found for partition topic-4-5 (kafka.cluster.Partition)
[2019-08-08 11:27:01,068] INFO Created log for partition topic-4-11 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:01,066] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=0, leaderEpoch=0), topic-4-2 -> (offset=0, leaderEpoch=0), topic-4-10 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,093] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,093] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-1, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,096] INFO [Partition topic-4-11 broker=3] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-08 11:27:01,122] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,124] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,093] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-4-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,135] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-11 -> (offset=0, leaderEpoch=0), topic-4-3 -> (offset=0, leaderEpoch=0), topic-4-7 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,147] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,131] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=0, leaderEpoch=0), topic-4-4 -> (offset=0, leaderEpoch=0), topic-4-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,147] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,152] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,174] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,158] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=0, leaderEpoch=0), topic-4-4 -> (offset=0, leaderEpoch=0), topic-4-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,178] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,178] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,230] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:01,184] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition topic-4-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,150] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,209] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,245] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 11:27:01,205] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition topic-4-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,181] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,255] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 11:27:01,241] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-4-11 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,239] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,267] INFO Created log for partition topic-4-2 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:01,278] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2019-08-08 11:27:01,268] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,295] INFO [Partition topic-4-2 broker=2] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-08 11:27:01,207] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-4-9 -> (offset=0, leaderEpoch=0), topic-4-1 -> (offset=0, leaderEpoch=0), topic-4-5 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,291] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,295] INFO Created log for partition topic-4-2 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 11:27:01,321] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,312] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-4-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,305] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition topic-4-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,326] INFO [Partition topic-4-2 broker=3] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-08 11:27:01,353] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,291] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition topic-4-11 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,325] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-4-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,356] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,389] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,385] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 11:27:01,269] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-4-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,356] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,395] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,389] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,387] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,420] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-9, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,422] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition topic-4-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,468] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,353] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,492] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=0, leaderEpoch=0), topic-4-2 -> (offset=0, leaderEpoch=0), topic-4-10 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,456] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,473] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-11 -> (offset=0, leaderEpoch=0), topic-4-3 -> (offset=0, leaderEpoch=0), topic-4-7 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,467] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition topic-4-11 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,453] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition topic-4-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,478] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition topic-4-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,495] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,512] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition topic-4-3 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,420] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,503] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=0, leaderEpoch=0), topic-4-4 -> (offset=0, leaderEpoch=0), topic-4-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,523] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition topic-4-7 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,513] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,509] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=0, leaderEpoch=0), topic-4-2 -> (offset=0, leaderEpoch=0), topic-4-10 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,519] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,563] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-4-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,473] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-4-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,524] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition topic-4-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,579] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,524] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-4-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,517] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,592] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-4-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,588] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-4-11 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,584] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,547] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,621] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,619] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,561] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-4-9 -> (offset=0, leaderEpoch=0), topic-4-1 -> (offset=0, leaderEpoch=0), topic-4-5 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,579] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,580] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,625] ERROR [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error for partition topic-4-8 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,558] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition topic-4-11 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,552] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-4-9 -> (offset=0, leaderEpoch=0), topic-4-1 -> (offset=0, leaderEpoch=0), topic-4-5 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 11:27:01,621] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-4-3 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,596] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,642] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-4-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,626] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-4-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,674] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-4-7 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,647] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition topic-4-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,622] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-4-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,672] ERROR [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error for partition topic-4-4 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,623] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition topic-4-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,647] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-4-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,704] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,596] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition topic-4-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,681] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-4-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,704] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,733] ERROR [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error for partition topic-4-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,674] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,733] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,733] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,753] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-4-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,711] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,756] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,784] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition topic-4-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,731] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,818] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-4-8 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,756] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,809] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,830] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-4-4 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,845] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-4-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,829] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,782] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition topic-4-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,843] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-4-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,811] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition topic-4-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,830] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-4-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,840] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition topic-4-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,870] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,885] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,866] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,900] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,886] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,910] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition topic-4-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,917] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition topic-4-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,921] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-4-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 11:27:01,922] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,926] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error for partition topic-4-11 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,929] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,929] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 11:27:01,939] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error for partition topic-4-3 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,958] ERROR [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error for partition topic-4-8 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,957] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error for partition topic-4-7 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,961] ERROR [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error for partition topic-4-4 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:01,964] ERROR [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error for partition topic-4-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:02,265] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition topic-4-6 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:02,265] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition topic-4-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:02,267] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition topic-4-10 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 11:27:33,481] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:31:45,001] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:54862 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:31:45,393] WARN Exception causing close of session 0x0: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:31:45,393] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54862 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:32:45,209] INFO Accepted socket connection from /127.0.0.1:54900 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:32:45,214] INFO Client attempting to establish new session at /127.0.0.1:54900 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:32:45,225] INFO Established session 0x10005432d98000c with negotiated timeout 30000 for client /127.0.0.1:54900 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:32:45,685] WARN Exception causing close of session 0x10005432d98000c: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:32:45,686] INFO Closed socket connection for client /127.0.0.1:54900 which had sessionid 0x10005432d98000c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:33:16,124] INFO Expiring session 0x10005432d98000c, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:33:16,124] INFO Processed session termination for sessionid: 0x10005432d98000c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:34:40,715] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:35:01,227] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:36:41,241] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:37:33,481] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:39:36,362] INFO Accepted socket connection from /127.0.0.1:55151 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 11:39:36,366] INFO Client attempting to establish new session at /127.0.0.1:55151 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:39:36,376] INFO Established session 0x10005432d98000d with negotiated timeout 30000 for client /127.0.0.1:55151 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 11:39:36,664] INFO Processed session termination for sessionid: 0x10005432d98000d (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 11:39:36,666] INFO Closed socket connection for client /127.0.0.1:55151 which had sessionid 0x10005432d98000d (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 11:44:40,717] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:45:01,228] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:46:41,242] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:47:33,483] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:54:40,717] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:55:01,227] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:56:41,241] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 11:57:33,482] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:04:40,716] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:05:01,227] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:06:41,242] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:07:33,482] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:14:40,715] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:15:01,228] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:16:41,242] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:17:33,482] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:24:40,715] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:25:01,228] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:26:41,241] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:27:33,481] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:34:40,715] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:35:01,226] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:36:41,241] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:37:33,485] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:44:40,732] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:45:01,244] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:46:41,258] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:47:33,499] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:49:50,679] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member consumer-1-f3c0c321-613d-44da-b2b4-038314009ab4) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:49:50,686] INFO [GroupCoordinator 0]: Stabilized group test-consumer-group generation 1 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:49:50,694] INFO [GroupCoordinator 0]: Assignment received from leader for group test-consumer-group for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:52:48,323] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-48720 in state PreparingRebalance with old generation 0 (__consumer_offsets-42) (reason: Adding new member consumer-1-ab24856e-5690-4dba-9cc0-dcf66980c28c) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:52:48,324] INFO [GroupCoordinator 0]: Stabilized group console-consumer-48720 generation 1 (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:52:48,329] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-48720 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:54:40,735] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:55:01,246] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:55:28,686] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-36661 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-1-73411c69-aeea-4477-8565-df104390a418) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:55:28,687] INFO [GroupCoordinator 0]: Stabilized group console-consumer-36661 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:55:28,692] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-36661 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:56:41,261] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:57:27,282] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-48720 in state PreparingRebalance with old generation 1 (__consumer_offsets-42) (reason: removing member consumer-1-ab24856e-5690-4dba-9cc0-dcf66980c28c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:27,284] INFO [GroupCoordinator 0]: Group console-consumer-48720 with generation 2 is now empty (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:33,502] INFO [GroupMetadataManager brokerId=0] Group console-consumer-48720 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:57:33,505] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 12:57:36,071] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-93916 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-1-5005ba63-be85-4469-b1a0-d5ca298a6d59) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:36,072] INFO [GroupCoordinator 0]: Stabilized group console-consumer-93916 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:36,076] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-93916 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:41,944] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-36661 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-1-73411c69-aeea-4477-8565-df104390a418 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:41,945] INFO [GroupCoordinator 0]: Group console-consumer-36661 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:49,362] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-81326 in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-1-ed4aec05-e484-46c2-8d49-ea6e50dbf1d5) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:49,363] INFO [GroupCoordinator 0]: Stabilized group console-consumer-81326 generation 1 (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 12:57:49,369] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-81326 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:10,458] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member consumer-1-f3c0c321-613d-44da-b2b4-038314009ab4 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:10,462] INFO [GroupCoordinator 0]: Group test-consumer-group with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:23,726] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 2 (__consumer_offsets-31) (reason: Adding new member consumer-1-2d5bc6ba-b225-4e8b-999d-9b3233147e7b) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:23,727] INFO [GroupCoordinator 0]: Stabilized group test-consumer-group generation 3 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:23,732] INFO [GroupCoordinator 0]: Assignment received from leader for group test-consumer-group for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:49,223] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 3 (__consumer_offsets-31) (reason: removing member consumer-1-2d5bc6ba-b225-4e8b-999d-9b3233147e7b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:02:49,223] INFO [GroupCoordinator 0]: Group test-consumer-group with generation 4 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:06,886] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 4 (__consumer_offsets-31) (reason: Adding new member consumer-1-f92237a6-459e-4e95-9e4a-1d5cf06c4f0a) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:06,887] INFO [GroupCoordinator 0]: Stabilized group test-consumer-group generation 5 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:06,891] INFO [GroupCoordinator 0]: Assignment received from leader for group test-consumer-group for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:18,295] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-93916 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-5005ba63-be85-4469-b1a0-d5ca298a6d59 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:18,296] INFO [GroupCoordinator 0]: Group console-consumer-93916 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:48,568] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 5 (__consumer_offsets-31) (reason: Adding new member consumer-1-e6627446-5683-4abe-845b-4856254cd4b7) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:48,906] INFO [GroupCoordinator 0]: Stabilized group test-consumer-group generation 6 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:03:48,909] INFO [GroupCoordinator 0]: Assignment received from leader for group test-consumer-group for generation 6 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:04:23,440] INFO [GroupCoordinator 0]: Member consumer-1-ed4aec05-e484-46c2-8d49-ea6e50dbf1d5 in group console-consumer-81326 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:04:23,440] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-81326 in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: removing member consumer-1-ed4aec05-e484-46c2-8d49-ea6e50dbf1d5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:04:23,441] INFO [GroupCoordinator 0]: Group console-consumer-81326 with generation 2 is now empty (__consumer_offsets-1) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:04:40,734] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:05:01,245] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:06:41,259] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:07:33,499] INFO [GroupMetadataManager brokerId=0] Group console-consumer-93916 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:07:33,501] INFO [GroupMetadataManager brokerId=0] Group console-consumer-36661 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:07:33,503] INFO [GroupMetadataManager brokerId=0] Group console-consumer-81326 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:07:33,504] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:09:18,252] INFO Accepted socket connection from /127.0.0.1:59349 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 13:09:18,274] INFO Client attempting to establish new session at /127.0.0.1:59349 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 13:09:18,283] INFO Established session 0x10005432d98000e with negotiated timeout 30000 for client /127.0.0.1:59349 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 13:09:18,529] INFO Processed session termination for sessionid: 0x10005432d98000e (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 13:09:18,532] INFO Closed socket connection for client /127.0.0.1:59349 which had sessionid 0x10005432d98000e (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 13:14:40,732] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:15:01,244] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:16:41,258] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:17:13,780] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-08 13:17:13,781] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 13:17:13,854] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-1, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,854] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,856] INFO [Partition topic-4-5 broker=2] topic-4-5 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:13,855] INFO [Partition topic-4-1 broker=1] topic-4-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:13,863] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-5, topic-4-9, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,866] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,884] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,872] INFO [Partition topic-4-9 broker=3] topic-4-9 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:13,889] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,895] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-11) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,903] INFO [Partition topic-3-1 broker=1] topic-3-1 starts at Leader Epoch 3 from offset 7. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 13:17:13,900] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-11) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,911] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-1, topic-4-9) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,915] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,918] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-6) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,914] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-1 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,926] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,924] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-9 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,934] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,939] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,939] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,927] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-2) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,931] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-08 13:17:13,951] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 13:17:13,953] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 13:17:13,953] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 13:17:13,955] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 13:17:13,955] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,955] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-5, topic-4-9) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,956] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,957] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-5 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,958] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-9 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,958] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,957] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,963] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:13,966] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,979] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,987] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 13:17:13,980] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:13,989] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 13:17:13,976] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-5 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,992] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-3, topic-4-7, topic-4-11) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,998] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-1 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:13,998] INFO [Partition topic-4-3 broker=2] topic-4-3 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,004] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 13:17:14,004] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,011] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 13:17:14,011] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-10, topic-3-0, topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,014] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,013] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,012] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,014] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,030] INFO [Partition topic-4-7 broker=2] topic-4-7 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,032] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,036] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,032] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,047] INFO [Partition topic-4-11 broker=2] topic-4-11 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,052] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 4 from offset 6. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 13:17:14,061] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,068] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,072] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,075] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-10, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,077] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=1, leaderEpoch=1), topic-4-2 -> (offset=1, leaderEpoch=1), topic-4-10 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,086] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,080] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=1, leaderEpoch=1), topic-4-4 -> (offset=1, leaderEpoch=1), topic-4-0 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,089] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,093] INFO [Partition topic-3-0 broker=1] Expanding ISR from 1 to 1,0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,113] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-10, topic-4-3, topic-4-11, topic-4-7, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,114] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,116] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-11 -> (offset=1, leaderEpoch=1), topic-4-3 -> (offset=1, leaderEpoch=1), topic-4-7 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,116] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-11 -> (offset=1, leaderEpoch=1), topic-4-3 -> (offset=1, leaderEpoch=1), topic-4-7 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,118] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=1, leaderEpoch=1), topic-4-2 -> (offset=1, leaderEpoch=1), topic-4-10 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,118] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=1, leaderEpoch=1), topic-4-4 -> (offset=1, leaderEpoch=1), topic-4-0 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,178] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,178] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,181] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 13:17:14,182] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 4000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 13:17:14,182] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 13:17:14,182] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 13:17:14,183] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 13:17:14,183] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 13:17:14,184] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 13:17:14,185] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:17:14,185] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,216] INFO [Partition topic-4-4 broker=3] Expanding ISR from 3,1,2 to 3,1,2,0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,251] INFO [Partition topic-4-0 broker=3] Expanding ISR from 3,1,2 to 3,1,2,0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,257] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,257] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,257] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,257] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,261] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,261] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,263] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:14,264] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:14,307] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2,3,1 to 2,3,1,0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,338] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2,1,3 to 2,1,3,0 (kafka.cluster.Partition)
[2019-08-08 13:17:14,350] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,350] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,350] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,352] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:14,350] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,356] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:14,356] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,359] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,363] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,363] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,373] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,512] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,512] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,514] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 13:17:14,515] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 13:17:14,515] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 13:17:14,526] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 13:17:14,526] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 13:17:14,528] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,530] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,530] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,531] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,536] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=947254808, epoch=13174) to node 3: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 13:17:14,536] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=2086020404, epoch=13804) to node 1: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 13:17:14,536] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,536] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1451968561, epoch=13176) to node 2: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 13:17:14,537] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,537] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,537] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,540] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,542] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 13:17:14,545] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:14,546] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:14,548] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 13:17:14,548] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,576] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,577] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,579] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,579] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,579] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,583] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:14,744] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,744] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,745] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,759] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,759] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,760] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,774] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,774] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 13:17:14,786] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 13:17:14,787] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 13:17:15,009] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,046] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,075] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (W101GKNGH2.mshome.net/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 13:17:15,145] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,183] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,218] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,568] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2402 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,630] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,674] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,707] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,741] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,835] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:15,869] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,090] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,157] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,179] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (W101GKNGH2.mshome.net/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 13:17:16,194] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,229] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,553] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,622] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:16,694] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 13:17:17,042] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 13:17:17,049] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 13:17:17,051] INFO Processed session termination for sessionid: 0x10005432d980007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 13:17:17,053] INFO Session: 0x10005432d980007 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 13:17:17,053] INFO Closed socket connection for client /127.0.0.1:54095 which had sessionid 0x10005432d980007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 13:17:17,053] INFO EventThread shut down for session: 0x10005432d980007 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 13:17:17,055] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 13:17:17,055] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,113] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,113] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,115] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,203] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-3, topic-4-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,204] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,205] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,204] INFO [Partition topic-4-3 broker=2] topic-4-3 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 13:17:17,206] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 13:17:17,205] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 5 from offset 6. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 13:17:17,210] WARN [LeaderEpochCache topic-4-3] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 13:17:17,211] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=2, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 13:17:17,212] WARN [LeaderEpochCache topic-3-0] New epoch entry EpochEntry(epoch=5, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 13:17:17,224] INFO [Partition topic-4-7 broker=2] topic-4-7 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 13:17:17,226] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 13:17:17,226] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-3, topic-4-7, topic-4-4, topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,225] WARN [LeaderEpochCache topic-4-7] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 13:17:17,226] WARN [LeaderEpochCache topic-4-4] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 13:17:17,227] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-3 -> (offset=1, leaderEpoch=2), topic-4-7 -> (offset=1, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,231] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=2, leaderEpoch=2), topic-4-4 -> (offset=1, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,243] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-4, topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,244] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=2, leaderEpoch=2), topic-4-4 -> (offset=1, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,245] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-3, topic-4-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,246] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.mshome.net:9094) for partitions Map(topic-4-3 -> (offset=1, leaderEpoch=2), topic-4-7 -> (offset=1, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 13:17:17,278] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,279] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,279] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:17,280] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 13:17:17,331] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,331] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,332] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,370] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,370] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,371] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,370] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 13:17:17,644] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,644] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 13:17:17,652] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 13:17:17,700] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 13:17:17,706] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-08-08 13:24:40,732] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:25:01,243] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:26:41,258] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:34:40,733] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:35:01,244] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:36:41,257] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:44:40,732] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:45:01,243] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 13:46:41,258] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:27:01,526] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=365700336, epoch=17155) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:01,532] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1703277405, epoch=17155) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:01,794] WARN Client session timed out, have not heard from server in 2190541ms for sessionid 0x10005432d980006 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:02,893] INFO Client session timed out, have not heard from server in 2190541ms for sessionid 0x10005432d980006, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:01,576] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9093-172.20.104.65:54598-1 (kafka.network.Processor)
[2019-08-08 14:27:01,576] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9093-172.20.104.65:54602-1 (kafka.network.Processor)
[2019-08-08 14:27:01,530] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=660795298, epoch=17157) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:02,909] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=660795298, epoch=17157)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:02,834] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=365700336, epoch=17155)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:01,535] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1704013287, epoch=17157) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:02,658] INFO Expiring session 0x10005432d980008, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:02,773] WARN Client session timed out, have not heard from server in 2190542ms for sessionid 0x10005432d980009 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:01,660] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:54597-0 (kafka.network.Processor)
[2019-08-08 14:27:02,297] WARN Client session timed out, have not heard from server in 2190541ms for sessionid 0x10005432d980008 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:01,660] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:54603-1 (kafka.network.Processor)
[2019-08-08 14:27:02,894] WARN Unable to read additional data from client sessionid 0x10005432d980006, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:03,277] INFO Expiring session 0x10005432d980006, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:03,393] INFO Expiring session 0x10005432d980009, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:03,384] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54023 which had sessionid 0x10005432d980006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:01,658] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9094-172.20.104.65:54593-0 (kafka.network.Processor)
[2019-08-08 14:27:03,395] INFO Processed session termination for sessionid: 0x10005432d980008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:01,535] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1986112623, epoch=17156) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:03,464] INFO Processed session termination for sessionid: 0x10005432d980006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:01,658] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9094-172.20.104.65:54600-1 (kafka.network.Processor)
[2019-08-08 14:27:03,294] INFO Client session timed out, have not heard from server in 2190542ms for sessionid 0x10005432d980009, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:03,281] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1704013287, epoch=17157)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:03,465] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1986112623, epoch=17156)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:01,532] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1464240534, epoch=17158) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 14:27:03,377] INFO Client session timed out, have not heard from server in 2190541ms for sessionid 0x10005432d980008, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:02,892] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1703277405, epoch=17155)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:03,930] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1464240534, epoch=17158)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 14:27:03,478] INFO Closed socket connection for client /127.0.0.1:54445 which had sessionid 0x10005432d980008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:03,864] INFO Processed session termination for sessionid: 0x10005432d980009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:04,028] WARN Unable to read additional data from client sessionid 0x10005432d980009, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:04,031] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54477 which had sessionid 0x10005432d980009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:04,032] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54477 which had sessionid 0x10005432d980009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:04,483] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,609] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61024 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:04,610] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,726] INFO Client attempting to renew session 0x10005432d980006 at /0:0:0:0:0:0:0:1:61024 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:04,733] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980006 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,740] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980006 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,735] INFO EventThread shut down for session: 0x10005432d980006 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,733] INFO Invalid session 0x10005432d980006 for client /0:0:0:0:0:0:0:1:61024, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:04,749] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61024 which had sessionid 0x10005432d980006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:04,872] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:04,924] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:04,930] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 14:27:04,942] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,944] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,943] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61028 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:04,952] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:04,950] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61028 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:04,958] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d98000f, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:04,958] INFO Established session 0x10005432d98000f with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61028 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:04,967] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:04,967] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:05,163] INFO Got user-level KeeperException when processing sessionid:0x10005432d98000f type:multi cxid:0xd1 zxid:0x1d9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:05,175] INFO Got user-level KeeperException when processing sessionid:0x10005432d98000f type:multi cxid:0xd3 zxid:0x1da txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:05,522] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,578] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:05,592] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61036 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:05,591] INFO [Partition topic-4-9 broker=1] topic-4-9 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:05,593] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,633] INFO Client attempting to renew session 0x10005432d980009 at /0:0:0:0:0:0:0:1:61036 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:05,637] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980009 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,637] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980009 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,639] INFO EventThread shut down for session: 0x10005432d980009 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,637] INFO Invalid session 0x10005432d980009 for client /0:0:0:0:0:0:0:1:61036, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:05,644] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61036 which had sessionid 0x10005432d980009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:05,653] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:05,657] INFO [Partition topic-4-3 broker=1] topic-4-3 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 14:27:05,667] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:05,667] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 14:27:05,682] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:05,695] INFO [Partition topic-4-0 broker=1] topic-4-0 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 14:27:05,697] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,700] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,700] INFO Accepted socket connection from /127.0.0.1:61040 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:05,707] INFO Client attempting to establish new session at /127.0.0.1:61040 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:05,714] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980010, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:05,714] INFO Established session 0x10005432d980010 with negotiated timeout 6000 for client /127.0.0.1:61040 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:05,715] INFO [Partition topic-4-7 broker=1] topic-4-7 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 14:27:05,724] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:05,725] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:05,742] INFO [Partition topic-4-4 broker=1] topic-4-4 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 14:27:05,867] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:06,009] INFO [Partition topic-4-8 broker=1] topic-4-8 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:05,977] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-9 -> (offset=2, leaderEpoch=2), topic-4-11 -> (offset=2, leaderEpoch=2), topic-4-8 -> (offset=2, leaderEpoch=2), topic-4-3 -> (offset=1, leaderEpoch=3), topic-4-7 -> (offset=1, leaderEpoch=3), topic-4-4 -> (offset=1, leaderEpoch=3), topic-4-0 -> (offset=2, leaderEpoch=3), topic-4-5 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:06,038] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,048] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,099] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61056 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:06,095] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,102] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,123] INFO Client attempting to renew session 0x10005432d980008 at /0:0:0:0:0:0:0:1:61056 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:06,127] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980008 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,095] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,129] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980008 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,141] INFO EventThread shut down for session: 0x10005432d980008 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,125] INFO [Partition topic-4-5 broker=1] topic-4-5 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:06,127] INFO Invalid session 0x10005432d980008 for client /0:0:0:0:0:0:0:1:61056, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:06,149] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61056 which had sessionid 0x10005432d980008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:06,156] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:06,167] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 14:27:06,169] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 14:27:06,179] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,182] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,181] INFO Accepted socket connection from /127.0.0.1:61059 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 14:27:06,195] INFO Client attempting to establish new session at /127.0.0.1:61059 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:06,288] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980011, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 14:27:06,288] INFO Established session 0x10005432d980011 with negotiated timeout 6000 for client /127.0.0.1:61059 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:06,366] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-4-9 has an older epoch (1) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,371] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-4-4 has an older epoch (2) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,378] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-4-0 has an older epoch (2) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,380] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-4-8 has an older epoch (1) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,806] INFO [Partition topic-4-11 broker=1] topic-4-11 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:06,843] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:06,873] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:06,902] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 14:27:06,929] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:06,969] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:06,974] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:06,975] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:27:06,975] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:06,976] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:27:06,977] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:27:06,981] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:06,929] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,986] INFO [Partition topic-4-9 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:06,991] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,991] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:06,997] INFO [Partition topic-4-11 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,008] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,015] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,015] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,027] INFO [Partition topic-4-8 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,041] INFO [Partition topic-4-3 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,061] INFO [Partition topic-4-7 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,067] INFO [Partition topic-4-4 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,078] INFO [Partition topic-4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,090] INFO [Partition topic-4-5 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-08-08 14:27:07,078] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:07,098] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-9 -> (offset=2, leaderEpoch=2), topic-4-11 -> (offset=2, leaderEpoch=2), topic-4-8 -> (offset=2, leaderEpoch=2), topic-4-3 -> (offset=1, leaderEpoch=3), topic-4-7 -> (offset=1, leaderEpoch=3), topic-4-4 -> (offset=1, leaderEpoch=3), topic-4-0 -> (offset=2, leaderEpoch=3), topic-4-5 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:07,112] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,124] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,124] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:07,201] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs-2\replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-2\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-2\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-2\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-2\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-08 14:27:07,231] INFO [ReplicaManager broker=2] Stopping serving replicas in dir C:\tmp\kafka-logs-2 (kafka.server.ReplicaManager)
[2019-08-08 14:27:07,233] ERROR [ReplicaManager broker=2] Error while writing to highwatermark file in directory C:\tmp\kafka-logs-2 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs-2\replication-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-2\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-2\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-2\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-2\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-08 14:27:07,251] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:07,268] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 14:27:07,299] INFO [ReplicaManager broker=2] Broker 2 stopped fetcher for partitions topic-4-9,topic-4-11,topic-4-6,topic-4-2,topic-4-10,topic-4-1,topic-4-8,topic-4-3,topic-4-7,topic-4-4,topic-4-0,topic-4-5 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-2. (kafka.server.ReplicaManager)
[2019-08-08 14:27:07,310] INFO Stopping serving logs in dir C:\tmp\kafka-logs-2 (kafka.log.LogManager)
[2019-08-08 14:27:07,313] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-2 have failed (kafka.log.LogManager)
[2019-08-08 14:27:07,791] WARN Exception causing close of session 0x10005432d980011: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:07,804] INFO Closed socket connection for client /127.0.0.1:61059 which had sessionid 0x10005432d980011 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 14:27:10,229] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:09,776] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (W101GKNGH2.mshome.net/172.20.104.65:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 14:27:10,242] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:10,847] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-4 -> (offset=1, leaderEpoch=4), topic-4-0 -> (offset=2, leaderEpoch=4), topic-4-8 -> (offset=2, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:10,804] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 4 from offset 2. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 14:27:10,848] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=4, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 14:27:10,865] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:10,888] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:10,885] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 14:27:10,888] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-4 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-08 14:27:10,890] WARN [LeaderEpochCache topic-4-4] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 14:27:10,894] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:10,958] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 14:27:11,929] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:11,932] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:27:11,965] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (W101GKNGH2.mshome.net/172.20.104.65:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 14:27:13,116] INFO Expiring session 0x10005432d980011, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 14:27:13,120] INFO Processed session termination for sessionid: 0x10005432d980011 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 14:27:13,238] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:13,241] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=1, leaderEpoch=2), topic-4-1 -> (offset=1, leaderEpoch=2), topic-4-10 -> (offset=2, leaderEpoch=2), topic-4-2 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:13,236] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-10, topic-4-1, topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 14:27:13,249] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:13,252] WARN [LeaderEpochCache topic-4-6] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 14:27:13,287] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:13,311] INFO [Partition topic-4-1 broker=1] topic-4-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:13,312] WARN [LeaderEpochCache topic-4-1] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 14:27:13,350] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-08 14:27:13,674] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:13,674] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:27:13,676] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 14:27:13,676] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 14:31:29,759] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:31:29,759] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:31:29,761] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:31:29,761] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:33:09,757] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:33:09,757] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:33:09,759] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:33:09,760] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:35:01,162] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:36:41,141] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:45:01,110] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:46:41,129] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:55:01,121] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:56:41,134] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 14:58:18,346] WARN [LeaderEpochCache topic-4-4] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 14:58:18,369] WARN [LeaderEpochCache topic-4-8] New epoch entry EpochEntry(epoch=3, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:05:01,126] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:06:41,143] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:24,653] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 15:08:25,005] INFO starting (kafka.server.KafkaServer)
[2019-08-08 15:08:25,006] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 15:08:25,021] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 15:08:25,031] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,031] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,032] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,032] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,033] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,033] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,037] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,037] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,038] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,038] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,038] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,039] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,039] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,040] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,040] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,043] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:08:25,070] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 15:08:25,071] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 15:08:25,075] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 15:08:25,076] INFO Accepted socket connection from /127.0.0.1:51796 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 15:08:25,087] INFO Client attempting to establish new session at /127.0.0.1:51796 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 15:08:25,095] INFO Established session 0x10005432d980012 with negotiated timeout 6000 for client /127.0.0.1:51796 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 15:08:25,097] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980012, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 15:08:25,100] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 15:08:25,145] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x1 zxid:0x1f2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,155] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x2 zxid:0x1f3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,158] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x3 zxid:0x1f4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,161] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x4 zxid:0x1f5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,163] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x5 zxid:0x1f6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,165] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x6 zxid:0x1f7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,167] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x7 zxid:0x1f8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,170] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x8 zxid:0x1f9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,172] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0x9 zxid:0x1fa txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,174] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0xa zxid:0x1fb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,176] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0xb zxid:0x1fc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,178] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0xc zxid:0x1fd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,181] INFO Got user-level KeeperException when processing sessionid:0x10005432d980012 type:create cxid:0xd zxid:0x1fe txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:08:25,372] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 15:08:25,442] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 15:08:25,452] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 15:08:25,485] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:08:25,487] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:08:25,488] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:08:25,535] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 15:08:25,693] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,714] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:25,746] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 178 ms (kafka.log.Log)
[2019-08-08 15:08:25,782] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,787] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 15:08:25,830] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,836] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:25,837] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 46 ms (kafka.log.Log)
[2019-08-08 15:08:25,880] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,887] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:25,888] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 48 ms (kafka.log.Log)
[2019-08-08 15:08:25,929] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,935] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:25,936] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 44 ms (kafka.log.Log)
[2019-08-08 15:08:25,981] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:25,987] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:25,988] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 49 ms (kafka.log.Log)
[2019-08-08 15:08:26,025] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,030] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-10\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,031] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 40 ms (kafka.log.Log)
[2019-08-08 15:08:26,061] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,066] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-11\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,067] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 33 ms (kafka.log.Log)
[2019-08-08 15:08:26,099] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,104] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,105] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 34 ms (kafka.log.Log)
[2019-08-08 15:08:26,136] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,141] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-3\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,142] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 34 ms (kafka.log.Log)
[2019-08-08 15:08:26,170] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,173] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-4\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,174] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 29 ms (kafka.log.Log)
[2019-08-08 15:08:26,202] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,206] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-5\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,206] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 30 ms (kafka.log.Log)
[2019-08-08 15:08:26,229] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,233] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-6\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,234] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 26 ms (kafka.log.Log)
[2019-08-08 15:08:26,260] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,264] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,265] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 29 ms (kafka.log.Log)
[2019-08-08 15:08:26,294] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,298] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-8\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,299] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-08-08 15:08:26,331] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,336] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-9\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,336] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 35 ms (kafka.log.Log)
[2019-08-08 15:08:26,363] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,365] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 15:08:26,426] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,431] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,432] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-08-08 15:08:26,459] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,461] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 15:08:26,486] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,488] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 15:08:26,513] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,514] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 15:08:26,541] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,543] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 15:08:26,577] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,580] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-08-08 15:08:26,617] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,619] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 15:08:26,651] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,653] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 15:08:26,681] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,683] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 15:08:26,711] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,713] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-08-08 15:08:26,741] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,743] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 15:08:26,763] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,765] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:26,784] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,785] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 15:08:26,821] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,825] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:26,829] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 43 ms (kafka.log.Log)
[2019-08-08 15:08:26,850] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,851] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:26,875] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,877] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 15:08:26,898] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,899] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:26,922] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,923] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 15:08:26,955] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,956] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-08-08 15:08:26,980] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:26,981] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 15:08:27,009] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,010] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 15:08:27,034] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,036] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 15:08:27,071] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,077] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:27,078] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-08-08 15:08:27,104] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,106] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 15:08:27,161] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 2402 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,167] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000002402.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:27,168] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2402 in 61 ms (kafka.log.Log)
[2019-08-08 15:08:27,228] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,234] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:27,239] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 70 ms (kafka.log.Log)
[2019-08-08 15:08:27,268] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,269] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 15:08:27,295] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,297] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 15:08:27,322] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,323] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 15:08:27,348] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,350] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 15:08:27,373] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,375] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 15:08:27,397] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,398] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 15:08:27,435] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,439] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:27,440] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-08-08 15:08:27,462] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,464] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 15:08:27,490] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,491] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 15:08:27,515] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,516] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 15:08:27,546] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,549] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 15:08:27,550] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 33 ms (kafka.log.Log)
[2019-08-08 15:08:27,573] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,575] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 15:08:27,597] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,599] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 15:08:27,618] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,620] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 15:08:27,639] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,641] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 15:08:27,663] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,664] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 15:08:27,686] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,687] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:27,708] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,709] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:27,734] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,736] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 15:08:27,756] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,757] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 15:08:27,778] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,779] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 15:08:27,801] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,803] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 15:08:27,825] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 15:08:27,827] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 15:08:27,831] INFO Logs loading complete in 2296 ms. (kafka.log.LogManager)
[2019-08-08 15:08:27,839] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 15:08:27,840] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 15:08:28,063] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 15:08:28,100] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 15:08:28,123] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,125] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,125] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,138] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 15:08:28,192] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 15:08:28,196] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 15:08:28,198] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 15:08:28,271] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,275] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,276] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:08:28,291] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:28,293] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:28,295] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:28,307] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 15:08:28,353] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 15:08:28,356] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 15:08:28,357] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 15:08:28,396] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 15:08:28,420] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 15:08:28,424] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 15:08:28,424] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 15:08:28,425] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 15:08:28,538] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,544] INFO Replica loaded for partition topic-4-9 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,544] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,545] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,545] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,550] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,553] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,556] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,563] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,563] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,564] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,568] INFO Replica loaded for partition topic-4-6 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,568] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,572] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,575] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,578] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 15:08:28,578] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,579] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,582] INFO Replica loaded for partition topic-4-3 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,582] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,585] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,588] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,593] INFO Replica loaded for partition topic-1-0 with initial high watermark 111 (kafka.cluster.Replica)
[2019-08-08 15:08:28,594] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,597] INFO Replica loaded for partition topic-4-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 15:08:28,597] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,598] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,601] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 15:08:28,605] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,609] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 15:08:28,613] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,616] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,620] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,622] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,627] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,627] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,630] INFO Replica loaded for partition topic-4-10 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,630] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,631] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,634] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,638] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,638] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,642] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,642] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,643] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,648] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,650] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,653] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,654] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,654] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,655] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,658] INFO Replica loaded for partition topic-4-4 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,661] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,664] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,671] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,676] INFO Replica loaded for partition topic-4-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,676] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,677] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,677] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,681] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,684] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,685] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,687] INFO Replica loaded for partition topic-3-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-08 15:08:28,690] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,693] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,696] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,696] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,696] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,699] INFO Replica loaded for partition topic-4-8 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,700] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,704] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,707] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,710] INFO Replica loaded for partition topic-4-5 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 15:08:28,710] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,711] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,713] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,716] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,716] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,717] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,717] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,720] INFO Replica loaded for partition topic-4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,722] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2402 (kafka.cluster.Replica)
[2019-08-08 15:08:28,726] INFO Replica loaded for partition topic-3-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-08 15:08:28,726] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,727] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,727] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,728] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,730] INFO Replica loaded for partition topic-4-11 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 15:08:28,733] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,736] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,738] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,740] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,744] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,746] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,748] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,751] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,753] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,756] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,760] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,763] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,766] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 15:08:28,769] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 15:08:28,771] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,774] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 15:08:28,777] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-5, topic-4-9, topic-4-2, topic-4-6, topic-4-10, topic-3-0, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-4-0, topic-4-8, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:08:28,819] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:08:28,826] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-9 -> (offset=1, leaderEpoch=2), topic-4-11 -> (offset=1, leaderEpoch=2), topic-4-6 -> (offset=1, leaderEpoch=2), topic-4-2 -> (offset=1, leaderEpoch=2), topic-3-1 -> (offset=7, leaderEpoch=3), topic-4-10 -> (offset=1, leaderEpoch=2), topic-4-1 -> (offset=1, leaderEpoch=2), topic-3-0 -> (offset=6, leaderEpoch=5), topic-4-3 -> (offset=1, leaderEpoch=3), topic-4-7 -> (offset=1, leaderEpoch=3), topic-4-5 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:08:28,833] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=1, leaderEpoch=3), topic-4-4 -> (offset=1, leaderEpoch=4), topic-4-0 -> (offset=2, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:08:28,834] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:08:28,857] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:28,858] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:28,860] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:08:28,868] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:08:28,870] INFO [Partition topic-4-0 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:28,875] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:28,932] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:28,951] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:28,966] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:28,979] INFO [Partition topic-4-8 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:28,981] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:28,985] INFO [Partition topic-4-4 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:28,997] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,015] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,028] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,038] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,049] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,060] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 3 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,070] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,081] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,092] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,102] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,115] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,129] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,139] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,149] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,159] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,170] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,179] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,188] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,197] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,206] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,216] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,228] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,238] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,248] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,257] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,267] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,277] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,286] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,296] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,306] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,317] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 3 from offset 2402. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,330] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,340] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,350] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,360] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,372] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,382] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,391] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,402] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,412] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,423] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,436] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,446] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,456] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,467] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,476] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,487] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 15:08:29,501] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,502] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,504] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,506] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,507] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,508] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,510] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,510] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,510] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,511] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,519] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,520] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,522] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,522] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,530] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,531] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,531] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,532] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,532] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,532] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,569] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 6 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:29,574] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 62 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,575] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,587] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,587] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,596] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,596] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,599] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,605] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,606] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,606] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,610] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-25012 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:29,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,619] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,619] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,619] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:08:29,626] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 6 (__consumer_offsets-31) (reason: Adding new member consumer-1-10c3ba6d-71dd-42af-9773-55ba382a8b5f) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:29,833] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,833] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,836] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,837] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,838] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,838] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:08:29,839] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,839] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-08 15:08:29,840] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,840] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-08 15:08:29,841] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:08:29,844] INFO [Partition topic-4-1 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,856] INFO [Partition topic-4-3 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,859] INFO [Partition topic-4-7 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,862] INFO [Partition topic-3-1 broker=1] Expanding ISR from 1 to 1,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,865] INFO [Partition topic-3-0 broker=1] Expanding ISR from 1 to 1,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,954] INFO [Partition topic-4-9 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,957] INFO [Partition topic-4-11 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,960] INFO [Partition topic-4-6 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,964] INFO [Partition topic-4-2 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,967] INFO [Partition topic-4-10 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:29,969] INFO [Partition topic-4-5 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:08:39,576] INFO [GroupCoordinator 0]: Member consumer-1-f92237a6-459e-4e95-9e4a-1d5cf06c4f0a in group test-consumer-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:39,582] INFO [GroupCoordinator 0]: Stabilized group test-consumer-group generation 7 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:08:39,590] INFO [GroupCoordinator 0]: Assignment received from leader for group test-consumer-group for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:10:18,733] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-08 15:10:18,733] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 15:10:18,747] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,748] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,751] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-9) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,751] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-9) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,755] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-11) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,755] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-11) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,756] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,757] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-6) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,758] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,758] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-2) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,760] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,760] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-3-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,762] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,762] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,765] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,767] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,769] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,769] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,769] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,770] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-08 15:10:18,769] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-3-1, topic-4-10, topic-4-1, topic-3-0, topic-4-3, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,770] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 5 from offset 2. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 15:10:18,771] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,774] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,772] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=5, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,771] INFO [Partition topic-4-9 broker=1] topic-4-9 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,776] WARN [LeaderEpochCache topic-4-9] New epoch entry EpochEntry(epoch=3, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,775] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 15:10:18,778] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-3) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,780] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-3) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,780] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 15:10:18,780] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 15:10:18,784] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 15:10:18,784] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,786] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-7) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,788] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-4) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,790] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(topic-4-4) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:18,794] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 5 from offset 11. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 15:10:18,794] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 3 from offset 11. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,798] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 15:10:18,800] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 15:10:18,804] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 15:10:18,812] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 4 from offset 7. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 15:10:18,813] INFO [Partition topic-4-3 broker=1] topic-4-3 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 15:10:18,813] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 15:10:18,813] WARN [LeaderEpochCache topic-4-3] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,814] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:18,827] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 3 from offset 11. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,830] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,831] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-9 -> (offset=2, leaderEpoch=3), topic-4-11 -> (offset=2, leaderEpoch=3), topic-4-6 -> (offset=11, leaderEpoch=3), topic-4-2 -> (offset=2, leaderEpoch=3), topic-4-10 -> (offset=11, leaderEpoch=3), topic-4-1 -> (offset=2, leaderEpoch=3), topic-4-3 -> (offset=1, leaderEpoch=4), topic-4-7 -> (offset=1, leaderEpoch=4), topic-4-5 -> (offset=17, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,839] INFO [Partition topic-4-7 broker=1] topic-4-7 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 15:10:18,839] WARN [LeaderEpochCache topic-4-7] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,851] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 6 from offset 6. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 15:10:18,851] WARN [LeaderEpochCache topic-3-0] New epoch entry EpochEntry(epoch=6, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,861] INFO [Partition topic-4-1 broker=1] topic-4-1 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,870] INFO [Partition topic-4-5 broker=1] topic-4-5 starts at Leader Epoch 3 from offset 17. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,878] INFO [Partition topic-4-11 broker=1] topic-4-11 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,878] WARN [LeaderEpochCache topic-4-11] New epoch entry EpochEntry(epoch=3, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,888] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-08-08 15:10:18,888] WARN [LeaderEpochCache topic-4-2] New epoch entry EpochEntry(epoch=3, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,900] INFO [Partition topic-3-1 broker=1] topic-3-1 starts at Leader Epoch 4 from offset 7. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 15:10:18,900] WARN [LeaderEpochCache topic-3-1] New epoch entry EpochEntry(epoch=4, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=7)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:18,911] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,911] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=7, leaderEpoch=4), topic-4-0 -> (offset=2, leaderEpoch=5), topic-4-4 -> (offset=11, leaderEpoch=5)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:18,944] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-08 15:10:18,944] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 15:10:18,946] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:18,948] INFO [Partition topic-4-0 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:10:18,960] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:18,961] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 15:10:18,962] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:18,962] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:10:18,963] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 15:10:18,964] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 17 has no effect as the largest offset in the log is 16 (kafka.log.Log)
[2019-08-08 15:10:18,964] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 15:10:18,965] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:18,965] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:18,968] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:18,968] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:18,971] INFO [Partition topic-4-5 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 15:10:18,973] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 15:10:18,974] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 7000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 15:10:18,974] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 15:10:18,975] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 15:10:18,975] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 15:10:18,975] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 15:10:18,976] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 15:10:18,977] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:10:18,977] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,048] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,048] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,050] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,191] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,191] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,193] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 15:10:19,194] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 15:10:19,194] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 15:10:19,195] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 15:10:19,195] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 15:10:19,197] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:19,198] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,199] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,202] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=2033725116, epoch=220) to node 1: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 15:10:19,202] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1705772593, epoch=221) to node 3: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 15:10:19,202] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,202] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,203] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,206] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 15:10:19,208] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:19,209] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:19,209] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 15:10:19,210] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,400] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,400] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,401] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,589] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,589] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,591] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,621] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,621] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 15:10:19,642] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 15:10:19,643] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 15:10:19,878] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:19,903] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (W101GKNGH2.mshome.net/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 15:10:19,912] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,010] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,046] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,433] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2643 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,529] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,565] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:20,694] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:21,006] WARN [Controller id=1, targetBrokerId=0] Connection to node 0 (W101GKNGH2.mshome.net/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 15:10:21,043] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:21,440] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 17 (kafka.log.ProducerStateManager)
[2019-08-08 15:10:21,860] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 15:10:21,864] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 15:10:21,866] INFO Processed session termination for sessionid: 0x10005432d980012 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 15:10:21,868] INFO Session: 0x10005432d980012 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 15:10:21,868] INFO EventThread shut down for session: 0x10005432d980012 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 15:10:21,869] INFO Closed socket connection for client /127.0.0.1:51796 which had sessionid 0x10005432d980012 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 15:10:21,870] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 15:10:21,873] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:21,942] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,943] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,942] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 6 from offset 2. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 15:10:21,943] INFO [Partition topic-4-5 broker=1] topic-4-5 starts at Leader Epoch 4 from offset 17. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 15:10:21,944] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=6, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:21,946] WARN [LeaderEpochCache topic-4-5] New epoch entry EpochEntry(epoch=4, startOffset=17) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=17)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:10:21,960] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,960] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=2, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,961] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,961] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-5 -> (offset=17, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 15:10:21,979] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 17 has no effect as the largest offset in the log is 16 (kafka.log.Log)
[2019-08-08 15:10:22,463] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 15:10:22,577] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,577] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,577] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,580] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,580] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,580] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,585] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,585] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 15:10:22,586] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 15:10:22,609] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 15:10:22,612] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-08-08 15:15:01,128] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:16:41,142] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:22:13,288] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=6, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 15:25:01,116] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:26:41,131] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:35:01,116] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:36:41,130] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:45:01,120] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:46:41,135] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:55:01,126] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 15:56:41,144] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:05:01,137] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:06:41,150] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:15:01,131] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:16:41,144] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:25:01,129] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:26:41,141] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:27:39,468] INFO Accepted socket connection from /127.0.0.1:55599 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 16:27:39,476] INFO Client attempting to establish new session at /127.0.0.1:55599 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:27:39,490] INFO Established session 0x10005432d980013 with negotiated timeout 30000 for client /127.0.0.1:55599 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:27:39,717] INFO Processed session termination for sessionid: 0x10005432d980013 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:27:39,728] INFO Closed socket connection for client /127.0.0.1:55599 which had sessionid 0x10005432d980013 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 16:28:34,747] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 16:28:35,043] INFO starting (kafka.server.KafkaServer)
[2019-08-08 16:28:35,044] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 16:28:35,064] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:28:35,074] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,074] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,075] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,075] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,075] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,076] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,077] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,077] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,078] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,078] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,078] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,079] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,079] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,080] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,080] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,082] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:28:35,105] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:28:35,106] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:28:35,110] INFO Accepted socket connection from /127.0.0.1:55629 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 16:28:35,110] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:28:35,114] INFO Client attempting to establish new session at /127.0.0.1:55629 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:28:35,117] INFO Established session 0x10005432d980014 with negotiated timeout 6000 for client /127.0.0.1:55629 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:28:35,120] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980014, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:28:35,125] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:28:35,175] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x1 zxid:0x295 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,186] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x2 zxid:0x296 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,188] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x3 zxid:0x297 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,191] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x4 zxid:0x298 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,193] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x5 zxid:0x299 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,195] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x6 zxid:0x29a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,197] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x7 zxid:0x29b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,199] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x8 zxid:0x29c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,200] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0x9 zxid:0x29d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,202] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0xa zxid:0x29e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,205] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0xb zxid:0x29f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,208] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0xc zxid:0x2a0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,210] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:create cxid:0xd zxid:0x2a1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:35,344] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 16:28:35,383] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 16:28:35,391] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 16:28:35,412] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:28:35,414] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:28:35,414] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:28:35,446] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 16:28:35,567] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,583] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,605] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 134 ms (kafka.log.Log)
[2019-08-08 16:28:35,631] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,634] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 16:28:35,669] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,675] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,676] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 38 ms (kafka.log.Log)
[2019-08-08 16:28:35,704] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,708] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,709] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 31 ms (kafka.log.Log)
[2019-08-08 16:28:35,737] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,741] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,742] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 30 ms (kafka.log.Log)
[2019-08-08 16:28:35,773] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,777] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-1\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,778] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 33 ms (kafka.log.Log)
[2019-08-08 16:28:35,806] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,810] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-10\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,814] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 33 ms (kafka.log.Log)
[2019-08-08 16:28:35,839] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,843] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-11\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,843] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 27 ms (kafka.log.Log)
[2019-08-08 16:28:35,867] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,871] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,873] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 28 ms (kafka.log.Log)
[2019-08-08 16:28:35,900] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,904] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-3\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,905] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 30 ms (kafka.log.Log)
[2019-08-08 16:28:35,932] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,937] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-4\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,938] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 30 ms (kafka.log.Log)
[2019-08-08 16:28:35,963] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 17 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,967] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-5\00000000000000000017.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,968] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 17 in 29 ms (kafka.log.Log)
[2019-08-08 16:28:35,992] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:35,997] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-6\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:35,998] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 28 ms (kafka.log.Log)
[2019-08-08 16:28:36,025] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,029] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,029] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 30 ms (kafka.log.Log)
[2019-08-08 16:28:36,055] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,060] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-8\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,061] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 30 ms (kafka.log.Log)
[2019-08-08 16:28:36,082] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,087] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-9\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,088] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 26 ms (kafka.log.Log)
[2019-08-08 16:28:36,105] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,107] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,142] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,145] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,149] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-08-08 16:28:36,166] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,167] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,185] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,186] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,209] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,211] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,228] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,230] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:36,248] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,250] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 16:28:36,270] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,272] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 16:28:36,293] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,294] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 16:28:36,315] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,317] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 16:28:36,338] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,340] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 16:28:36,361] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,363] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 16:28:36,383] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,385] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 16:28:36,403] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,405] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:36,435] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,440] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,441] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 34 ms (kafka.log.Log)
[2019-08-08 16:28:36,466] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,468] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-08-08 16:28:36,488] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,490] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 16:28:36,507] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,509] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:36,525] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,526] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:36,542] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,544] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,561] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,562] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,577] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,578] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-08-08 16:28:36,593] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,594] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-08-08 16:28:36,626] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,630] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,630] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 34 ms (kafka.log.Log)
[2019-08-08 16:28:36,646] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,647] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:36,679] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 2643 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,683] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000002643.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,684] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2643 in 36 ms (kafka.log.Log)
[2019-08-08 16:28:36,718] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,722] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,723] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-08-08 16:28:36,745] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,747] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 16:28:36,767] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,769] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 16:28:36,786] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,788] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:36,808] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,810] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 16:28:36,826] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,827] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:36,843] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,844] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-08-08 16:28:36,877] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,880] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,881] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 35 ms (kafka.log.Log)
[2019-08-08 16:28:36,898] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,899] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:36,915] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,916] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:36,931] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,933] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:36,967] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,971] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 16:28:36,972] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-08-08 16:28:36,989] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:36,991] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:37,007] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,011] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 16:28:37,029] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,030] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:37,045] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,047] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:37,063] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,065] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:37,081] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,083] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:37,100] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,101] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:37,117] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,118] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:37,134] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,136] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 16:28:37,155] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,156] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 16:28:37,173] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,174] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 16:28:37,188] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 16:28:37,189] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-08-08 16:28:37,192] INFO Logs loading complete in 1746 ms. (kafka.log.LogManager)
[2019-08-08 16:28:37,200] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 16:28:37,200] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 16:28:37,388] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 16:28:37,417] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 16:28:37,434] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,435] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,436] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,445] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:28:37,502] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 16:28:37,514] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 16:28:37,515] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 16:28:37,577] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,580] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,581] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:28:37,595] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:37,596] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:37,598] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:37,609] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 16:28:37,625] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:28:37,627] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:28:37,627] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:28:37,651] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:28:37,668] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 16:28:37,670] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 16:28:37,670] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 16:28:37,672] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 16:28:37,750] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,755] INFO Replica loaded for partition topic-4-9 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 16:28:37,756] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,756] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,756] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,761] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,765] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,767] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,771] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,772] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,772] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,776] INFO Replica loaded for partition topic-4-6 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-08 16:28:37,776] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,779] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,782] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,785] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 16:28:37,785] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,786] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,789] INFO Replica loaded for partition topic-4-3 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 16:28:37,789] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,793] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,796] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,798] INFO Replica loaded for partition topic-1-0 with initial high watermark 111 (kafka.cluster.Replica)
[2019-08-08 16:28:37,799] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,802] INFO Replica loaded for partition topic-4-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 16:28:37,803] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,804] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,808] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 16:28:37,811] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,814] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 16:28:37,817] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,821] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,824] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,827] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,830] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,830] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,834] INFO Replica loaded for partition topic-4-10 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-08 16:28:37,835] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,835] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,840] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,843] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,843] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,848] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 16:28:37,848] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,848] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,852] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,856] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,860] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,861] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,861] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,862] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,865] INFO Replica loaded for partition topic-4-4 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-08 16:28:37,868] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,872] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,875] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,878] INFO Replica loaded for partition topic-4-1 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 16:28:37,878] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,879] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,879] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,882] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 16:28:37,886] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,886] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,891] INFO Replica loaded for partition topic-3-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-08 16:28:37,894] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,897] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,901] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,901] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,902] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,905] INFO Replica loaded for partition topic-4-8 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-08 16:28:37,905] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,909] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,913] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,916] INFO Replica loaded for partition topic-4-5 with initial high watermark 17 (kafka.cluster.Replica)
[2019-08-08 16:28:37,916] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,917] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,917] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,921] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,922] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,922] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,923] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,925] INFO Replica loaded for partition topic-4-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 16:28:37,927] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2643 (kafka.cluster.Replica)
[2019-08-08 16:28:37,930] INFO Replica loaded for partition topic-3-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-08 16:28:37,932] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,932] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,933] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,933] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,936] INFO Replica loaded for partition topic-4-11 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 16:28:37,939] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,942] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,944] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,946] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,948] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,951] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,955] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,958] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,960] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,964] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,966] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,969] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,972] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 16:28:37,975] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 16:28:37,978] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,980] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 16:28:37,982] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-5, topic-4-9, topic-4-2, topic-4-6, topic-4-10, topic-3-0, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-4-0, topic-4-8, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:28:38,008] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:28:38,013] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-9 -> (offset=2, leaderEpoch=3), topic-4-11 -> (offset=2, leaderEpoch=3), topic-4-6 -> (offset=11, leaderEpoch=3), topic-4-2 -> (offset=2, leaderEpoch=3), topic-3-1 -> (offset=7, leaderEpoch=4), topic-4-10 -> (offset=11, leaderEpoch=3), topic-4-1 -> (offset=2, leaderEpoch=3), topic-3-0 -> (offset=6, leaderEpoch=6), topic-4-3 -> (offset=1, leaderEpoch=4), topic-4-7 -> (offset=1, leaderEpoch=4), topic-4-5 -> (offset=17, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:28:38,018] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-8 -> (offset=7, leaderEpoch=4), topic-4-4 -> (offset=11, leaderEpoch=5), topic-4-0 -> (offset=2, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:28:38,020] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:28:38,049] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-08 16:28:38,050] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 16:28:38,051] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 16:28:38,055] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:28:38,058] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,077] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,087] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,098] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,109] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,112] INFO [Partition topic-4-8 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:38,117] INFO [Partition topic-4-4 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:38,119] INFO [Partition topic-4-0 broker=3] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:38,121] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,132] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,144] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,157] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,169] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,180] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 5 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,192] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,203] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,214] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,226] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,234] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,244] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,253] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,262] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,272] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,281] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,291] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,301] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,310] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,320] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,331] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,341] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,350] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,360] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,369] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,380] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,399] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,417] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,428] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,442] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,462] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 5 from offset 2643. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,476] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,494] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,510] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,524] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,541] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,572] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,600] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,623] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,639] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,653] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,663] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,672] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,682] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,692] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,703] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,713] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 16:28:38,727] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,727] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,730] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,733] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,733] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,734] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,735] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,735] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,736] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,737] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,737] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,738] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,738] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,739] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,740] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,741] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,742] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,745] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,746] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,747] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,747] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,748] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,750] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,750] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,750] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,751] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,751] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,752] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,752] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,753] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,755] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,761] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,761] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,763] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,763] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,804] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:38,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 66 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,815] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,821] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,821] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,822] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,822] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,823] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,823] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,824] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,826] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,826] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,827] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,827] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,828] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,828] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,829] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,829] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,840] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,843] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-25012 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:38,843] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,843] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,844] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,844] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,851] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,855] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 16:28:38,943] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-25012 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: Adding new member consumer-1-1c189336-586d-4b71-91e4-4f32b274f86f) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:39,019] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 16:28:39,019] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 16:28:39,020] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 16:28:39,021] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 16:28:39,021] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 16:28:39,021] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Truncating to 17 has no effect as the largest offset in the log is 16 (kafka.log.Log)
[2019-08-08 16:28:39,022] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 16:28:39,023] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-08 16:28:39,023] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 16:28:39,024] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-08 16:28:39,024] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 16:28:39,027] INFO [Partition topic-4-7 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,038] INFO [Partition topic-3-1 broker=1] Expanding ISR from 1 to 1,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,040] INFO [Partition topic-3-0 broker=1] Expanding ISR from 1 to 1,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,132] INFO [Partition topic-4-9 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,135] INFO [Partition topic-4-11 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,137] INFO [Partition topic-4-6 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,139] INFO [Partition topic-4-2 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,142] INFO [Partition topic-4-10 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,145] INFO [Partition topic-4-1 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,147] INFO [Partition topic-4-3 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:39,149] INFO [Partition topic-4-5 broker=1] Expanding ISR from 1,3 to 1,3,0 (kafka.cluster.Partition)
[2019-08-08 16:28:40,332] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member rdkafka-ebd91bc1-fb56-42bd-8ba7-b11f2c4a355e) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:40,340] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:40,352] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:40,451] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55672 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 16:28:40,455] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55672 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:28:40,466] INFO Established session 0x10005432d980015 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:55672 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 16:28:40,780] INFO Processed session termination for sessionid: 0x10005432d980015 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:28:40,791] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55672 which had sessionid 0x10005432d980015 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 16:28:48,812] INFO [GroupCoordinator 0]: Member consumer-1-10c3ba6d-71dd-42af-9773-55ba382a8b5f in group test-consumer-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,813] INFO [GroupCoordinator 0]: Preparing to rebalance group test-consumer-group in state PreparingRebalance with old generation 7 (__consumer_offsets-31) (reason: removing member consumer-1-10c3ba6d-71dd-42af-9773-55ba382a8b5f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,814] INFO [GroupCoordinator 0]: Member consumer-1-e6627446-5683-4abe-845b-4856254cd4b7 in group test-consumer-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,815] INFO [GroupCoordinator 0]: Group test-consumer-group with generation 8 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,845] INFO [GroupCoordinator 0]: Member consumer-1-14eff17a-e153-4c01-b1d1-eb3170d3d1b7 in group console-consumer-25012 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,846] INFO [GroupCoordinator 0]: Stabilized group console-consumer-25012 generation 2 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:28:48,850] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-25012 for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:30:30,569] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-08-08 16:30:30,570] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 16:30:30,592] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-3-0, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-2, topic-3-1, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,593] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-6, topic-4-3, topic-4-11, topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,594] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-9, topic-3-1, topic-4-10, topic-4-1, topic-3-0, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,594] INFO [Partition topic-4-6 broker=3] topic-4-6 starts at Leader Epoch 4 from offset 34. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,595] INFO [Partition topic-4-9 broker=0] topic-4-9 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,604] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,605] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,605] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-08 16:30:30,610] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,611] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(topic-4-8) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,616] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:30:30,616] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:30:30,616] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:30:30,618] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-4) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,619] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:30:30,619] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(topic-4-4) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,622] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,622] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(topic-4-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,623] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,626] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=338665324, epoch=14775) to node 3: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 16:30:30,627] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,628] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,628] INFO [Partition topic-4-3 broker=3] topic-4-3 starts at Leader Epoch 5 from offset 9. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:30:30,641] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,643] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:30:30,653] INFO [Partition topic-4-10 broker=0] topic-4-10 starts at Leader Epoch 4 from offset 24. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,643] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,652] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:30:30,660] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:30:30,661] INFO [Partition topic-4-11 broker=3] topic-4-11 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,668] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 16:30:30,670] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,677] INFO [Partition topic-4-7 broker=0] topic-4-7 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:30:30,685] INFO [Partition topic-4-2 broker=3] topic-4-2 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,690] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 7 from offset 6. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 16:30:30,701] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-9, topic-4-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,702] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,702] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,704] INFO [Partition topic-4-1 broker=0] topic-4-1 starts at Leader Epoch 4 from offset 10. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-08-08 16:30:30,707] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:30:30,709] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 3000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 16:30:30,710] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 16:30:30,710] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:30:30,711] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:30:30,713] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-4-9 -> (offset=3, leaderEpoch=4), topic-4-10 -> (offset=24, leaderEpoch=4), topic-4-1 -> (offset=10, leaderEpoch=4), topic-4-7 -> (offset=1, leaderEpoch=5), topic-4-5 -> (offset=51, leaderEpoch=5)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,714] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,711] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:30:30,716] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:30:30,718] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:30:30,716] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,718] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,716] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,716] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,725] INFO [Partition topic-4-5 broker=0] topic-4-5 starts at Leader Epoch 5 from offset 51. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:30:30,726] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,727] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 7 from offset 4. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 16:30:30,742] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 6 from offset 28. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 16:30:30,742] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 5 from offset 7. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:30:30,745] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2019-08-08 16:30:30,745] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 16:30:30,746] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 16:30:30,746] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 51 has no effect as the largest offset in the log is 50 (kafka.log.Log)
[2019-08-08 16:30:30,748] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-08-08 16:30:30,756] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-3, topic-4-11, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,756] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 5 from offset 19. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:30:30,757] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,757] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-6 -> (offset=34, leaderEpoch=4), topic-4-3 -> (offset=9, leaderEpoch=5), topic-4-2 -> (offset=3, leaderEpoch=4), topic-4-11 -> (offset=3, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,757] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,759] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,761] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,760] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,761] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:30:30,776] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,779] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=4, leaderEpoch=7), topic-4-8 -> (offset=19, leaderEpoch=5), topic-4-4 -> (offset=28, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,788] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,788] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,790] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:30:30,791] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 16:30:30,791] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:30:30,792] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:30:30,792] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:30:30,793] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,795] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:30:30,795] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,796] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:30:30,796] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,949] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,949] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,950] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,958] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,958] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:30,958] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:31,041] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:31,041] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:30:31,056] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 16:30:31,057] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 16:30:31,078] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,122] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,146] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 16:30:31,147] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 19 has no effect as the largest offset in the log is 18 (kafka.log.Log)
[2019-08-08 16:30:31,148] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 34 has no effect as the largest offset in the log is 33 (kafka.log.Log)
[2019-08-08 16:30:31,148] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 28 has no effect as the largest offset in the log is 27 (kafka.log.Log)
[2019-08-08 16:30:31,149] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-08-08 16:30:31,149] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 16:30:31,150] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-08-08 16:30:31,160] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 34 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,204] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,235] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,266] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,298] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,331] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 19 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,364] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,401] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,435] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,468] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 28 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,501] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,535] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 51 (kafka.log.ProducerStateManager)
[2019-08-08 16:30:31,602] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 16:30:31,611] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:30:31,612] INFO Processed session termination for sessionid: 0x10005432d98000f (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:30:31,614] INFO Session: 0x10005432d98000f closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:30:31,615] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61028 which had sessionid 0x10005432d98000f (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 16:30:31,614] INFO EventThread shut down for session: 0x10005432d98000f (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:30:31,617] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:30:31,618] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:31,626] INFO Got user-level KeeperException when processing sessionid:0x10005432d980010 type:multi cxid:0x14 zxid:0x2fc txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:30:31,780] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:multi cxid:0xc6 zxid:0x2fd txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:30:31,789] INFO Got user-level KeeperException when processing sessionid:0x10005432d980014 type:multi cxid:0xc8 zxid:0x2fe txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:30:31,875] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:31,875] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:31,876] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,404] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,404] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,405] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,521] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,521] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:30:32,524] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 16:30:32,541] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 16:30:32,544] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-08-08 16:32:13,945] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-08-08 16:32:13,947] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 16:32:13,993] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-3, topic-4-11, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:13,994] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-11, topic-4-6, topic-4-2, topic-4-8, topic-4-3, topic-4-4, topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:13,995] INFO [Partition topic-4-6 broker=0] topic-4-6 starts at Leader Epoch 5 from offset 42. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,001] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,001] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,010] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,010] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-9) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,011] INFO [Partition topic-4-3 broker=0] topic-4-3 starts at Leader Epoch 6 from offset 10. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 16:32:14,013] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,014] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-10) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,015] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,015] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,019] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,021] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-7) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,021] INFO [KafkaServer id=3] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-08-08 16:32:14,022] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,023] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-5) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,026] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,026] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:32:14,028] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=536004058, epoch=212) to node 0: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 16:32:14,028] INFO [Partition topic-4-0 broker=0] topic-4-0 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 16:32:14,028] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:32:14,028] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,028] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,028] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:32:14,030] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:32:14,036] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,037] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,043] INFO [Partition topic-4-4 broker=0] topic-4-4 starts at Leader Epoch 7 from offset 36. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 16:32:14,050] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:32:14,051] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:32:14,062] INFO [Partition topic-4-8 broker=0] topic-4-8 starts at Leader Epoch 6 from offset 23. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 16:32:14,063] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:32:14,066] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 16:32:14,068] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,075] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,075] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,076] INFO [Partition topic-4-11 broker=0] topic-4-11 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,079] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:32:14,081] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 16:32:14,082] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 16:32:14,084] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:32:14,085] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:32:14,085] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:32:14,086] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:32:14,087] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:32:14,087] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,089] INFO [Partition topic-4-2 broker=0] topic-4-2 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,103] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,103] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,103] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 16:32:14,109] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-9, topic-4-10, topic-4-1, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,110] INFO [Partition topic-4-9 broker=0] topic-4-9 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,111] WARN [LeaderEpochCache topic-4-9] New epoch entry EpochEntry(epoch=5, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=3)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 16:32:14,122] INFO [Partition topic-4-10 broker=0] topic-4-10 starts at Leader Epoch 5 from offset 30. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,130] INFO [Partition topic-4-7 broker=0] topic-4-7 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 16:32:14,130] WARN [LeaderEpochCache topic-4-7] New epoch entry EpochEntry(epoch=6, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 16:32:14,140] INFO [Partition topic-4-1 broker=0] topic-4-1 starts at Leader Epoch 5 from offset 11. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-08 16:32:14,148] INFO [Partition topic-4-5 broker=0] topic-4-5 starts at Leader Epoch 6 from offset 63. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 16:32:14,175] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,175] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,176] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,291] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,291] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,293] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:32:14,295] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 16:32:14,295] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:32:14,296] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:32:14,296] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:32:14,297] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,299] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:32:14,299] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,300] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:32:14,300] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,470] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,470] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,471] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,672] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,672] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,673] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,687] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,687] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:32:14,708] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 16:32:14,709] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 16:32:14,726] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,777] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,813] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 42 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,846] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,880] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 30 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,916] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,951] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:14,985] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:15,020] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:15,055] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:15,090] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:15,123] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 63 (kafka.log.ProducerStateManager)
[2019-08-08 16:32:15,178] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (W101GKNGH2.mshome.net/172.20.104.65:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-08 16:32:15,192] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 16:32:15,194] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:32:15,195] INFO Processed session termination for sessionid: 0x10005432d980010 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:32:15,197] INFO EventThread shut down for session: 0x10005432d980010 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:32:15,197] INFO Closed socket connection for client /127.0.0.1:61040 which had sessionid 0x10005432d980010 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 16:32:15,197] INFO Session: 0x10005432d980010 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:32:15,199] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:32:15,200] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,349] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,349] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,350] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,366] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,366] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:15,367] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:16,031] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:16,031] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:32:16,034] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 16:32:16,048] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 16:32:16,051] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-08-08 16:34:38,541] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-25012 in state PreparingRebalance with old generation 2 (__consumer_offsets-21) (reason: removing member consumer-1-1c189336-586d-4b71-91e4-4f32b274f86f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:34:38,542] INFO [GroupCoordinator 0]: Group console-consumer-25012 with generation 3 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:35:21,101] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-08-08 16:35:21,102] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-08-08 16:35:21,132] INFO [KafkaServer id=0] Remaining partitions to move: topic-4-7,topic-4-6,topic-4-5,topic-4-4,topic-4-3,topic-4-2,topic-3-1,topic-4-1,topic-3-0,topic-4-0,topic-4-11,topic-4-10,topic-4-9,topic-4-8 (kafka.server.KafkaServer)
[2019-08-08 16:35:21,133] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 16:35:26,134] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 16:35:26,144] INFO [KafkaServer id=0] Remaining partitions to move: topic-4-7,topic-4-6,topic-4-5,topic-4-4,topic-4-3,topic-4-2,topic-3-1,topic-4-1,topic-3-0,topic-4-0,topic-4-11,topic-4-10,topic-4-9,topic-4-8 (kafka.server.KafkaServer)
[2019-08-08 16:35:26,144] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 16:35:31,145] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 16:35:31,155] INFO [KafkaServer id=0] Remaining partitions to move: topic-4-7,topic-4-6,topic-4-5,topic-4-4,topic-4-3,topic-4-2,topic-3-1,topic-4-1,topic-3-0,topic-4-0,topic-4-11,topic-4-10,topic-4-9,topic-4-8 (kafka.server.KafkaServer)
[2019-08-08 16:35:31,155] INFO [KafkaServer id=0] Error from controller: NONE (kafka.server.KafkaServer)
[2019-08-08 16:35:36,156] WARN [KafkaServer id=0] Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2019-08-08 16:35:36,158] WARN [KafkaServer id=0] Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2019-08-08 16:35:36,159] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:35:36,160] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:35:36,160] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 16:35:36,161] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:35:36,170] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-08-08 16:35:36,171] INFO [Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:35:36,172] INFO [Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-08-08 16:35:36,175] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-08-08 16:35:36,177] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,371] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,371] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,374] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:35:36,375] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 8000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 16:35:36,375] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-08-08 16:35:36,376] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:35:36,376] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:35:36,376] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 16:35:36,377] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 16:35:36,378] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:35:36,378] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,443] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,443] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,444] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,530] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,530] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,533] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 16:35:36,534] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-08-08 16:35:36,534] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:35:36,535] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:35:36,535] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 16:35:36,536] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:35:36,537] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-08-08 16:35:36,537] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:35:36,538] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 16:35:36,538] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,610] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,610] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,611] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,709] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,709] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,710] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,825] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,825] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 16:35:36,846] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-08-08 16:35:36,846] INFO Shutting down. (kafka.log.LogManager)
[2019-08-08 16:35:36,952] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,082] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,116] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,210] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 49 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,242] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,488] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 49 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,612] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2644 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,707] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 34 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,741] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 15 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:37,870] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 27 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:38,115] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:38,207] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 44 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:38,240] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:38,602] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 75 (kafka.log.ProducerStateManager)
[2019-08-08 16:35:39,001] INFO Shutdown complete. (kafka.log.LogManager)
[2019-08-08 16:35:39,009] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:35:39,010] INFO Processed session termination for sessionid: 0x10005432d980014 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 16:35:39,012] INFO Session: 0x10005432d980014 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-08 16:35:39,013] INFO Closed socket connection for client /127.0.0.1:55629 which had sessionid 0x10005432d980014 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 16:35:39,012] INFO EventThread shut down for session: 0x10005432d980014 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 16:35:39,014] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 16:35:39,015] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:39,766] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:39,766] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:39,767] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,742] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,742] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,743] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,752] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,752] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 16:35:40,754] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-08-08 16:35:40,766] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-08-08 16:35:40,769] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-08-08 17:17:18,639] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 17:17:19,014] INFO starting (kafka.server.KafkaServer)
[2019-08-08 17:17:19,016] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 17:17:19,034] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:17:19,044] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,044] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,044] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,045] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,045] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,046] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,046] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,047] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,047] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,048] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,048] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,048] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,049] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,049] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,050] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,051] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:17:19,075] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:17:19,076] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:17:19,078] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:17:19,078] INFO Accepted socket connection from /127.0.0.1:58102 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 17:17:19,084] INFO Client attempting to establish new session at /127.0.0.1:58102 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 17:17:19,096] INFO Established session 0x10005432d980016 with negotiated timeout 6000 for client /127.0.0.1:58102 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 17:17:19,098] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980016, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:17:19,102] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:17:19,155] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x1 zxid:0x30e txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,166] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x2 zxid:0x30f txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,168] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x3 zxid:0x310 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,170] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x4 zxid:0x311 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,172] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x5 zxid:0x312 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,175] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x6 zxid:0x313 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,178] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x7 zxid:0x314 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,179] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x8 zxid:0x315 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,182] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0x9 zxid:0x316 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,183] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0xa zxid:0x317 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,186] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0xb zxid:0x318 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,188] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0xc zxid:0x319 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,190] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:create cxid:0xd zxid:0x31a txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:19,366] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 17:17:19,419] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 17:17:19,430] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 17:17:19,467] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:17:19,471] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:17:19,471] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:17:19,518] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 17:17:19,644] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,655] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,673] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 123 ms (kafka.log.Log)
[2019-08-08 17:17:19,691] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,694] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:19,725] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,729] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,729] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 33 ms (kafka.log.Log)
[2019-08-08 17:17:19,763] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,768] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,769] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 38 ms (kafka.log.Log)
[2019-08-08 17:17:19,802] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,806] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,807] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 36 ms (kafka.log.Log)
[2019-08-08 17:17:19,833] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,838] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-1\00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,839] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 30 ms (kafka.log.Log)
[2019-08-08 17:17:19,864] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,869] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-10\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,871] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 30 ms (kafka.log.Log)
[2019-08-08 17:17:19,930] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,936] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,937] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-08-08 17:17:19,973] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:19,977] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:19,978] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-08-08 17:17:20,005] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,009] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-3\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,010] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 30 ms (kafka.log.Log)
[2019-08-08 17:17:20,038] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 44 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,044] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-4\00000000000000000044.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,044] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 44 in 31 ms (kafka.log.Log)
[2019-08-08 17:17:20,074] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 75 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,078] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-5\00000000000000000075.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,079] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 75 in 33 ms (kafka.log.Log)
[2019-08-08 17:17:20,105] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 49 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,109] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-6\00000000000000000049.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,109] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 49 in 29 ms (kafka.log.Log)
[2019-08-08 17:17:20,142] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,146] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,147] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 36 ms (kafka.log.Log)
[2019-08-08 17:17:20,171] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 27 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,176] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-8\00000000000000000027.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,177] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 27 in 29 ms (kafka.log.Log)
[2019-08-08 17:17:20,210] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,215] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-9\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,215] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 37 ms (kafka.log.Log)
[2019-08-08 17:17:20,232] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,234] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,270] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,274] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,274] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 38 ms (kafka.log.Log)
[2019-08-08 17:17:20,292] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,293] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,309] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,311] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,329] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,331] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,348] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,350] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,369] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,371] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 17:17:20,388] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,390] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,407] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,408] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,427] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,428] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,445] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,447] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,464] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,465] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,481] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,482] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,499] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,500] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,522] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,526] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,527] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 25 ms (kafka.log.Log)
[2019-08-08 17:17:20,543] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,544] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,560] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,562] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,578] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,580] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,596] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,597] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,612] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,614] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,630] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,632] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:20,647] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,648] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,664] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,665] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 17:17:20,696] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,700] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,701] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 35 ms (kafka.log.Log)
[2019-08-08 17:17:20,719] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,720] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,749] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 2644 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,755] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000002644.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,756] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2644 in 35 ms (kafka.log.Log)
[2019-08-08 17:17:20,793] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,798] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,798] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-08-08 17:17:20,816] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,819] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 17:17:20,836] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,837] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,856] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,858] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 17:17:20,875] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,877] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,896] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,897] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 17:17:20,915] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,916] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,956] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,959] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:20,960] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-08-08 17:17:20,977] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,979] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:20,996] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:20,997] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:21,016] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,017] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,057] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,062] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:21,062] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 39 ms (kafka.log.Log)
[2019-08-08 17:17:21,080] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,081] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,099] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,100] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,119] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,120] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,137] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,138] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:21,155] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,156] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:21,173] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,175] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,198] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 49 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,201] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000049.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:17:21,202] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 49 in 26 ms (kafka.log.Log)
[2019-08-08 17:17:21,220] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,221] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,238] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,240] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 17:17:21,260] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,261] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 17:17:21,280] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,282] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 17:17:21,299] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 17:17:21,300] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-08-08 17:17:21,304] INFO Logs loading complete in 1786 ms. (kafka.log.LogManager)
[2019-08-08 17:17:21,312] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 17:17:21,313] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 17:17:21,510] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 17:17:21,537] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 17:17:21,554] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,555] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,555] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,563] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 17:17:21,616] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 17:17:21,620] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 17:17:21,622] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 17:17:21,670] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,673] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,674] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:17:21,695] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:21,696] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:21,697] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:21,709] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 17:17:21,732] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 17:17:21,735] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 17:17:21,735] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 17:17:21,767] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 17:17:21,787] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 17:17:21,790] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 17:17:21,790] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 17:17:21,791] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 17:17:21,842] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:multi cxid:0x7d zxid:0x31e txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:21,859] INFO Got user-level KeeperException when processing sessionid:0x10005432d980016 type:multi cxid:0x7f zxid:0x31f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:17:21,877] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, topic-4-9, topic-4-11, __consumer_offsets-9, __consumer_offsets-46, topic-4-6, topic-4-2, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, topic-4-10, topic-4-1, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-4-8, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, topic-4-3, __consumer_offsets-11, topic-4-7, topic-4-4, topic-4-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, topic-4-5, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:17:21,887] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,890] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,914] INFO Replica loaded for partition topic-4-9 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:21,915] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,915] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,915] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,915] INFO [Partition topic-4-9 broker=0] topic-4-9 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,932] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,933] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,948] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,948] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,962] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,962] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,974] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,974] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,987] INFO Replica loaded for partition topic-4-6 with initial high watermark 49 (kafka.cluster.Replica)
[2019-08-08 17:17:21,987] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,988] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,989] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,989] INFO [Partition topic-4-6 broker=0] topic-4-6 starts at Leader Epoch 5 from offset 49. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:21,991] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:21,992] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,004] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,005] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,017] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,018] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,030] INFO Replica loaded for partition topic-4-3 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-08 17:17:22,030] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,030] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,030] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,030] INFO [Partition topic-4-3 broker=0] topic-4-3 starts at Leader Epoch 6 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,033] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,033] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,046] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,047] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,061] INFO Replica loaded for partition topic-1-0 with initial high watermark 111 (kafka.cluster.Replica)
[2019-08-08 17:17:22,061] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 5 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,075] INFO Replica loaded for partition topic-4-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-08-08 17:17:22,075] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,075] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,075] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,075] INFO [Partition topic-4-0 broker=0] topic-4-0 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,087] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,088] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,101] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,101] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,116] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,116] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,129] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,129] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,144] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,144] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,156] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,157] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,168] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,168] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,181] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 49 (kafka.cluster.Replica)
[2019-08-08 17:17:22,181] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 5 from offset 49. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,183] INFO Replica loaded for partition topic-4-10 with initial high watermark 34 (kafka.cluster.Replica)
[2019-08-08 17:17:22,184] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,185] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,186] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,186] INFO [Partition topic-4-10 broker=0] topic-4-10 starts at Leader Epoch 5 from offset 34. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,189] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,189] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,202] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,202] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,213] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 17:17:22,213] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,214] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,215] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,215] INFO [Partition topic-4-7 broker=0] topic-4-7 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,227] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,227] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,239] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,239] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,250] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,250] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,262] INFO Replica loaded for partition topic-4-4 with initial high watermark 44 (kafka.cluster.Replica)
[2019-08-08 17:17:22,262] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,262] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,262] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,262] INFO [Partition topic-4-4 broker=0] topic-4-4 starts at Leader Epoch 7 from offset 44. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,265] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,265] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,277] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,277] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,289] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,289] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,300] INFO Replica loaded for partition topic-4-1 with initial high watermark 15 (kafka.cluster.Replica)
[2019-08-08 17:17:22,300] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,300] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,300] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,300] INFO [Partition topic-4-1 broker=0] topic-4-1 starts at Leader Epoch 5 from offset 15. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,303] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,305] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,307] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,307] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,323] INFO Replica loaded for partition topic-3-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-08 17:17:22,323] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,324] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 7 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,341] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,342] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,359] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,359] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,380] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,380] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,395] INFO Replica loaded for partition topic-4-8 with initial high watermark 27 (kafka.cluster.Replica)
[2019-08-08 17:17:22,395] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,395] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,395] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,396] INFO [Partition topic-4-8 broker=0] topic-4-8 starts at Leader Epoch 6 from offset 27. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,398] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,398] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,415] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,415] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,433] INFO Replica loaded for partition topic-4-5 with initial high watermark 75 (kafka.cluster.Replica)
[2019-08-08 17:17:22,434] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,434] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,434] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,434] INFO [Partition topic-4-5 broker=0] topic-4-5 starts at Leader Epoch 6 from offset 75. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,438] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,438] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,454] INFO Replica loaded for partition topic-4-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,455] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,455] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,455] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,455] INFO [Partition topic-4-2 broker=0] topic-4-2 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,473] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2644 (kafka.cluster.Replica)
[2019-08-08 17:17:22,473] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 5 from offset 2644. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,488] INFO Replica loaded for partition topic-3-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-08 17:17:22,488] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,488] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 5 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,507] INFO Replica loaded for partition topic-4-11 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,508] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,509] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,509] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,509] INFO [Partition topic-4-11 broker=0] topic-4-11 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,537] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,537] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,553] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,553] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,566] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,567] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,581] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,581] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,595] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,595] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,610] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,611] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,625] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,625] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,638] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,639] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,651] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,652] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,668] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,668] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,681] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,682] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,696] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,696] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,710] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,710] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,723] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:17:22,724] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,736] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,737] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,750] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:17:22,751] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 17:17:22,770] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,771] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,772] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,773] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,774] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,828] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:22,829] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 50 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,833] INFO [GroupCoordinator 0]: Loading group metadata for group-1 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:22,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,841] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,844] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,844] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,849] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,850] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,853] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,856] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-25012 with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:22,857] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,857] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,857] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,860] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,860] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,861] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,862] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,863] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,864] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,867] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:22,867] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:17:32,841] INFO [GroupCoordinator 0]: Member rdkafka-ebd91bc1-fb56-42bd-8ba7-b11f2c4a355e in group group-1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:32,844] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: removing member rdkafka-ebd91bc1-fb56-42bd-8ba7-b11f2c4a355e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:32,846] INFO [GroupCoordinator 0]: Group group-1 with generation 2 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:38,982] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 2 (__consumer_offsets-49) (reason: Adding new member rdkafka-e87b30a9-8404-4178-b65a-2bac3945c371) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:38,988] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 3 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:17:38,995] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:21:12,687] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 3 (__consumer_offsets-49) (reason: removing member rdkafka-e87b30a9-8404-4178-b65a-2bac3945c371 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:21:12,687] INFO [GroupCoordinator 0]: Group group-1 with generation 4 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:21:31,358] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 4 (__consumer_offsets-49) (reason: Adding new member rdkafka-a2471d7e-aba3-4b01-9881-eaf5876fb58c) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:21:31,359] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 5 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:21:31,361] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:27:21,688] INFO [GroupMetadataManager brokerId=0] Group console-consumer-25012 transitioned to Dead in generation 3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:27:21,691] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:32:18,050] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 5 (__consumer_offsets-49) (reason: removing member rdkafka-a2471d7e-aba3-4b01-9881-eaf5876fb58c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:32:18,050] INFO [GroupCoordinator 0]: Group group-1 with generation 6 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:37:21,686] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:40:33,035] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 17:40:33,342] INFO starting (kafka.server.KafkaServer)
[2019-08-08 17:40:33,343] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 17:40:33,360] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:40:33,370] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,370] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,373] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,374] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,374] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,375] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,376] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,376] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,376] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,377] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,378] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,379] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,379] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,380] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,382] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,384] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 17:40:33,402] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:40:33,404] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:40:33,407] INFO Accepted socket connection from /127.0.0.1:59202 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 17:40:33,407] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:40:33,411] INFO Client attempting to establish new session at /127.0.0.1:59202 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 17:40:33,423] INFO Established session 0x10005432d980017 with negotiated timeout 6000 for client /127.0.0.1:59202 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 17:40:33,424] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980017, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 17:40:33,428] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 17:40:33,467] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x1 zxid:0x321 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,477] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x2 zxid:0x322 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,480] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x3 zxid:0x323 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,482] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x4 zxid:0x324 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,485] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x5 zxid:0x325 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,488] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x6 zxid:0x326 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,492] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x7 zxid:0x327 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,494] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x8 zxid:0x328 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,496] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0x9 zxid:0x329 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,498] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0xa zxid:0x32a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,501] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0xb zxid:0x32b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,503] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0xc zxid:0x32c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,506] INFO Got user-level KeeperException when processing sessionid:0x10005432d980017 type:create cxid:0xd zxid:0x32d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 17:40:33,641] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 17:40:33,688] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 17:40:33,697] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 17:40:33,717] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:40:33,719] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:40:33,721] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 17:40:33,752] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 17:40:33,862] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:33,879] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:33,887] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 115 ms (kafka.log.Log)
[2019-08-08 17:40:33,937] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:33,942] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-1\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:33,943] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 35 ms (kafka.log.Log)
[2019-08-08 17:40:33,976] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 30 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:33,981] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-10\00000000000000000030.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:33,982] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 30 in 35 ms (kafka.log.Log)
[2019-08-08 17:40:34,024] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,029] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,030] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 44 ms (kafka.log.Log)
[2019-08-08 17:40:34,070] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,074] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,075] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 42 ms (kafka.log.Log)
[2019-08-08 17:40:34,108] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,112] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-3\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,113] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 34 ms (kafka.log.Log)
[2019-08-08 17:40:34,141] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,146] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-4\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,146] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 30 ms (kafka.log.Log)
[2019-08-08 17:40:34,176] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 63 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,180] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-5\00000000000000000063.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,181] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 63 in 32 ms (kafka.log.Log)
[2019-08-08 17:40:34,212] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 42 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,217] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-6\00000000000000000042.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,218] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 42 in 33 ms (kafka.log.Log)
[2019-08-08 17:40:34,248] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,253] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,254] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 33 ms (kafka.log.Log)
[2019-08-08 17:40:34,284] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,289] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-8\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,291] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 33 ms (kafka.log.Log)
[2019-08-08 17:40:34,318] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 17:40:34,323] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-9\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 17:40:34,324] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 32 ms (kafka.log.Log)
[2019-08-08 17:40:34,332] INFO Logs loading complete in 580 ms. (kafka.log.LogManager)
[2019-08-08 17:40:34,341] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 17:40:34,342] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 17:40:34,606] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2019-08-08 17:40:34,638] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 17:40:34,657] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,658] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,659] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,677] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 17:40:34,734] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 17:40:34,746] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 17:40:34,747] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 17:40:34,791] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,794] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,795] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 17:40:34,809] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:40:34,811] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:40:34,812] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:40:34,825] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 17:40:34,843] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 17:40:34,844] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 17:40:34,844] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 17:40:34,878] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 17:40:34,895] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 17:40:34,897] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 17:40:34,898] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 17:40:34,899] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-08-08 17:40:34,950] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,956] INFO Replica loaded for partition topic-4-9 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:40:34,956] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,957] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,959] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,962] INFO Replica loaded for partition topic-4-6 with initial high watermark 42 (kafka.cluster.Replica)
[2019-08-08 17:40:34,963] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,963] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,964] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,967] INFO Replica loaded for partition topic-4-3 with initial high watermark 10 (kafka.cluster.Replica)
[2019-08-08 17:40:34,967] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,968] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,973] INFO Replica loaded for partition topic-4-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-08-08 17:40:34,973] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,974] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,974] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,975] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,975] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,976] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,979] INFO Replica loaded for partition topic-4-10 with initial high watermark 30 (kafka.cluster.Replica)
[2019-08-08 17:40:34,979] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,980] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,980] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,984] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 17:40:34,986] INFO Replica loaded for partition topic-4-4 with initial high watermark 36 (kafka.cluster.Replica)
[2019-08-08 17:40:34,986] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,987] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,988] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,989] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,989] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,989] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,993] INFO Replica loaded for partition topic-4-1 with initial high watermark 11 (kafka.cluster.Replica)
[2019-08-08 17:40:34,996] INFO Replica loaded for partition topic-4-8 with initial high watermark 23 (kafka.cluster.Replica)
[2019-08-08 17:40:34,997] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,999] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:34,999] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,000] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,000] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,002] INFO Replica loaded for partition topic-4-5 with initial high watermark 63 (kafka.cluster.Replica)
[2019-08-08 17:40:35,003] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,006] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,006] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,009] INFO Replica loaded for partition topic-4-11 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:40:35,009] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,010] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,010] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,013] INFO Replica loaded for partition topic-4-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 17:40:35,013] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 17:40:35,015] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:40:35,046] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 17:40:35,049] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-4-9 -> (offset=3, leaderEpoch=5), topic-4-11 -> (offset=3, leaderEpoch=5), topic-4-6 -> (offset=42, leaderEpoch=5), topic-4-2 -> (offset=3, leaderEpoch=5), topic-4-10 -> (offset=30, leaderEpoch=5), topic-4-1 -> (offset=11, leaderEpoch=5), topic-4-8 -> (offset=23, leaderEpoch=6), topic-4-3 -> (offset=10, leaderEpoch=6), topic-4-7 -> (offset=1, leaderEpoch=6), topic-4-4 -> (offset=36, leaderEpoch=7), topic-4-0 -> (offset=4, leaderEpoch=8), topic-4-5 -> (offset=63, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:40:35,075] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 17:40:35,076] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 30 has no effect as the largest offset in the log is 29 (kafka.log.Log)
[2019-08-08 17:40:35,078] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 17:40:35,078] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Truncating to 23 has no effect as the largest offset in the log is 22 (kafka.log.Log)
[2019-08-08 17:40:35,079] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 17:40:35,079] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 42 has no effect as the largest offset in the log is 41 (kafka.log.Log)
[2019-08-08 17:40:35,080] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 63 has no effect as the largest offset in the log is 62 (kafka.log.Log)
[2019-08-08 17:40:35,080] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Truncating to 36 has no effect as the largest offset in the log is 35 (kafka.log.Log)
[2019-08-08 17:40:35,081] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-08-08 17:40:35,081] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 17:40:35,082] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-08-08 17:40:35,082] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-08-08 17:40:35,099] INFO [Partition topic-4-9 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,107] INFO [Partition topic-4-2 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,109] INFO [Partition topic-4-7 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,112] INFO [Partition topic-4-0 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,222] INFO [Partition topic-4-11 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,225] INFO [Partition topic-4-6 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,226] INFO [Partition topic-4-10 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,228] INFO [Partition topic-4-1 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,230] INFO [Partition topic-4-8 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,232] INFO [Partition topic-4-3 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,235] INFO [Partition topic-4-4 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:40:35,237] INFO [Partition topic-4-5 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-08 17:42:26,897] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:42:26,899] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:42:26,901] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 9 from offset 4. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-08 17:42:26,918] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 8 from offset 52. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 17:42:26,925] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 17:42:26,928] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-4 -> (offset=52, leaderEpoch=8), topic-4-0 -> (offset=4, leaderEpoch=9), topic-4-8 -> (offset=31, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 17:42:26,932] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 7 from offset 31. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 17:42:26,951] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 31 has no effect as the largest offset in the log is 30 (kafka.log.Log)
[2019-08-08 17:42:26,952] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 52 has no effect as the largest offset in the log is 51 (kafka.log.Log)
[2019-08-08 17:42:26,952] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-08-08 17:45:51,003] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=9, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 17:47:21,688] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:49:22,876] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 6 (__consumer_offsets-49) (reason: Adding new member rdkafka-1de1e67c-d70c-4a3c-a24c-bf19507e0482) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:49:22,878] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 7 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:49:22,880] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:16,996] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 7 (__consumer_offsets-49) (reason: removing member rdkafka-1de1e67c-d70c-4a3c-a24c-bf19507e0482 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:16,996] INFO [GroupCoordinator 0]: Group group-1 with generation 8 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:28,779] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 8 (__consumer_offsets-49) (reason: Adding new member rdkafka-62769b17-2c7d-47b0-8ea2-9fb00dd3523e) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:28,780] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 9 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:28,781] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:50:34,816] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:57:21,693] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 17:58:28,701] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 9 (__consumer_offsets-49) (reason: removing member rdkafka-62769b17-2c7d-47b0-8ea2-9fb00dd3523e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 17:58:28,702] INFO [GroupCoordinator 0]: Group group-1 with generation 10 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:00:34,819] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:07:21,695] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:10:31,667] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 10 (__consumer_offsets-49) (reason: Adding new member rdkafka-df92222a-2666-4bdd-9512-4e14c0e2f43d) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:10:31,669] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 11 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:10:31,672] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:10:34,821] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:10:51,684] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 11 (__consumer_offsets-49) (reason: removing member rdkafka-df92222a-2666-4bdd-9512-4e14c0e2f43d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:10:51,685] INFO [GroupCoordinator 0]: Group group-1 with generation 12 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:11:28,319] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 12 (__consumer_offsets-49) (reason: Adding new member rdkafka-37081b18-aca0-4761-87fb-7407dbca275d) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:11:28,320] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 13 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:11:28,322] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:17:21,696] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:20:34,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:22:04,983] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 13 (__consumer_offsets-49) (reason: removing member rdkafka-37081b18-aca0-4761-87fb-7407dbca275d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:22:04,984] INFO [GroupCoordinator 0]: Group group-1 with generation 14 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:22:29,250] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 14 (__consumer_offsets-49) (reason: Adding new member rdkafka-2a71908b-8eb1-4cdb-9710-cb25f82abbad) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:22:29,251] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 15 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:22:29,253] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:23:08,027] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 15 (__consumer_offsets-49) (reason: removing member rdkafka-2a71908b-8eb1-4cdb-9710-cb25f82abbad on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:23:08,027] INFO [GroupCoordinator 0]: Group group-1 with generation 16 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:23:30,249] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 16 (__consumer_offsets-49) (reason: Adding new member rdkafka-b93bc1fe-e61e-4da3-bf53-8066a03a6b85) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:23:30,250] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 17 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:23:30,252] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 17 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:24:09,387] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 17 (__consumer_offsets-49) (reason: removing member rdkafka-b93bc1fe-e61e-4da3-bf53-8066a03a6b85 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:24:09,387] INFO [GroupCoordinator 0]: Group group-1 with generation 18 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:24:44,240] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 18 (__consumer_offsets-49) (reason: Adding new member rdkafka-50988418-52f1-4be6-a09c-b6d1993990dc) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:24:44,241] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 19 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:24:44,244] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 19 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:27:21,696] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:30:34,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:37:21,698] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:40:34,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:46:41,644] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 19 (__consumer_offsets-49) (reason: Adding new member rdkafka-8c093142-bbd2-4ae1-8638-8ed547c4b882) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:46:41,989] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 20 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:46:41,991] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 20 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:46:58,001] INFO [GroupCoordinator 0]: Member rdkafka-8c093142-bbd2-4ae1-8638-8ed547c4b882 in group group-1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:46:58,001] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 20 (__consumer_offsets-49) (reason: removing member rdkafka-8c093142-bbd2-4ae1-8638-8ed547c4b882 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:47:00,005] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 21 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:47:00,008] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 21 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:47:21,697] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:50:34,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 18:51:41,644] INFO [GroupCoordinator 0]: Member rdkafka-8c093142-bbd2-4ae1-8638-8ed547c4b882 in group group-1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:51:41,645] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 21 (__consumer_offsets-49) (reason: removing member rdkafka-8c093142-bbd2-4ae1-8638-8ed547c4b882 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:51:42,178] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 22 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:51:42,182] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 22 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 18:57:21,699] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:00:34,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:07:21,698] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:10:34,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:17:21,699] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:20:34,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:27:21,698] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 19:30:34,824] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:44:17,510] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:61595-6 (kafka.network.Processor)
[2019-08-08 22:44:17,514] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=825227203, epoch=13099) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 22:44:17,884] WARN Client session timed out, have not heard from server in 11596767ms for sessionid 0x10005432d980016 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:17,884] WARN Client session timed out, have not heard from server in 11596767ms for sessionid 0x10005432d980017 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:17,607] INFO [GroupCoordinator 0]: Member rdkafka-50988418-52f1-4be6-a09c-b6d1993990dc in group group-1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:17,593] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9092-172.20.104.65:61596-16 (kafka.network.Processor)
[2019-08-08 22:44:17,593] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9092-172.20.104.65:59219-5 (kafka.network.Processor)
[2019-08-08 22:44:17,568] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=422066821, epoch=13324) to node 0: java.io.IOException: Connection to 0 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-08 22:44:18,834] INFO Expiring session 0x10005432d980016, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:19,908] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 22 (__consumer_offsets-49) (reason: removing member rdkafka-50988418-52f1-4be6-a09c-b6d1993990dc on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:19,648] INFO Client session timed out, have not heard from server in 11596767ms for sessionid 0x10005432d980016, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:17,510] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:59298-0 (kafka.network.Processor)
[2019-08-08 22:44:20,271] INFO Expiring session 0x10005432d980017, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:19,449] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=825227203, epoch=13099)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 22:44:20,365] INFO [GroupCoordinator 0]: Group group-1 with generation 23 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:20,394] WARN Unable to read additional data from client sessionid 0x10005432d980016, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:20,276] WARN [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=422066821, epoch=13324)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-08 22:44:20,586] INFO Processed session termination for sessionid: 0x10005432d980016 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:44:19,695] INFO Client session timed out, have not heard from server in 11596767ms for sessionid 0x10005432d980017, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:20,640] INFO Closed socket connection for client /127.0.0.1:58102 which had sessionid 0x10005432d980016 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:20,680] INFO Processed session termination for sessionid: 0x10005432d980017 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:44:21,224] WARN Exception causing close of session 0x10005432d980017: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:21,460] INFO Closed socket connection for client /127.0.0.1:59202 which had sessionid 0x10005432d980017 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:21,376] INFO Closed socket connection for client /127.0.0.1:59202 which had sessionid 0x10005432d980017 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:22,213] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,310] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64441 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:44:22,309] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,470] INFO Client attempting to renew session 0x10005432d980017 at /0:0:0:0:0:0:0:1:64441 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:22,495] INFO Invalid session 0x10005432d980017 for client /0:0:0:0:0:0:0:1:64441, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:22,496] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980017 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,750] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64441 which had sessionid 0x10005432d980017 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:22,746] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,758] INFO EventThread shut down for session: 0x10005432d980017 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,859] INFO Accepted socket connection from /127.0.0.1:64443 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:44:22,760] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:44:22,859] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,007] INFO Client attempting to renew session 0x10005432d980016 at /127.0.0.1:64443 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:23,028] INFO Invalid session 0x10005432d980016 for client /127.0.0.1:64443, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:23,035] INFO Closed socket connection for client /127.0.0.1:64443 which had sessionid 0x10005432d980016 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:22,760] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980017 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,029] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980016 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,032] INFO EventThread shut down for session: 0x10005432d980016 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,056] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980016 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:22,987] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:44:23,108] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:44:23,119] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:44:23,260] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,278] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,277] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64447 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:44:23,313] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64447 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:23,407] INFO Established session 0x10005432d980018 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64447 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:23,338] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:23,407] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980018, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:23,190] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:44:23,577] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:23,697] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:44:23,738] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:23,966] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:24,104] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:24,111] INFO Accepted socket connection from /127.0.0.1:64450 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:44:24,112] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:24,142] INFO Client attempting to establish new session at /127.0.0.1:64450 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:24,200] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980019, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:24,200] INFO Established session 0x10005432d980019 with negotiated timeout 6000 for client /127.0.0.1:64450 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:24,320] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:24,401] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:44:26,799] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 23 (__consumer_offsets-49) (reason: Adding new member rdkafka-428eb069-4afb-4a24-9f92-7c476aeb2a02) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:26,072] INFO Got user-level KeeperException when processing sessionid:0x10005432d980018 type:multi cxid:0xd7 zxid:0x351 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:44:26,719] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-3, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:44:26,928] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 24 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:28,501] WARN Client session timed out, have not heard from server in 4000ms for sessionid 0x10005432d980019 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:27,991] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs\log-start-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-08 22:44:29,981] INFO Client session timed out, have not heard from server in 4000ms for sessionid 0x10005432d980019, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:29,987] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-08 22:44:29,990] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 24 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:44:29,651] WARN Client session timed out, have not heard from server in 4001ms for sessionid 0x10005432d980018 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:29,972] INFO [Partition topic-4-9 broker=3] topic-4-9 starts at Leader Epoch 6 from offset 83. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:29,995] INFO Client session timed out, have not heard from server in 4001ms for sessionid 0x10005432d980018, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:29,992] ERROR Uncaught exception in scheduled task 'kafka-log-start-offset-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs\log-start-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-08 22:44:30,010] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, topic-4-9, topic-4-11, __consumer_offsets-9, __consumer_offsets-46, topic-4-6, topic-4-2, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, topic-4-10, topic-4-1, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-4-8, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, topic-4-3, __consumer_offsets-11, topic-4-7, topic-4-4, topic-4-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, topic-4-5, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:44:30,024] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, topic-4-9, topic-4-11, __consumer_offsets-9, __consumer_offsets-46, topic-4-6, topic-4-2, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, topic-4-10, topic-4-1, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-4-8, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, topic-4-3, __consumer_offsets-11, topic-4-7, topic-4-4, topic-4-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, topic-4-5, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 22:44:29,986] WARN Exception causing close of session 0x10005432d980019: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:30,064] INFO Closed socket connection for client /127.0.0.1:64450 which had sessionid 0x10005432d980019 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:30,071] WARN Exception causing close of session 0x10005432d980018: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:30,103] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64447 which had sessionid 0x10005432d980018 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:30,096] INFO [Partition topic-4-6 broker=3] topic-4-6 starts at Leader Epoch 6 from offset 97. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:30,113] ERROR Caught unexpected throwable (org.apache.zookeeper.ClientCnxn)
java.lang.NullPointerException
	at kafka.zookeeper.ZooKeeperClient$$anon$10.processResult(ZooKeeperClient.scala:234)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:633)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:508)
[2019-08-08 22:44:30,254] INFO [Partition topic-4-3 broker=3] topic-4-3 starts at Leader Epoch 7 from offset 136. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:44:30,335] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,topic-4-9,topic-4-11,__consumer_offsets-9,__consumer_offsets-46,topic-4-6,topic-4-2,topic-3-1,topic-2-0,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,topic-4-10,topic-4-1,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,topic-4-8,topic-3-0,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,topic-4-3,__consumer_offsets-11,topic-4-7,topic-4-4,topic-4-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,topic-1-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,topic-4-5,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-08 22:44:30,347] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-08 22:44:30,373] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-08 22:44:30,411] INFO [Partition topic-4-10 broker=3] topic-4-10 starts at Leader Epoch 6 from offset 88. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:30,438] INFO [Partition topic-4-7 broker=3] topic-4-7 starts at Leader Epoch 7 from offset 133. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:44:30,484] INFO [Partition topic-4-1 broker=3] topic-4-1 starts at Leader Epoch 6 from offset 132. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:30,534] INFO [Partition topic-4-5 broker=3] topic-4-5 starts at Leader Epoch 7 from offset 216. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:44:30,556] INFO [Partition topic-4-11 broker=3] topic-4-11 starts at Leader Epoch 6 from offset 64. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:30,600] INFO [Partition topic-4-2 broker=3] topic-4-2 starts at Leader Epoch 6 from offset 258. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-08 22:44:30,622] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:44:30,627] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:44:30,627] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:44:31,366] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:31,428] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64469 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:44:31,466] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:31,488] INFO Client attempting to renew session 0x10005432d980018 at /0:0:0:0:0:0:0:1:64469 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:31,518] INFO Established session 0x10005432d980018 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:64469 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:31,519] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980018, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:44:34,023] INFO Expiring session 0x10005432d980019, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:34,045] INFO Processed session termination for sessionid: 0x10005432d980019 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:44:34,970] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs-3\log-start-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-3\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-3\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-08 22:44:35,059] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\kafka-logs-3 (kafka.server.ReplicaManager)
[2019-08-08 22:44:35,061] ERROR Uncaught exception in scheduled task 'kafka-log-start-offset-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs-3\log-start-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-3\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-3\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-08 22:44:35,077] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:44:35,120] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-08 22:44:35,182] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions topic-4-9,topic-4-11,topic-4-6,topic-4-2,topic-4-10,topic-4-1,topic-4-8,topic-4-3,topic-4-7,topic-4-4,topic-4-0,topic-4-5 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-3. (kafka.server.ReplicaManager)
[2019-08-08 22:44:35,205] INFO Stopping serving logs in dir C:\tmp\kafka-logs-3 (kafka.log.LogManager)
[2019-08-08 22:44:35,233] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-3 have failed (kafka.log.LogManager)
[2019-08-08 22:44:36,309] WARN Exception causing close of session 0x10005432d980018: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:36,323] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64469 which had sessionid 0x10005432d980018 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:44:40,035] INFO Expiring session 0x10005432d980018, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:44:40,049] INFO Processed session termination for sessionid: 0x10005432d980018 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:19,140] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55103 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:46:19,142] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55103 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:19,152] INFO Established session 0x10005432d98001a with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:55103 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:19,201] INFO Processed session termination for sessionid: 0x10005432d98001a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:19,202] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55103 which had sessionid 0x10005432d98001a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:46:43,130] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 22:46:43,519] INFO starting (kafka.server.KafkaServer)
[2019-08-08 22:46:43,520] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 22:46:43,540] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:48,062] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,062] INFO Client environment:host.name=W101GKNGH2.blr.amer.dell.com (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,063] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,063] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,063] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,064] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,064] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,065] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,066] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,066] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,067] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:48,091] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:48,092] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:48,094] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55120 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:46:48,095] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:48,097] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55120 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:48,108] INFO Established session 0x10005432d98001b with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:55120 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:48,109] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d98001b, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:48,112] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:48,165] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x1 zxid:0x357 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,177] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x2 zxid:0x358 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,180] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x3 zxid:0x359 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,182] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x4 zxid:0x35a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,185] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x5 zxid:0x35b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,188] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x6 zxid:0x35c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,190] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x7 zxid:0x35d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,192] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x8 zxid:0x35e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,193] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0x9 zxid:0x35f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,195] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0xa zxid:0x360 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,198] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0xb zxid:0x361 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,207] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0xc zxid:0x362 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,209] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:create cxid:0xd zxid:0x363 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:48,373] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 22:46:48,416] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:46:48,423] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:46:48,445] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:48,445] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:48,447] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:48,479] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 22:46:48,532] WARN [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-1-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-1-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565180185902}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:48,533] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,601] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,607] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:48,607] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,653] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,701] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,706] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,714] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 211 ms (kafka.log.Log)
[2019-08-08 22:46:48,728] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:48,728] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,771] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,776] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:48,786] WARN [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-3-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-3-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565243146720}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:48,786] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,825] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,828] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:48,828] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,870] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,895] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,899] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,904] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 126 ms (kafka.log.Log)
[2019-08-08 22:46:48,920] WARN [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565243088233}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:48,920] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,956] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:48,958] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:48,958] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:48,997] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,021] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,024] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,028] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 121 ms (kafka.log.Log)
[2019-08-08 22:46:49,061] WARN [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565250148695}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,061] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,103] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,105] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,106] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,150] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,169] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 134 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,173] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-0\00000000000000000134.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,176] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 134 in 146 ms (kafka.log.Log)
[2019-08-08 22:46:49,212] WARN [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249674064}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,212] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,259] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,262] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,262] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,314] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,337] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,340] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-1\00000000000000000132.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,345] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 132 in 167 ms (kafka.log.Log)
[2019-08-08 22:46:49,356] WARN [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249370714}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,356] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,396] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,399] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,400] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,448] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,469] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 88 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,472] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-10\00000000000000000088.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,476] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 88 in 128 ms (kafka.log.Log)
[2019-08-08 22:46:49,487] WARN [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249671951}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,487] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,529] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,532] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,532] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,576] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,595] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 64 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,600] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-11\00000000000000000064.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,605] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 64 in 126 ms (kafka.log.Log)
[2019-08-08 22:46:49,644] WARN [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249670316}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,644] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,690] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,692] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,693] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,743] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,771] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 258 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,775] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-2\00000000000000000258.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,778] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 258 in 170 ms (kafka.log.Log)
[2019-08-08 22:46:49,812] WARN [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249676514}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,812] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,855] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,857] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:49,858] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,904] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,930] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 136 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:49,936] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-3\00000000000000000136.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:49,940] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 136 in 159 ms (kafka.log.Log)
[2019-08-08 22:46:49,978] WARN [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-4\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-4\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249673300}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:49,979] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,043] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,047] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,047] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,112] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,136] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 502 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,140] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-4\00000000000000000502.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,145] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 502 in 202 ms (kafka.log.Log)
[2019-08-08 22:46:50,187] WARN [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565250153351}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:50,187] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,246] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,250] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,251] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,303] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,327] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 216 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,331] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-5\00000000000000000216.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,335] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 216 in 186 ms (kafka.log.Log)
[2019-08-08 22:46:50,346] WARN [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-6\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-6\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249675053}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:50,346] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,389] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,392] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,393] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,444] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,467] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 97 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,471] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-6\00000000000000000097.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,475] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 97 in 137 ms (kafka.log.Log)
[2019-08-08 22:46:50,512] WARN [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249675776}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:50,513] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,557] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,560] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,560] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,612] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,637] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 133 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,642] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-7\00000000000000000133.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,646] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 133 in 169 ms (kafka.log.Log)
[2019-08-08 22:46:50,659] WARN [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249663864}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:50,659] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,706] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,709] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,710] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,762] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,785] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 66 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,789] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-8\00000000000000000066.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,793] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 66 in 145 ms (kafka.log.Log)
[2019-08-08 22:46:50,809] WARN [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-9\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-9\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249671195}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:50,809] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,855] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,858] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,859] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,906] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,927] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 83 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:50,931] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-9\00000000000000000083.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:50,937] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 83 in 142 ms (kafka.log.Log)
[2019-08-08 22:46:50,960] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:50,961] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,018] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,024] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 84 ms (kafka.log.Log)
[2019-08-08 22:46:51,036] WARN [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853503}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:51,036] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,084] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:51,087] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,088] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,132] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:51,163] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,170] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:51,176] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 150 ms (kafka.log.Log)
[2019-08-08 22:46:51,187] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,187] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,236] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,242] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-08-08 22:46:51,253] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,253] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,303] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,308] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 22:46:51,319] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,319] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,371] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,377] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-08 22:46:51,389] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,389] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,442] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,447] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-08 22:46:51,458] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,458] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,521] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,527] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-08-08 22:46:51,540] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,540] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,586] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 22:46:51,593] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,599] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-08 22:46:51,611] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,612] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,666] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,671] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-08 22:46:51,683] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,683] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,735] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,740] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 22:46:51,754] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,754] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,811] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,817] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-08-08 22:46:51,828] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,828] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,884] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,888] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-08 22:46:51,902] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,903] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,952] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:51,957] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-08 22:46:51,968] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:51,968] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,014] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,019] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-08-08 22:46:52,028] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565243061970}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:52,028] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,055] INFO starting (kafka.server.KafkaServer)
[2019-08-08 22:46:52,056] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 22:46:52,071] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,074] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,074] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,076] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:52,120] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,143] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,149] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,157] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 137 ms (kafka.log.Log)
[2019-08-08 22:46:52,176] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,177] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,264] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,268] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 108 ms (kafka.log.Log)
[2019-08-08 22:46:52,277] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,277] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,322] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,326] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:52,336] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,336] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,380] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,385] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-08-08 22:46:52,393] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,393] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,444] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,449] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-08 22:46:52,459] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,459] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,507] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,510] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 22:46:52,519] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,519] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,563] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,567] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:52,574] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,574] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,618] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,622] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-08-08 22:46:52,629] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,630] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,671] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,675] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-08-08 22:46:52,682] WARN [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853503}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:52,682] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,719] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,722] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,722] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,763] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,794] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,797] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,802] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 126 ms (kafka.log.Log)
[2019-08-08 22:46:52,816] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,816] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,869] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,873] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-08 22:46:52,883] WARN [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565248895721}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:52,884] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:52,944] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2644 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:52,947] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:52,948] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,012] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2644 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,038] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 2644 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,043] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000002644.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,047] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2644 in 173 ms (kafka.log.Log)
[2019-08-08 22:46:53,059] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565238310737}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:53,059] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,107] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,112] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,112] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,154] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,179] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,183] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,187] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 138 ms (kafka.log.Log)
[2019-08-08 22:46:53,195] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,195] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,241] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,245] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-08-08 22:46:53,254] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,254] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,302] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,307] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-08 22:46:53,315] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,316] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,361] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,365] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-08-08 22:46:53,374] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,374] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,419] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,423] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:53,431] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,431] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,476] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,480] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:53,488] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,488] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,529] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,533] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-08-08 22:46:53,541] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853499}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:53,541] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,576] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,579] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,579] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,620] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,646] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,650] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,653] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 119 ms (kafka.log.Log)
[2019-08-08 22:46:53,661] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,661] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,711] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,716] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-08 22:46:53,724] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,724] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,766] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,770] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-08-08 22:46:53,782] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,782] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,824] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,828] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-08-08 22:46:53,836] WARN [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249253502}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:53,837] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,872] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,875] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,875] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,914] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,942] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:53,945] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:53,949] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 120 ms (kafka.log.Log)
[2019-08-08 22:46:53,957] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:53,957] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,000] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,004] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-08-08 22:46:54,012] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,013] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,059] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,064] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 22:46:54,073] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,073] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,114] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,119] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-08-08 22:46:54,127] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,127] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,170] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,174] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-08-08 22:46:54,182] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,182] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,225] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,229] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-08-08 22:46:54,238] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,238] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,285] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,289] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 22:46:54,319] WARN [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262170354}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:46:54,320] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,356] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 164 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:54,358] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,358] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,405] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 164 (kafka.log.ProducerStateManager)
[2019-08-08 22:46:54,427] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 164 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,431] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000164.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:54,435] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 164 in 145 ms (kafka.log.Log)
[2019-08-08 22:46:54,442] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,443] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,487] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,492] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-08-08 22:46:54,506] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,506] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,547] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,552] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-08 22:46:54,559] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,560] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,604] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,608] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-08-08 22:46:54,616] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,616] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,669] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,673] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-08 22:46:54,681] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:46:54,681] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,727] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:54,732] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-08-08 22:46:54,734] INFO Logs loading complete in 6255 ms. (kafka.log.LogManager)
[2019-08-08 22:46:54,743] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 22:46:54,743] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 22:46:54,967] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-08 22:46:55,011] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 22:46:55,036] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:55,038] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:55,038] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:55,050] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 22:46:56,788] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,789] INFO Client environment:host.name=W101GKNGH2.blr.amer.dell.com (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,790] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,790] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,791] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,791] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,793] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,793] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,793] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,794] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,794] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,795] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,795] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,796] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,796] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,798] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:46:56,825] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:56,827] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:56,830] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55140 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:46:56,830] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:56,833] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55140 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:56,843] INFO Established session 0x10005432d98001c with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:55140 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:46:56,846] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d98001c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:46:56,851] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:46:56,911] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x1 zxid:0x365 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,922] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x2 zxid:0x366 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,923] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x3 zxid:0x367 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,925] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x4 zxid:0x368 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,927] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x5 zxid:0x369 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,930] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x6 zxid:0x36a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,934] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x7 zxid:0x36b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,936] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x8 zxid:0x36c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,938] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0x9 zxid:0x36d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,941] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0xa zxid:0x36e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,943] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0xb zxid:0x36f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,945] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0xc zxid:0x370 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:56,947] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001c type:create cxid:0xd zxid:0x371 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:57,118] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 22:46:57,179] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:46:57,188] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:46:57,212] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:57,212] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:57,214] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:46:57,254] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 22:46:57,365] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,381] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,402] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 126 ms (kafka.log.Log)
[2019-08-08 22:46:57,446] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,450] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,451] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 42 ms (kafka.log.Log)
[2019-08-08 22:46:57,479] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,483] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,483] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 29 ms (kafka.log.Log)
[2019-08-08 22:46:57,515] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,520] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,522] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 36 ms (kafka.log.Log)
[2019-08-08 22:46:57,554] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,559] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-10\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,560] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 35 ms (kafka.log.Log)
[2019-08-08 22:46:57,592] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,596] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-11\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,597] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 34 ms (kafka.log.Log)
[2019-08-08 22:46:57,626] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,630] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,631] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-08-08 22:46:57,657] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,662] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-3\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,662] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 29 ms (kafka.log.Log)
[2019-08-08 22:46:57,691] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 28 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,695] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-4\00000000000000000028.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,696] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 28 in 31 ms (kafka.log.Log)
[2019-08-08 22:46:57,731] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 51 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,735] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-5\00000000000000000051.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,736] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 51 in 37 ms (kafka.log.Log)
[2019-08-08 22:46:57,767] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 34 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,771] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-6\00000000000000000034.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,772] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 34 in 33 ms (kafka.log.Log)
[2019-08-08 22:46:57,807] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,811] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,811] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 37 ms (kafka.log.Log)
[2019-08-08 22:46:57,839] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 19 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,842] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-8\00000000000000000019.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,843] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 19 in 30 ms (kafka.log.Log)
[2019-08-08 22:46:57,873] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-08 22:46:57,877] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-9\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:46:57,878] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 34 ms (kafka.log.Log)
[2019-08-08 22:46:57,883] INFO Logs loading complete in 628 ms. (kafka.log.LogManager)
[2019-08-08 22:46:57,894] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 22:46:57,895] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 22:46:58,141] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-08-08 22:46:58,177] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 22:46:58,196] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:58,196] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:58,199] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:58,207] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 22:46:59,622] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:46:59,634] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:46:59,635] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:46:59,675] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:59,678] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:59,679] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:46:59,700] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:46:59,701] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:46:59,703] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:46:59,716] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 22:46:59,742] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:46:59,745] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:46:59,746] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 22:46:59,793] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 22:46:59,821] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 22:46:59,825] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:46:59,826] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:46:59,828] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-08 22:46:59,866] ERROR [KafkaApi-0] Number of alive brokers '0' does not meet the required replication factor '1' for the offsets topic (configured via 'offsets.topic.replication.factor'). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)
[2019-08-08 22:46:59,958] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:46:59,975] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-08-08 22:46:59,977] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:multi cxid:0x96 zxid:0x378 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:46:59,981] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:46:59,984] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:46:59,990] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001b type:multi cxid:0x98 zxid:0x379 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:47:00,037] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,038] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,059] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-08-08 22:47:00,059] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,062] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,083] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,083] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,103] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,105] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,130] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,131] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,156] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-08-08 22:47:00,156] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,158] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,190] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-08-08 22:47:00,190] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,195] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,222] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-08-08 22:47:00,222] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,225] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,246] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-08-08 22:47:00,260] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,260] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,280] INFO [Partition topic-1-0 broker=0] No checkpointed highwatermark is found for partition topic-1-0 (kafka.cluster.Partition)
[2019-08-08 22:47:00,281] INFO Replica loaded for partition topic-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,282] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 5 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,302] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 22:47:00,302] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,321] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-08-08 22:47:00,321] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,322] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,338] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-08-08 22:47:00,338] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,340] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,356] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-08-08 22:47:00,356] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,357] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,374] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-08-08 22:47:00,374] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,379] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,398] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-08-08 22:47:00,409] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,409] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,448] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-08-08 22:47:00,487] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,488] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,515] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-08-08 22:47:00,516] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,519] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 5 from offset 164. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,524] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-08-08 22:47:00,524] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,524] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,543] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-08-08 22:47:00,544] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,545] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,561] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-08-08 22:47:00,561] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,562] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,578] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-08-08 22:47:00,578] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,580] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,595] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-08-08 22:47:00,596] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,596] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,614] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-08-08 22:47:00,614] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,616] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,632] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-08-08 22:47:00,632] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,632] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,647] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,647] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,662] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-08-08 22:47:00,663] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,663] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 5 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,668] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-08-08 22:47:00,669] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,669] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,682] INFO [Partition topic-3-0 broker=0] No checkpointed highwatermark is found for partition topic-3-0 (kafka.cluster.Partition)
[2019-08-08 22:47:00,682] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,683] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,683] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 7 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,701] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,701] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,718] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-08-08 22:47:00,718] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,718] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,741] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-08-08 22:47:00,741] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,742] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,757] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,758] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,773] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-08-08 22:47:00,773] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,774] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,789] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-08-08 22:47:00,789] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,790] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,803] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-08-08 22:47:00,803] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,804] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 5 from offset 2644. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,807] INFO [Partition topic-3-1 broker=0] No checkpointed highwatermark is found for partition topic-3-1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,808] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,808] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,808] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 5 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,824] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-08-08 22:47:00,824] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,824] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,837] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-08-08 22:47:00,837] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,838] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,853] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-08-08 22:47:00,853] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,853] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,874] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-08-08 22:47:00,874] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,876] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,893] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-08-08 22:47:00,893] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,893] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,911] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-08-08 22:47:00,911] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,913] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,931] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-08-08 22:47:00,931] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,931] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,947] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-08-08 22:47:00,947] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,948] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,964] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-08-08 22:47:00,964] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,965] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,981] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-08-08 22:47:00,981] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,982] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:00,996] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-08-08 22:47:00,996] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:00,996] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,014] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-08-08 22:47:01,014] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,015] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,028] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 22:47:01,028] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,042] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-08-08 22:47:01,043] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,044] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 5 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,057] INFO [Partition topic-2-0 broker=0] No checkpointed highwatermark is found for partition topic-2-0 (kafka.cluster.Partition)
[2019-08-08 22:47:01,057] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,057] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,070] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-08-08 22:47:01,070] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,071] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,089] INFO [Partition topic-4-9 broker=0] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-08 22:47:01,089] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,092] INFO [Partition topic-4-6 broker=0] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-08 22:47:01,092] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,095] INFO [Partition topic-4-3 broker=0] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-08 22:47:01,095] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,098] INFO [Partition topic-4-0 broker=0] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-08 22:47:01,098] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,100] INFO [Partition topic-4-10 broker=0] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-08 22:47:01,101] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,103] INFO [Partition topic-4-7 broker=0] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-08 22:47:01,103] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,105] INFO [Partition topic-4-4 broker=0] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-08 22:47:01,105] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,107] INFO [Partition topic-4-1 broker=0] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,107] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,109] INFO [Partition topic-4-8 broker=0] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-08 22:47:01,111] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,114] INFO Replica loaded for partition topic-4-5 with initial high watermark 216 (kafka.cluster.Replica)
[2019-08-08 22:47:01,116] INFO [Partition topic-4-2 broker=0] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-08 22:47:01,116] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,118] INFO [Partition topic-4-11 broker=0] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-08 22:47:01,119] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,119] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:01,130] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,132] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,132] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,133] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,139] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,139] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,139] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,139] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,139] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,140] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,142] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,142] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,144] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,146] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,160] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:01,161] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,161] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,161] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,162] INFO [Partition topic-4-0 broker=0] topic-4-0 starts at Leader Epoch 10 from offset 134. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,218] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:47:01,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 72 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,221] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,226] INFO [GroupCoordinator 0]: Loading group metadata for group-1 with generation 24 (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:47:01,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,233] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,238] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,239] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,240] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,242] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,243] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,243] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,243] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,243] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,248] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,252] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,253] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,253] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,253] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,253] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,254] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,257] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,258] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,262] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,268] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,268] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,268] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:01,418] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,418] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,420] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,420] INFO [Partition topic-4-4 broker=0] topic-4-4 starts at Leader Epoch 9 from offset 502. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:01,432] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,432] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,432] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:01,433] INFO [Partition topic-4-8 broker=0] topic-4-8 starts at Leader Epoch 8 from offset 66. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:47:02,766] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:47:02,777] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:47:02,779] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:47:02,847] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:47:02,851] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:47:02,852] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:47:02,870] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:47:02,871] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:47:02,873] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:47:02,885] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:12000,blockEndProducerId:12999) by writing to Zk with path version 13 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 22:47:02,909] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:47:02,913] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 22:47:02,913] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:47:02,976] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 22:47:02,996] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 22:47:02,999] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:47:03,000] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:47:03,002] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-08-08 22:47:03,061] INFO Replica loaded for partition topic-4-9 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 22:47:03,065] INFO Replica loaded for partition topic-4-6 with initial high watermark 34 (kafka.cluster.Replica)
[2019-08-08 22:47:03,068] INFO Replica loaded for partition topic-4-3 with initial high watermark 9 (kafka.cluster.Replica)
[2019-08-08 22:47:03,070] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,070] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,074] INFO Replica loaded for partition topic-4-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-08-08 22:47:03,074] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,080] INFO Replica loaded for partition topic-4-10 with initial high watermark 24 (kafka.cluster.Replica)
[2019-08-08 22:47:03,083] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:47:03,084] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,087] INFO Replica loaded for partition topic-4-4 with initial high watermark 28 (kafka.cluster.Replica)
[2019-08-08 22:47:03,087] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,088] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,091] INFO Replica loaded for partition topic-4-1 with initial high watermark 10 (kafka.cluster.Replica)
[2019-08-08 22:47:03,094] INFO Replica loaded for partition topic-3-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-08 22:47:03,095] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,096] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,096] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,097] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,100] INFO Replica loaded for partition topic-4-8 with initial high watermark 19 (kafka.cluster.Replica)
[2019-08-08 22:47:03,103] INFO Replica loaded for partition topic-4-5 with initial high watermark 51 (kafka.cluster.Replica)
[2019-08-08 22:47:03,106] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:47:03,109] INFO Replica loaded for partition topic-3-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-08 22:47:03,113] INFO Replica loaded for partition topic-4-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 22:47:03,116] INFO Replica loaded for partition topic-4-11 with initial high watermark 3 (kafka.cluster.Replica)
[2019-08-08 22:47:03,118] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0, topic-4-4, topic-4-0, topic-4-8, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:03,152] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:47:03,159] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-3-1 -> (offset=7, leaderEpoch=5), topic-4-8 -> (offset=19, leaderEpoch=8), topic-3-0 -> (offset=6, leaderEpoch=7), topic-4-4 -> (offset=28, leaderEpoch=9), topic-4-0 -> (offset=4, leaderEpoch=10)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:03,199] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 19 has no effect as the largest offset in the log is 18 (kafka.log.Log)
[2019-08-08 22:47:03,201] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 28 has no effect as the largest offset in the log is 27 (kafka.log.Log)
[2019-08-08 22:47:03,202] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-08 22:47:03,203] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-08 22:47:03,203] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-08-08 22:47:03,240] INFO [Partition topic-3-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 22:47:03,251] INFO [Partition topic-3-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 22:47:03,405] INFO [Partition topic-4-8 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 22:47:03,407] INFO [Partition topic-4-4 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 22:47:03,410] INFO [Partition topic-4-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-08 22:47:05,020] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:05,021] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-3-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:05,025] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 8 from offset 6. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:47:05,041] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:47:05,044] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-3-0 -> (offset=6, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:47:05,060] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-08 22:47:56,118] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55200 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:47:56,122] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55200 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:47:56,132] INFO Established session 0x10005432d98001d with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:55200 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:47:56,364] INFO Processed session termination for sessionid: 0x10005432d98001d (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:47:56,367] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55200 which had sessionid 0x10005432d98001d (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:48:01,394] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 22:48:01,748] INFO starting (kafka.server.KafkaServer)
[2019-08-08 22:48:01,749] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 22:48:01,765] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:48:06,435] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,435] INFO Client environment:host.name=W101GKNGH2.blr.amer.dell.com (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,437] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,437] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,438] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,438] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,439] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,440] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,440] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,440] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,441] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,441] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,441] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,442] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,442] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,443] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:48:06,464] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:48:06,464] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:48:06,467] INFO Accepted socket connection from /127.0.0.1:55207 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:48:06,468] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:48:06,470] INFO Client attempting to establish new session at /127.0.0.1:55207 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:06,480] INFO Established session 0x10005432d98001e with negotiated timeout 6000 for client /127.0.0.1:55207 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:06,482] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98001e, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:48:06,487] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:48:06,532] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x1 zxid:0x387 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,542] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x2 zxid:0x388 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,545] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x3 zxid:0x389 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,546] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x4 zxid:0x38a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,548] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x5 zxid:0x38b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,550] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x6 zxid:0x38c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,552] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x7 zxid:0x38d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,555] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x8 zxid:0x38e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,557] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0x9 zxid:0x38f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,559] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0xa zxid:0x390 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,560] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0xb zxid:0x391 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,563] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0xc zxid:0x392 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,566] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001e type:create cxid:0xd zxid:0x393 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:06,712] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 22:48:06,753] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:48:06,761] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:48:06,784] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:48:06,784] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:48:06,786] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:48:06,818] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 22:48:06,891] WARN [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:06,891] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:06,970] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:06,976] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:06,976] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,024] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,065] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 134 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,069] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-0\00000000000000000134.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,078] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 134 in 241 ms (kafka.log.Log)
[2019-08-08 22:48:07,112] WARN [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,112] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,153] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,155] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,156] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,203] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,233] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,237] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-1\00000000000000000132.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,240] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 132 in 156 ms (kafka.log.Log)
[2019-08-08 22:48:07,251] WARN [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262091467}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,251] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,292] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,295] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,295] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,343] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,372] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 88 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,376] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-10\00000000000000000088.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,380] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 88 in 137 ms (kafka.log.Log)
[2019-08-08 22:48:07,390] WARN [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,391] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,431] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,434] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,434] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,475] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,505] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 64 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,509] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-11\00000000000000000064.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,513] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 64 in 130 ms (kafka.log.Log)
[2019-08-08 22:48:07,551] WARN [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,551] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,599] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,602] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,602] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,656] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,685] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 258 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,689] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-2\00000000000000000258.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,692] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 258 in 176 ms (kafka.log.Log)
[2019-08-08 22:48:07,725] WARN [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,726] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,767] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,770] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,770] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,818] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,844] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 136 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,848] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-3\00000000000000000136.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,852] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 136 in 157 ms (kafka.log.Log)
[2019-08-08 22:48:07,884] WARN [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-4\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-4\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:07,884] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,926] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,929] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:07,929] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:07,978] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:07,998] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 502 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,003] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-4\00000000000000000502.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,006] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 502 in 151 ms (kafka.log.Log)
[2019-08-08 22:48:08,039] WARN [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:08,039] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,077] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,080] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:08,080] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,124] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,155] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 216 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,159] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-5\00000000000000000216.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,163] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 216 in 155 ms (kafka.log.Log)
[2019-08-08 22:48:08,175] WARN [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-6\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-6\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:08,176] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,215] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,217] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:08,218] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,259] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,286] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 97 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,290] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-6\00000000000000000097.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,293] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 97 in 127 ms (kafka.log.Log)
[2019-08-08 22:48:08,326] WARN [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249675776}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:08,326] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,364] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,366] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:08,367] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,408] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,435] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 133 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,439] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-7\00000000000000000133.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,443] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 133 in 147 ms (kafka.log.Log)
[2019-08-08 22:48:08,453] WARN [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262123303}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:08,453] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,489] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,492] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:08,492] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,538] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,556] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 66 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,560] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-8\00000000000000000066.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,564] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 66 in 119 ms (kafka.log.Log)
[2019-08-08 22:48:08,573] WARN [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-9\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-9\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-08 22:48:08,573] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,610] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,612] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:48:08,613] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,654] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,680] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 83 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:08,684] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-9\00000000000000000083.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:48:08,688] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 83 in 122 ms (kafka.log.Log)
[2019-08-08 22:48:08,691] INFO Logs loading complete in 1873 ms. (kafka.log.LogManager)
[2019-08-08 22:48:08,703] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 22:48:08,704] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 22:48:08,944] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2019-08-08 22:48:08,978] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 22:48:08,994] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:08,996] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:08,996] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:09,008] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 22:48:13,575] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:48:13,586] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:48:13,588] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:48:13,618] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,620] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,620] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,621] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,622] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,622] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,623] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,623] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,623] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,624] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,625] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,625] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,625] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,625] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,625] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,626] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,627] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,627] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,628] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:13,623] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,631] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,634] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,635] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,636] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,637] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-9 -> (offset=0, leaderEpoch=7), topic-4-11 -> (offset=0, leaderEpoch=7), topic-4-6 -> (offset=0, leaderEpoch=7), topic-4-2 -> (offset=0, leaderEpoch=7), topic-4-10 -> (offset=0, leaderEpoch=7), topic-4-1 -> (offset=0, leaderEpoch=7), topic-4-3 -> (offset=0, leaderEpoch=8), topic-4-7 -> (offset=0, leaderEpoch=8), topic-4-5 -> (offset=216, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:13,637] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,638] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,638] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,639] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,639] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,642] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,644] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,649] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,651] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,651] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,651] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,652] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,653] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,653] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,654] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,655] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,656] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,656] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,657] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,662] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,663] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:13,680] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-9 -> (offset=3, leaderEpoch=7), topic-4-11 -> (offset=3, leaderEpoch=7), topic-4-6 -> (offset=34, leaderEpoch=7), topic-4-2 -> (offset=3, leaderEpoch=7), topic-4-10 -> (offset=24, leaderEpoch=7), topic-4-1 -> (offset=10, leaderEpoch=7), topic-4-3 -> (offset=9, leaderEpoch=8), topic-4-7 -> (offset=1, leaderEpoch=8), topic-4-5 -> (offset=51, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:13,679] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:13,679] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:13,685] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,679] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:48:13,709] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:48:13,712] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:48:13,718] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:48:13,745] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:13000,blockEndProducerId:13999) by writing to Zk with path version 14 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 22:48:13,786] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:48:13,794] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:48:13,802] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 22:48:13,869] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 22:48:13,892] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 22:48:13,895] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:48:13,895] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:48:13,897] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-08-08 22:48:13,931] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-11 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,933] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,935] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-9 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,931] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-11 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,935] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-7 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,936] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-6 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,936] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-5 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,936] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-3 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,937] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,937] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-1 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,936] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,939] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-9 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,940] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-7 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,940] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-6 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,941] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-5 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,942] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-3 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,944] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,947] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-1 as the leader reported an error: UNKNOWN_TOPIC_OR_PARTITION (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:13,964] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-3, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:13,979] INFO Replica loaded for partition topic-4-9 with initial high watermark 83 (kafka.cluster.Replica)
[2019-08-08 22:48:13,983] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,984] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,987] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:13,989] INFO [Partition topic-4-9 broker=3] topic-4-9 starts at Leader Epoch 6 from offset 83. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,040] INFO Replica loaded for partition topic-4-6 with initial high watermark 97 (kafka.cluster.Replica)
[2019-08-08 22:48:14,042] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,043] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,044] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,045] INFO [Partition topic-4-6 broker=3] topic-4-6 starts at Leader Epoch 6 from offset 97. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,067] INFO Replica loaded for partition topic-4-3 with initial high watermark 136 (kafka.cluster.Replica)
[2019-08-08 22:48:14,069] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,071] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,071] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,072] INFO [Partition topic-4-3 broker=3] topic-4-3 starts at Leader Epoch 7 from offset 136. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,090] INFO Replica loaded for partition topic-4-10 with initial high watermark 88 (kafka.cluster.Replica)
[2019-08-08 22:48:14,091] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,093] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,093] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,094] INFO [Partition topic-4-10 broker=3] topic-4-10 starts at Leader Epoch 6 from offset 88. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,110] INFO Replica loaded for partition topic-4-7 with initial high watermark 133 (kafka.cluster.Replica)
[2019-08-08 22:48:14,110] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,111] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,113] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,114] INFO [Partition topic-4-7 broker=3] topic-4-7 starts at Leader Epoch 7 from offset 133. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,131] INFO Replica loaded for partition topic-4-1 with initial high watermark 132 (kafka.cluster.Replica)
[2019-08-08 22:48:14,131] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,132] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,135] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,136] INFO [Partition topic-4-1 broker=3] topic-4-1 starts at Leader Epoch 6 from offset 132. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,155] INFO Replica loaded for partition topic-4-5 with initial high watermark 216 (kafka.cluster.Replica)
[2019-08-08 22:48:14,156] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,158] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,158] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,159] INFO [Partition topic-4-5 broker=3] topic-4-5 starts at Leader Epoch 7 from offset 216. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,176] INFO Replica loaded for partition topic-4-11 with initial high watermark 64 (kafka.cluster.Replica)
[2019-08-08 22:48:14,176] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,178] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,178] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,180] INFO [Partition topic-4-11 broker=3] topic-4-11 starts at Leader Epoch 6 from offset 64. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,197] INFO Replica loaded for partition topic-4-2 with initial high watermark 258 (kafka.cluster.Replica)
[2019-08-08 22:48:14,197] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,199] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,200] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,201] INFO [Partition topic-4-2 broker=3] topic-4-2 starts at Leader Epoch 6 from offset 258. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:14,227] INFO Replica loaded for partition topic-4-0 with initial high watermark 134 (kafka.cluster.Replica)
[2019-08-08 22:48:14,228] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,231] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,232] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,236] INFO Replica loaded for partition topic-4-4 with initial high watermark 502 (kafka.cluster.Replica)
[2019-08-08 22:48:14,236] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,237] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,242] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,247] INFO Replica loaded for partition topic-4-8 with initial high watermark 66 (kafka.cluster.Replica)
[2019-08-08 22:48:14,247] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,248] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,248] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:14,250] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:14,281] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:14,286] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-4-4 -> (offset=502, leaderEpoch=9), topic-4-0 -> (offset=134, leaderEpoch=10), topic-4-8 -> (offset=66, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:14,301] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-3, topic-4-7, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:14,302] INFO [Partition topic-4-9 broker=3] topic-4-9 starts at Leader Epoch 7 from offset 83. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,303] WARN [LeaderEpochCache topic-4-9] New epoch entry EpochEntry(epoch=7, startOffset=83) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=83)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,318] INFO [Partition topic-4-6 broker=3] topic-4-6 starts at Leader Epoch 7 from offset 97. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,318] WARN [LeaderEpochCache topic-4-6] New epoch entry EpochEntry(epoch=7, startOffset=97) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=97)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,331] INFO [Partition topic-4-3 broker=3] topic-4-3 starts at Leader Epoch 8 from offset 136. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:48:14,331] WARN [LeaderEpochCache topic-4-3] New epoch entry EpochEntry(epoch=8, startOffset=136) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=136)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,344] INFO [Partition topic-4-10 broker=3] topic-4-10 starts at Leader Epoch 7 from offset 88. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,344] WARN [LeaderEpochCache topic-4-10] New epoch entry EpochEntry(epoch=7, startOffset=88) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=88)). Cache now contains 7 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,356] INFO [Partition topic-4-7 broker=3] topic-4-7 starts at Leader Epoch 8 from offset 133. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:48:14,356] WARN [LeaderEpochCache topic-4-7] New epoch entry EpochEntry(epoch=8, startOffset=133) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=133)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,368] INFO [Partition topic-4-1 broker=3] topic-4-1 starts at Leader Epoch 7 from offset 132. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,368] WARN [LeaderEpochCache topic-4-1] New epoch entry EpochEntry(epoch=7, startOffset=132) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=132)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,380] INFO [Partition topic-4-5 broker=3] topic-4-5 starts at Leader Epoch 8 from offset 216. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:48:14,380] WARN [LeaderEpochCache topic-4-5] New epoch entry EpochEntry(epoch=8, startOffset=216) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=216)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,393] INFO [Partition topic-4-11 broker=3] topic-4-11 starts at Leader Epoch 7 from offset 64. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,393] WARN [LeaderEpochCache topic-4-11] New epoch entry EpochEntry(epoch=7, startOffset=64) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=64)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,404] INFO [Partition topic-4-2 broker=3] topic-4-2 starts at Leader Epoch 7 from offset 258. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-08 22:48:14,404] WARN [LeaderEpochCache topic-4-2] New epoch entry EpochEntry(epoch=7, startOffset=258) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=258)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-08 22:48:14,946] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-08 22:48:14,946] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-08 22:48:14,947] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-08 22:48:14,948] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-08 22:48:14,957] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 22:48:14,958] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2019-08-08 22:48:14,959] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 22:48:14,960] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:48:14,961] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Truncating to 34 has no effect as the largest offset in the log is 33 (kafka.log.Log)
[2019-08-08 22:48:14,962] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Truncating to 51 has no effect as the largest offset in the log is 50 (kafka.log.Log)
[2019-08-08 22:48:14,962] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-08-08 22:48:14,963] INFO [Partition topic-4-9 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:14,963] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-08-08 22:48:14,964] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-08-08 22:48:14,987] INFO [Partition topic-4-11 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:14,991] INFO [Partition topic-4-6 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:14,995] INFO [Partition topic-4-2 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:14,998] INFO [Partition topic-4-10 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:15,001] INFO [Partition topic-4-1 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:15,004] INFO [Partition topic-4-3 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:15,007] INFO [Partition topic-4-7 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:15,012] INFO [Partition topic-4-5 broker=3] Expanding ISR from 3 to 3,0 (kafka.cluster.Partition)
[2019-08-08 22:48:15,207] INFO [Partition topic-4-9 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,210] INFO [Partition topic-4-11 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,213] INFO [Partition topic-4-6 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,215] INFO [Partition topic-4-2 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,218] INFO [Partition topic-4-10 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,221] INFO [Partition topic-4-1 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,224] INFO [Partition topic-4-3 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,227] INFO [Partition topic-4-7 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,230] INFO [Partition topic-4-5 broker=3] Expanding ISR from 3,0 to 3,0,1 (kafka.cluster.Partition)
[2019-08-08 22:48:15,302] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-08 22:48:15,303] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-08 22:48:15,303] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-08 22:48:15,307] INFO [Partition topic-4-4 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-08 22:48:15,309] INFO [Partition topic-4-0 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-08 22:48:15,311] INFO [Partition topic-4-8 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-08 22:48:32,472] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55238 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:48:32,474] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55238 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:32,485] INFO Established session 0x10005432d98001f with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:55238 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:32,723] INFO Got user-level KeeperException when processing sessionid:0x10005432d98001f type:setData cxid:0x6 zxid:0x3b9 txntype:-1 reqpath:n/a Error Path:/config/topics/topic-5 Error:KeeperErrorCode = NoNode for /config/topics/topic-5 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:32,778] INFO Processed session termination for sessionid: 0x10005432d98001f (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:32,781] WARN Unable to read additional data from client sessionid 0x10005432d98001f, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:48:32,782] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55238 which had sessionid 0x10005432d98001f (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:48:32,810] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-5-7, topic-5-4, topic-5-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:32,809] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-5-5, topic-5-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:32,810] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-5-6, topic-5-3, topic-5-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:32,829] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,830] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,830] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,835] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 22:48:32,836] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 22:48:32,837] INFO Created log for partition topic-5-7 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,838] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 22:48:32,838] INFO Created log for partition topic-5-6 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,839] INFO [Partition topic-5-7 broker=0] No checkpointed highwatermark is found for partition topic-5-7 (kafka.cluster.Partition)
[2019-08-08 22:48:32,840] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,840] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,840] INFO Created log for partition topic-5-5 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,840] INFO [Partition topic-5-7 broker=0] topic-5-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,842] INFO [Partition topic-5-6 broker=3] No checkpointed highwatermark is found for partition topic-5-6 (kafka.cluster.Partition)
[2019-08-08 22:48:32,843] INFO [Partition topic-5-5 broker=1] No checkpointed highwatermark is found for partition topic-5-5 (kafka.cluster.Partition)
[2019-08-08 22:48:32,845] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,850] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,856] INFO [Partition topic-5-6 broker=3] topic-5-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,845] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,858] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,858] INFO [Partition topic-5-5 broker=1] topic-5-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,875] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,885] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 22:48:32,886] INFO Created log for partition topic-5-4 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,888] INFO [Partition topic-5-4 broker=0] No checkpointed highwatermark is found for partition topic-5-4 (kafka.cluster.Partition)
[2019-08-08 22:48:32,888] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,889] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,889] INFO [Partition topic-5-4 broker=0] topic-5-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,894] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,895] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,906] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 22:48:32,907] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 22:48:32,908] INFO Created log for partition topic-5-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,909] INFO Created log for partition topic-5-3 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,911] INFO [Partition topic-5-3 broker=3] No checkpointed highwatermark is found for partition topic-5-3 (kafka.cluster.Partition)
[2019-08-08 22:48:32,912] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,912] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,910] INFO [Partition topic-5-2 broker=1] No checkpointed highwatermark is found for partition topic-5-2 (kafka.cluster.Partition)
[2019-08-08 22:48:32,914] INFO [Partition topic-5-3 broker=3] topic-5-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,914] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,915] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,917] INFO [Partition topic-5-2 broker=1] topic-5-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,927] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,934] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,937] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 22:48:32,938] INFO Created log for partition topic-5-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,941] INFO [Partition topic-5-1 broker=0] No checkpointed highwatermark is found for partition topic-5-1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,941] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,941] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,941] INFO [Partition topic-5-1 broker=0] topic-5-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,955] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,958] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,960] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,964] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 22:48:32,967] INFO Created log for partition topic-5-4 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,971] INFO [Partition topic-5-4 broker=1] No checkpointed highwatermark is found for partition topic-5-4 (kafka.cluster.Partition)
[2019-08-08 22:48:32,970] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 33 ms (kafka.log.Log)
[2019-08-08 22:48:32,972] INFO Created log for partition topic-5-0 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,971] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,975] INFO [Partition topic-5-0 broker=3] No checkpointed highwatermark is found for partition topic-5-0 (kafka.cluster.Partition)
[2019-08-08 22:48:32,976] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,976] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,977] INFO [Partition topic-5-0 broker=3] topic-5-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:48:32,976] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,983] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:32,991] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 22:48:32,992] INFO Created log for partition topic-5-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:32,993] INFO [Partition topic-5-2 broker=0] No checkpointed highwatermark is found for partition topic-5-2 (kafka.cluster.Partition)
[2019-08-08 22:48:32,995] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,995] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,996] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:32,999] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,008] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-08-08 22:48:33,009] INFO Created log for partition topic-5-6 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,010] INFO [Partition topic-5-6 broker=1] No checkpointed highwatermark is found for partition topic-5-6 (kafka.cluster.Partition)
[2019-08-08 22:48:33,011] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,016] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,019] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,020] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,026] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 22:48:33,027] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-08-08 22:48:33,029] INFO Created log for partition topic-5-7 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,032] INFO Created log for partition topic-5-3 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,032] INFO [Partition topic-5-7 broker=3] No checkpointed highwatermark is found for partition topic-5-7 (kafka.cluster.Partition)
[2019-08-08 22:48:33,036] INFO [Partition topic-5-3 broker=0] No checkpointed highwatermark is found for partition topic-5-3 (kafka.cluster.Partition)
[2019-08-08 22:48:33,036] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,036] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-5-3, topic-5-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,037] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-5-3 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,038] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-5-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,036] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,034] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,045] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,049] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-08-08 22:48:33,051] INFO Created log for partition topic-5-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,053] INFO [Partition topic-5-0 broker=1] No checkpointed highwatermark is found for partition topic-5-0 (kafka.cluster.Partition)
[2019-08-08 22:48:33,057] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,058] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-5-0, topic-5-6, topic-5-4) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,059] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-5-0 -> (offset=0, leaderEpoch=0), topic-5-6 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,059] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-5-4 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,065] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,071] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 22:48:33,072] INFO Created log for partition topic-5-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,073] INFO [Partition topic-5-1 broker=3] No checkpointed highwatermark is found for partition topic-5-1 (kafka.cluster.Partition)
[2019-08-08 22:48:33,073] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,074] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,080] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-5-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,081] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,091] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:48:33,096] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 22:48:33,097] INFO Created log for partition topic-5-5 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:48:33,099] INFO [Partition topic-5-5 broker=3] No checkpointed highwatermark is found for partition topic-5-5 (kafka.cluster.Partition)
[2019-08-08 22:48:33,099] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:48:33,100] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-5-1, topic-5-5, topic-5-7) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,108] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-5-5 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,109] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-5-1 -> (offset=0, leaderEpoch=0), topic-5-7 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:48:33,109] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,112] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-5-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,113] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,151] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-5-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,152] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,188] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition topic-5-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,189] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,381] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,382] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,383] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,383] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,427] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,428] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:33,429] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:48:33,432] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:48:50,901] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:55249 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:48:50,903] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:55249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:50,905] INFO Established session 0x10005432d980020 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:55249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:48:51,300] INFO Processed session termination for sessionid: 0x10005432d980020 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:48:51,311] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55249 which had sessionid 0x10005432d980020 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:50:33,201] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:59958 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:50:33,204] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:59958 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:50:33,206] INFO Established session 0x10005432d980021 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:59958 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:50:33,440] INFO Got user-level KeeperException when processing sessionid:0x10005432d980021 type:setData cxid:0x6 zxid:0x3d1 txntype:-1 reqpath:n/a Error Path:/config/topics/topic-6 Error:KeeperErrorCode = NoNode for /config/topics/topic-6 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:50:33,493] INFO Processed session termination for sessionid: 0x10005432d980021 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:50:33,495] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:59958 which had sessionid 0x10005432d980021 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:50:33,505] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,505] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-6-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,506] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-6-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,520] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,521] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,522] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,525] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-08-08 22:50:33,528] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 22:50:33,525] INFO Created log for partition topic-6-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,529] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 22:50:33,531] INFO [Partition topic-6-1 broker=0] No checkpointed highwatermark is found for partition topic-6-1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,531] INFO Created log for partition topic-6-0 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,534] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,534] INFO Created log for partition topic-6-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,535] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,535] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,536] INFO [Partition topic-6-1 broker=0] topic-6-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,537] INFO [Partition topic-6-2 broker=1] No checkpointed highwatermark is found for partition topic-6-2 (kafka.cluster.Partition)
[2019-08-08 22:50:33,539] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,537] INFO [Partition topic-6-0 broker=3] No checkpointed highwatermark is found for partition topic-6-0 (kafka.cluster.Partition)
[2019-08-08 22:50:33,544] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,539] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,544] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,545] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,546] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,547] INFO [Partition topic-6-2 broker=1] topic-6-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,548] INFO [Partition topic-6-0 broker=3] topic-6-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,553] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,554] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,560] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,561] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,563] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,577] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,579] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,583] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 22:50:33,584] INFO Created log for partition topic-6-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,586] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-08-08 22:50:33,590] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,585] INFO [Partition topic-6-0 broker=1] No checkpointed highwatermark is found for partition topic-6-0 (kafka.cluster.Partition)
[2019-08-08 22:50:33,588] INFO Created log for partition topic-6-2 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,596] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-08-08 22:50:33,597] INFO Created log for partition topic-6-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,595] INFO [Partition topic-6-2 broker=3] No checkpointed highwatermark is found for partition topic-6-2 (kafka.cluster.Partition)
[2019-08-08 22:50:33,594] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,600] INFO [Partition topic-6-2 broker=0] No checkpointed highwatermark is found for partition topic-6-2 (kafka.cluster.Partition)
[2019-08-08 22:50:33,600] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,599] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,600] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,600] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,601] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,603] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,604] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,615] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,617] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,621] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:50:33,622] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-08-08 22:50:33,623] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-08-08 22:50:33,623] INFO Created log for partition topic-6-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,624] INFO Created log for partition topic-6-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,625] INFO [Partition topic-6-0 broker=0] No checkpointed highwatermark is found for partition topic-6-0 (kafka.cluster.Partition)
[2019-08-08 22:50:33,626] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,626] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,626] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-6-2, topic-6-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,626] INFO [Partition topic-6-1 broker=1] No checkpointed highwatermark is found for partition topic-6-1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,626] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,627] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,628] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-08-08 22:50:33,627] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-6-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,629] INFO Created log for partition topic-6-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:50:33,630] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-6-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,628] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-6-0, topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,635] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-6-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,632] INFO [Partition topic-6-1 broker=3] No checkpointed highwatermark is found for partition topic-6-1 (kafka.cluster.Partition)
[2019-08-08 22:50:33,635] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-6-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,636] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:50:33,638] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-6-2, topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,641] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-6-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,641] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-6-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:50:33,735] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:33,736] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:50:33,782] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:33,783] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:50:33,789] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:33,791] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:50:33,849] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:33,850] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:50:34,079] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:34,079] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:50:34,081] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:50:34,082] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:51:12,214] INFO Accepted socket connection from /127.0.0.1:59965 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:51:12,217] INFO Client attempting to establish new session at /127.0.0.1:59965 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:51:12,227] INFO Established session 0x10005432d980022 with negotiated timeout 30000 for client /127.0.0.1:59965 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:51:12,429] INFO Processed session termination for sessionid: 0x10005432d980022 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:51:12,440] INFO Closed socket connection for client /127.0.0.1:59965 which had sessionid 0x10005432d980022 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:52:05,043] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-10, topic-4-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,043] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,043] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,045] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-10 -> (offset=88, leaderEpoch=8), topic-4-6 -> (offset=97, leaderEpoch=8), topic-4-2 -> (offset=258, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,043] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 8 from offset 97. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:52:05,054] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-10 -> (offset=88, leaderEpoch=8), topic-4-6 -> (offset=97, leaderEpoch=8), topic-4-2 -> (offset=258, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,054] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,058] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=11), topic-4-4 -> (offset=502, leaderEpoch=10), topic-4-8 -> (offset=66, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,060] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,061] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 11 from offset 134. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-08 22:52:05,068] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 8 from offset 88. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:52:05,080] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 8 from offset 258. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-08 22:52:05,073] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 10 from offset 502. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-08 22:52:05,093] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 9 from offset 66. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-08 22:52:05,097] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,099] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=11), topic-4-4 -> (offset=502, leaderEpoch=10), topic-4-8 -> (offset=66, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:05,280] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-08 22:52:05,280] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-08 22:52:05,281] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-08 22:52:05,282] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-08 22:52:05,281] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-08 22:52:05,283] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-08 22:52:05,555] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-08 22:52:05,556] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-08 22:52:05,555] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-08 22:52:05,557] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-08 22:52:05,558] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-08 22:52:05,558] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-08 22:52:39,057] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-08 22:52:39,401] INFO starting (kafka.server.KafkaServer)
[2019-08-08 22:52:39,402] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-08 22:52:39,415] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:52:44,208] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,208] INFO Client environment:host.name=W101GKNGH2.blr.amer.dell.com (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,208] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,209] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,209] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,209] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,210] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,210] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,211] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,212] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,213] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,214] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,214] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,215] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,215] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,217] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-08 22:52:44,242] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:52:44,243] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:52:44,247] INFO Accepted socket connection from /127.0.0.1:59977 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:52:44,247] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:52:44,265] INFO Client attempting to establish new session at /127.0.0.1:59977 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:52:44,277] INFO Established session 0x10005432d980023 with negotiated timeout 6000 for client /127.0.0.1:59977 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:52:44,280] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980023, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-08 22:52:44,284] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-08 22:52:44,325] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x1 zxid:0x3e5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,336] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x2 zxid:0x3e6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,338] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x3 zxid:0x3e7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,340] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x4 zxid:0x3e8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,342] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x5 zxid:0x3e9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,344] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x6 zxid:0x3ea txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,350] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x7 zxid:0x3eb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,352] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x8 zxid:0x3ec txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,355] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0x9 zxid:0x3ed txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,357] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0xa zxid:0x3ee txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,361] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0xb zxid:0x3ef txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,364] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0xc zxid:0x3f0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,366] INFO Got user-level KeeperException when processing sessionid:0x10005432d980023 type:create cxid:0xd zxid:0x3f1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:52:44,521] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-08 22:52:44,573] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:52:44,581] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-08 22:52:44,602] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:52:44,602] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:52:44,606] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-08 22:52:44,638] INFO Loading logs. (kafka.log.LogManager)
[2019-08-08 22:52:44,699] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:44,700] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:44,772] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:44,821] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:44,830] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:44,840] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 181 ms (kafka.log.Log)
[2019-08-08 22:52:44,859] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:44,860] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:44,905] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:44,933] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:44,939] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:44,944] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 95 ms (kafka.log.Log)
[2019-08-08 22:52:44,957] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:44,957] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:44,996] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,015] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,020] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-10\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,025] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 76 ms (kafka.log.Log)
[2019-08-08 22:52:45,038] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,039] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,079] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,098] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,104] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-11\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,110] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 80 ms (kafka.log.Log)
[2019-08-08 22:52:45,129] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,129] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,185] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,215] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,219] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,223] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 110 ms (kafka.log.Log)
[2019-08-08 22:52:45,239] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,239] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,275] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,304] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,308] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-3\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,311] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 81 ms (kafka.log.Log)
[2019-08-08 22:52:45,327] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,327] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,376] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,395] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,400] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-4\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,404] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 84 ms (kafka.log.Log)
[2019-08-08 22:52:45,440] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,440] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,479] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,507] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,511] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-5\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,516] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 106 ms (kafka.log.Log)
[2019-08-08 22:52:45,532] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,533] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,571] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,590] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,594] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-6\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,599] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 77 ms (kafka.log.Log)
[2019-08-08 22:52:45,615] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,616] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,664] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,697] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,702] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-7\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,707] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 100 ms (kafka.log.Log)
[2019-08-08 22:52:45,724] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,725] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,786] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,816] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,821] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-8\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,826] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 116 ms (kafka.log.Log)
[2019-08-08 22:52:45,837] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-08 22:52:45,838] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,880] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,902] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-08-08 22:52:45,907] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-2\topic-4-9\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-08-08 22:52:45,912] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 84 ms (kafka.log.Log)
[2019-08-08 22:52:45,919] INFO Logs loading complete in 1280 ms. (kafka.log.LogManager)
[2019-08-08 22:52:45,930] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-08 22:52:45,932] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-08 22:52:46,165] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-08-08 22:52:46,198] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-08 22:52:46,214] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:46,222] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:46,222] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:46,233] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-08 22:52:50,795] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-08 22:52:50,799] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-08-08 22:52:50,801] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-08 22:52:50,857] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:50,860] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:50,861] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-08 22:52:50,877] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:52:50,878] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-08 22:52:50,884] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-08 22:52:50,896] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:14000,blockEndProducerId:14999) by writing to Zk with path version 15 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-08 22:52:50,917] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:52:50,920] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-08 22:52:50,921] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-08 22:52:50,961] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-08 22:52:50,978] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-08 22:52:50,981] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:52:50,981] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-08 22:52:50,984] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-08-08 22:52:51,028] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,029] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,031] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,045] INFO Replica loaded for partition topic-4-9 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,047] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,053] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,055] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,067] INFO Replica loaded for partition topic-4-6 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:52:51,071] INFO Replica loaded for partition topic-4-3 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:52:51,076] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,079] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,088] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,092] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,098] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,099] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,103] INFO Replica loaded for partition topic-4-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,104] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,105] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,118] INFO Replica loaded for partition topic-4-10 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,118] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,128] INFO Replica loaded for partition topic-4-7 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:52:51,128] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,137] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,140] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,149] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,152] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,164] INFO Replica loaded for partition topic-4-4 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:52:51,164] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,165] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,173] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,180] INFO Replica loaded for partition topic-4-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-08-08 22:52:51,180] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,185] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,189] INFO Replica loaded for partition topic-4-8 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,198] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,200] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,201] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,213] INFO Replica loaded for partition topic-4-5 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,214] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,215] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,226] INFO Replica loaded for partition topic-4-11 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,227] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,228] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,236] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,239] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,242] INFO Replica loaded for partition topic-4-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-08-08 22:52:51,248] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,251] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:52:51,253] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-4-3, topic-4-11, topic-4-9, topic-4-7, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:51,286] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:52:51,292] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-9 -> (offset=2, leaderEpoch=7), topic-4-11 -> (offset=2, leaderEpoch=7), topic-4-1 -> (offset=1, leaderEpoch=7), topic-4-8 -> (offset=2, leaderEpoch=9), topic-4-3 -> (offset=1, leaderEpoch=8), topic-4-7 -> (offset=1, leaderEpoch=8), topic-4-4 -> (offset=1, leaderEpoch=10), topic-4-0 -> (offset=2, leaderEpoch=11), topic-4-5 -> (offset=2, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:51,299] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-6 -> (offset=1, leaderEpoch=8), topic-4-2 -> (offset=2, leaderEpoch=8), topic-4-10 -> (offset=2, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:52:51,302] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:52:51,325] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:51,327] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:52:51,340] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:51,481] INFO [Partition topic-4-6 broker=1] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:51,494] INFO [Partition topic-4-2 broker=1] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:51,496] INFO [Partition topic-4-10 broker=1] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,299] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:52,300] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:52,305] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:52,305] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:52:52,315] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:52,320] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:52:52,328] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:52:52,332] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-08-08 22:52:52,341] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-08-08 22:52:52,701] INFO [Partition topic-4-9 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,705] INFO [Partition topic-4-11 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,707] INFO [Partition topic-4-1 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,711] INFO [Partition topic-4-8 broker=3] Expanding ISR from 0,1,3 to 0,1,3,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,715] INFO [Partition topic-4-3 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,718] INFO [Partition topic-4-7 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,722] INFO [Partition topic-4-4 broker=3] Expanding ISR from 0,1,3 to 0,1,3,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,725] INFO [Partition topic-4-0 broker=3] Expanding ISR from 0,1,3 to 0,1,3,2 (kafka.cluster.Partition)
[2019-08-08 22:52:52,729] INFO [Partition topic-4-5 broker=3] Expanding ISR from 3,0,1 to 3,0,1,2 (kafka.cluster.Partition)
[2019-08-08 22:53:02,881] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60003 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:53:02,883] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:02,894] INFO Established session 0x10005432d980024 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60003 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:03,095] INFO Processed session termination for sessionid: 0x10005432d980024 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:53:03,100] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60003 which had sessionid 0x10005432d980024 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:53:31,476] INFO Accepted socket connection from /127.0.0.1:60007 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:53:31,479] INFO Client attempting to establish new session at /127.0.0.1:60007 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:31,489] INFO Established session 0x10005432d980025 with negotiated timeout 30000 for client /127.0.0.1:60007 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:31,708] INFO Got user-level KeeperException when processing sessionid:0x10005432d980025 type:setData cxid:0x7 zxid:0x407 txntype:-1 reqpath:n/a Error Path:/config/topics/topic-7 Error:KeeperErrorCode = NoNode for /config/topics/topic-7 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:53:31,752] INFO Processed session termination for sessionid: 0x10005432d980025 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:53:31,756] INFO Closed socket connection for client /127.0.0.1:60007 which had sessionid 0x10005432d980025 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:53:31,763] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-7-1) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,763] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-7-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,765] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,769] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-7-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,766] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,783] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,785] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,790] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,790] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-08-08 22:53:31,792] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 22:53:31,793] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,793] INFO Created log for partition topic-7-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,794] INFO Created log for partition topic-7-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,795] INFO [Partition topic-7-1 broker=1] No checkpointed highwatermark is found for partition topic-7-1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,799] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,796] INFO [Partition topic-7-0 broker=0] No checkpointed highwatermark is found for partition topic-7-0 (kafka.cluster.Partition)
[2019-08-08 22:53:31,800] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-08-08 22:53:31,800] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,800] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,801] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,801] INFO [Partition topic-7-0 broker=0] topic-7-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,804] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-08-08 22:53:31,801] INFO Created log for partition topic-7-0 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,806] INFO Created log for partition topic-7-2 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,800] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,824] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,826] INFO [Partition topic-7-2 broker=2] No checkpointed highwatermark is found for partition topic-7-2 (kafka.cluster.Partition)
[2019-08-08 22:53:31,826] INFO [Partition topic-7-1 broker=1] topic-7-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,819] INFO [Partition topic-7-0 broker=3] No checkpointed highwatermark is found for partition topic-7-0 (kafka.cluster.Partition)
[2019-08-08 22:53:31,835] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,826] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,828] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,835] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,837] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,844] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,846] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,837] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,861] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,866] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,869] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 22:53:31,868] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,851] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,878] INFO Created log for partition topic-7-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,879] INFO [Partition topic-7-1 broker=0] No checkpointed highwatermark is found for partition topic-7-1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,880] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,880] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,887] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-08-08 22:53:31,887] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-08-08 22:53:31,881] INFO [Partition topic-7-2 broker=2] topic-7-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,894] INFO Created log for partition topic-7-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,902] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,900] INFO [Partition topic-7-1 broker=3] No checkpointed highwatermark is found for partition topic-7-1 (kafka.cluster.Partition)
[2019-08-08 22:53:31,910] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-08-08 22:53:31,911] INFO Created log for partition topic-7-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,908] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,913] INFO [Partition topic-7-2 broker=0] No checkpointed highwatermark is found for partition topic-7-2 (kafka.cluster.Partition)
[2019-08-08 22:53:31,913] INFO Created log for partition topic-7-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:31,914] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,915] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,915] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-7-1, topic-7-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,913] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,923] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,933] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-7-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,932] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-7-1, topic-7-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,935] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:31,916] INFO [Partition topic-7-2 broker=1] No checkpointed highwatermark is found for partition topic-7-2 (kafka.cluster.Partition)
[2019-08-08 22:53:31,937] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-7-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:31,938] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:31,937] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-7-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,939] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,937] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,940] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-7-2) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,946] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:31,951] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:31,959] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:31,960] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition topic-7-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:31,961] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:31,977] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-08 22:53:31,986] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition topic-7-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 22:53:31,987] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition topic-7-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-08 22:53:31,988] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-08-08 22:53:31,997] INFO Created log for partition topic-7-0 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-08-08 22:53:32,015] INFO [Partition topic-7-0 broker=2] No checkpointed highwatermark is found for partition topic-7-0 (kafka.cluster.Partition)
[2019-08-08 22:53:32,020] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:32,022] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-08 22:53:32,029] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-7-0) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:32,048] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-08-08 22:53:32,048] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:32,061] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition topic-7-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:32,061] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:32,133] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:32,133] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:32,133] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:32,133] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:32,408] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-7-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-08 22:53:32,408] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-08 22:53:47,660] INFO Accepted socket connection from /127.0.0.1:60020 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:53:47,662] INFO Client attempting to establish new session at /127.0.0.1:60020 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:47,672] INFO Established session 0x10005432d980026 with negotiated timeout 30000 for client /127.0.0.1:60020 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:53:47,873] INFO Processed session termination for sessionid: 0x10005432d980026 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-08 22:53:47,886] INFO Closed socket connection for client /127.0.0.1:60020 which had sessionid 0x10005432d980026 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:54:33,275] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60030 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-08 22:54:33,277] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60030 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:54:33,279] INFO Established session 0x10005432d980027 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60030 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:54:33,755] WARN Exception causing close of session 0x10005432d980027: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:54:33,756] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60030 which had sessionid 0x10005432d980027 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-08 22:55:04,017] INFO Expiring session 0x10005432d980027, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-08 22:55:04,017] INFO Processed session termination for sessionid: 0x10005432d980027 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:33,525] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1971497255, epoch=1159) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,599] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=435017721, epoch=386) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,573] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9092-172.20.104.65:60016-1 (kafka.network.Processor)
[2019-08-09 10:04:33,572] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9092-172.20.104.65:55171-1 (kafka.network.Processor)
[2019-08-09 10:04:35,331] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=435017721, epoch=386)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:33,931] WARN Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d98001b (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:33,703] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1416453023, epoch=1020) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:35,341] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1416453023, epoch=1020)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:33,615] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=0, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1971497255, epoch=1159)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:35,341] INFO Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d98001b, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:33,510] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=322836788, epoch=1020) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,566] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1969180357, epoch=389) to node 0: java.io.IOException: Connection to 0 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,903] WARN Client session timed out, have not heard from server in 40068025ms for sessionid 0x10005432d98001c (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:33,530] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1837404544, epoch=984) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,992] WARN Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d980023 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:35,086] INFO Expiring session 0x10005432d98001c, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:33,596] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1776623048, epoch=386) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:35,342] WARN Unable to read additional data from client sessionid 0x10005432d98001b, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:35,619] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55120 which had sessionid 0x10005432d98001b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:35,586] INFO Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d980023, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:35,629] WARN Unable to read additional data from client sessionid 0x10005432d980023, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:35,629] INFO Closed socket connection for client /127.0.0.1:59977 which had sessionid 0x10005432d980023 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:35,618] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1776623048, epoch=386)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:33,703] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=2004564581, epoch=468) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1160970595, epoch=1164) to node 0: java.io.IOException: Connection to 0 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:33,886] WARN Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d98001e (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:35,600] INFO Expiring session 0x10005432d980023, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:35,668] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1160970595, epoch=1164)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:35,659] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=2004564581, epoch=468)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:33,527] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9093-172.20.104.65:55177-0 (kafka.network.Processor)
[2019-08-09 10:04:33,601] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9094-172.20.104.65:60013-0 (kafka.network.Processor)
[2019-08-09 10:04:35,983] INFO Expiring session 0x10005432d98001e, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:33,703] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:55221-0 (kafka.network.Processor)
[2019-08-09 10:04:33,703] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:55224-0 (kafka.network.Processor)
[2019-08-09 10:04:35,500] INFO Client session timed out, have not heard from server in 40068025ms for sessionid 0x10005432d98001c, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:36,314] INFO Expiring session 0x10005432d98001b, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:33,601] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9094-172.20.104.65:60010-0 (kafka.network.Processor)
[2019-08-09 10:04:36,365] WARN Unable to read additional data from client sessionid 0x10005432d98001c, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:36,381] INFO Processed session termination for sessionid: 0x10005432d98001c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:35,478] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1969180357, epoch=389)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:36,419] INFO Processed session termination for sessionid: 0x10005432d980023 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:36,419] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:55140 which had sessionid 0x10005432d98001c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:36,420] INFO Processed session termination for sessionid: 0x10005432d98001e (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:36,420] INFO Processed session termination for sessionid: 0x10005432d98001b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:36,425] INFO Closed socket connection for client /127.0.0.1:55207 which had sessionid 0x10005432d98001e (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:33,703] WARN Attempting to send response via channel for which there is no open connection, connection id 172.20.104.65:9095-172.20.104.65:59996-1 (kafka.network.Processor)
[2019-08-09 10:04:35,375] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=322836788, epoch=1020)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:35,983] INFO Client session timed out, have not heard from server in 40068024ms for sessionid 0x10005432d98001e, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:35,547] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1837404544, epoch=984)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:37,087] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,095] INFO Accepted socket connection from /127.0.0.1:60045 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:37,096] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,109] INFO Client attempting to renew session 0x10005432d980023 at /127.0.0.1:60045 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,112] INFO Invalid session 0x10005432d980023 for client /127.0.0.1:60045, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,117] INFO Closed socket connection for client /127.0.0.1:60045 which had sessionid 0x10005432d980023 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:37,112] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d980023 has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,114] INFO EventThread shut down for session: 0x10005432d980023 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,134] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d980023 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,135] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:37,172] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:37,189] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:04:37,285] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,286] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:37,293] INFO Accepted socket connection from /127.0.0.1:60048 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:37,294] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,317] INFO Client attempting to establish new session at /127.0.0.1:60048 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,333] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980028, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,332] INFO Established session 0x10005432d980028 with negotiated timeout 6000 for client /127.0.0.1:60048 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,346] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:37,348] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:37,412] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,418] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,418] INFO Accepted socket connection from /127.0.0.1:60052 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:37,435] INFO Client attempting to renew session 0x10005432d98001b at /127.0.0.1:60052 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,439] INFO Invalid session 0x10005432d98001b for client /127.0.0.1:60052, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,439] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d98001b has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,441] INFO Closed socket connection for client /127.0.0.1:60052 which had sessionid 0x10005432d98001b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:37,441] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d98001b has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,448] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:37,441] INFO EventThread shut down for session: 0x10005432d98001b (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,470] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:37,470] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:04:37,607] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,638] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:37,688] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60058 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:37,688] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,717] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60058 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,781] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10005432d980029, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:37,781] INFO Established session 0x10005432d980029 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60058 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:37,847] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:37,850] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,088] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-7-0, topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-4-7, topic-4-4, topic-4-0, topic-4-5) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,104] INFO [Partition topic-4-9 broker=2] topic-4-9 starts at Leader Epoch 8 from offset 83. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-09 10:04:38,107] INFO Got user-level KeeperException when processing sessionid:0x10005432d980028 type:multi cxid:0x108 zxid:0x42c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:38,155] INFO Got user-level KeeperException when processing sessionid:0x10005432d980028 type:multi cxid:0x10a zxid:0x42d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:38,160] INFO [Partition topic-4-6 broker=2] topic-4-6 starts at Leader Epoch 9 from offset 97. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:38,145] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,186] INFO Accepted socket connection from /127.0.0.1:60063 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:38,187] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,205] INFO Client attempting to renew session 0x10005432d98001e at /127.0.0.1:60063 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,229] INFO [Partition topic-4-3 broker=2] topic-4-3 starts at Leader Epoch 9 from offset 136. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:38,235] INFO Invalid session 0x10005432d98001e for client /127.0.0.1:60063, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,235] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d98001e has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,287] INFO Closed socket connection for client /127.0.0.1:60063 which had sessionid 0x10005432d98001e (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:38,306] INFO [Partition topic-4-0 broker=2] topic-4-0 starts at Leader Epoch 12 from offset 134. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:04:38,294] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d98001e has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,242] INFO EventThread shut down for session: 0x10005432d98001e (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,345] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-10, topic-4-5, topic-7-0, topic-4-11, topic-4-3, topic-4-9, topic-4-7, topic-4-4, topic-4-2, topic-4-0, topic-4-8, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,363] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=1), topic-4-9 -> (offset=83, leaderEpoch=8), topic-4-11 -> (offset=64, leaderEpoch=8), topic-4-6 -> (offset=97, leaderEpoch=9), topic-4-2 -> (offset=258, leaderEpoch=9), topic-4-10 -> (offset=88, leaderEpoch=9), topic-4-1 -> (offset=132, leaderEpoch=8), topic-4-8 -> (offset=66, leaderEpoch=10), topic-4-3 -> (offset=136, leaderEpoch=9), topic-4-7 -> (offset=133, leaderEpoch=9), topic-4-4 -> (offset=502, leaderEpoch=11), topic-4-0 -> (offset=134, leaderEpoch=12), topic-4-5 -> (offset=216, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,294] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:38,431] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:38,445] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:04:38,459] INFO [Partition topic-7-0 broker=2] topic-7-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:38,463] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-7-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,457] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,485] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,488] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,488] INFO Accepted socket connection from /127.0.0.1:60069 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:38,464] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, topic-5-7, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, topic-6-0, topic-7-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, topic-5-3, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, topic-5-2, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, topic-6-2, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-5-1, topic-5-4, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40, topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,530] INFO Client attempting to establish new session at /127.0.0.1:60069 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,475] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-7 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,538] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:38,565] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,572] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,560] INFO Established session 0x10005432d98002a with negotiated timeout 6000 for client /127.0.0.1:60069 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,572] INFO Accepted socket connection from /127.0.0.1:60071 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:38,574] INFO Client attempting to renew session 0x10005432d98001c at /127.0.0.1:60071 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,575] INFO Invalid session 0x10005432d98001c for client /127.0.0.1:60071, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,577] INFO Closed socket connection for client /127.0.0.1:60071 which had sessionid 0x10005432d98001c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:38,558] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:04:38,569] WARN [LeaderEpochCache __consumer_offsets-0] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:38,579] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-5 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,582] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-4 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,585] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:04:38,560] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98002a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,595] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,602] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,612] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:38,613] INFO [Partition topic-4-10 broker=2] topic-4-10 starts at Leader Epoch 9 from offset 88. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:38,575] WARN Unable to reconnect to ZooKeeper service, session 0x10005432d98001c has expired (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,630] INFO Unable to reconnect to ZooKeeper service, session 0x10005432d98001c has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,626] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:38,577] INFO EventThread shut down for session: 0x10005432d98001c (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,682] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:04:38,686] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:04:38,621] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-11 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,619] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,708] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,721] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:38,740] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:04:38,741] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:38,742] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:38,708] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,744] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,757] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,747] INFO [Partition topic-4-7 broker=2] topic-4-7 starts at Leader Epoch 9 from offset 133. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:38,720] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,757] INFO Accepted socket connection from /127.0.0.1:60078 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:04:38,747] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:04:38,771] INFO Client attempting to establish new session at /127.0.0.1:60078 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,787] INFO Established session 0x10005432d98002b with negotiated timeout 6000 for client /127.0.0.1:60078 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:38,787] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98002b, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:04:38,795] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:38,813] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,804] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:04:38,813] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.blr.amer.dell.com,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:04:38,809] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:38,842] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:04:38,863] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:04:38,876] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:38,892] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:38,927] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-5-0, topic-4-1, topic-6-0, topic-5-4, topic-4-5, topic-5-5, topic-4-9, topic-4-2, topic-6-1, topic-5-2, topic-4-6, topic-7-1, topic-6-2, topic-5-6, topic-4-10, topic-3-0, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-4-0, topic-4-8, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,959] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-5-5 -> (offset=0, leaderEpoch=1), topic-5-0 -> (offset=0, leaderEpoch=1), topic-5-6 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,962] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-4-9 -> (offset=83, leaderEpoch=8), topic-4-11 -> (offset=64, leaderEpoch=8), topic-4-6 -> (offset=97, leaderEpoch=9), topic-4-2 -> (offset=258, leaderEpoch=9), topic-4-10 -> (offset=88, leaderEpoch=9), topic-4-1 -> (offset=132, leaderEpoch=8), topic-4-8 -> (offset=66, leaderEpoch=10), topic-4-3 -> (offset=136, leaderEpoch=9), topic-4-7 -> (offset=133, leaderEpoch=9), topic-4-4 -> (offset=502, leaderEpoch=11), topic-4-0 -> (offset=134, leaderEpoch=12), topic-4-5 -> (offset=216, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,962] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-3-1 -> (offset=7, leaderEpoch=6), topic-6-0 -> (offset=0, leaderEpoch=1), topic-7-1 -> (offset=0, leaderEpoch=1), topic-3-0 -> (offset=6, leaderEpoch=9), topic-5-2 -> (offset=0, leaderEpoch=1), topic-6-2 -> (offset=0, leaderEpoch=1), topic-5-4 -> (offset=0, leaderEpoch=1), topic-6-1 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,991] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:38,923] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-6-0, topic-5-1, topic-4-5, topic-7-0, topic-4-9, topic-4-2, topic-6-1, topic-4-6, topic-7-1, topic-6-2, topic-4-10, topic-4-3, topic-4-11, topic-5-3, topic-4-7, topic-4-4, topic-5-7, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:38,994] INFO [Partition topic-4-4 broker=2] topic-4-4 starts at Leader Epoch 11 from offset 502. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-09 10:04:38,997] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,010] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-5-5 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,012] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,013] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,018] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,019] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:38,955] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Partition topic-5-5 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,057] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,026] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=1), topic-4-9 -> (offset=83, leaderEpoch=8), topic-4-11 -> (offset=64, leaderEpoch=8), topic-4-6 -> (offset=97, leaderEpoch=9), topic-4-2 -> (offset=258, leaderEpoch=9), topic-4-10 -> (offset=88, leaderEpoch=9), topic-4-1 -> (offset=132, leaderEpoch=8), topic-4-8 -> (offset=66, leaderEpoch=10), topic-4-3 -> (offset=136, leaderEpoch=9), topic-4-7 -> (offset=133, leaderEpoch=9), topic-4-4 -> (offset=502, leaderEpoch=11), topic-4-0 -> (offset=134, leaderEpoch=12), topic-4-5 -> (offset=216, leaderEpoch=9)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:39,069] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.blr.amer.dell.com:9092) for partitions Map(topic-5-7 -> (offset=0, leaderEpoch=1), topic-6-0 -> (offset=0, leaderEpoch=1), topic-7-1 -> (offset=0, leaderEpoch=1), topic-5-3 -> (offset=0, leaderEpoch=1), topic-6-2 -> (offset=0, leaderEpoch=1), topic-5-1 -> (offset=0, leaderEpoch=1), topic-6-1 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:39,076] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,085] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,083] INFO [Partition topic-4-1 broker=2] topic-4-1 starts at Leader Epoch 8 from offset 132. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-09 10:04:39,083] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:39,100] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,085] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,145] INFO [Partition topic-4-8 broker=2] topic-4-8 starts at Leader Epoch 10 from offset 66. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:39,145] INFO [Partition topic-5-7 broker=0] topic-5-7 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:39,157] WARN [LeaderEpochCache topic-5-7] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,101] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-5-5, topic-5-6, topic-5-0) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:39,190] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:39,191] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,192] INFO [Partition topic-4-5 broker=2] topic-4-5 starts at Leader Epoch 9 from offset 216. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:39,197] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,180] INFO [Partition topic-5-5 broker=3] topic-5-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:39,195] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-11 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,258] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:04:39,259] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:04:39,259] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,260] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:04:39,260] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:04:39,260] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-5 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,260] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:39,260] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:04:39,260] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,261] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:04:39,261] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:39,261] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition topic-7-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,261] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,244] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,278] INFO [Partition topic-4-2 broker=2] topic-4-2 starts at Leader Epoch 9 from offset 258. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:39,277] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:39,296] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,285] INFO [Partition topic-7-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,338] WARN [LeaderEpochCache __consumer_offsets-42] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,345] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,384] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,410] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,387] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,407] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,420] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,430] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition topic-4-11 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,470] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:04:39,474] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:04:39,479] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:39,423] INFO [Partition topic-4-11 broker=2] topic-4-11 starts at Leader Epoch 8 from offset 64. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-08-09 10:04:39,485] INFO [Partition topic-5-4 broker=0] topic-5-4 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:39,488] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:04:39,453] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,491] WARN [LeaderEpochCache topic-5-4] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,446] INFO [Partition topic-5-6 broker=3] topic-5-6 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:39,466] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,506] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:04:39,517] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,518] WARN [LeaderEpochCache topic-5-6] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,450] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,521] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,517] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:04:39,523] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,523] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:39,524] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:04:39,524] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,522] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,525] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:04:39,528] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-5-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,528] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:04:39,531] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:39,525] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,533] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,534] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,535] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,531] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,536] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,537] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:39,538] INFO [Partition topic-5-7 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,512] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,588] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,603] INFO [Partition topic-5-4 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:39,596] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,600] INFO [Partition topic-5-0 broker=3] topic-5-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:39,687] WARN [LeaderEpochCache topic-5-0] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,603] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,617] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:39,634] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,757] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:39,634] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,765] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,831] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,833] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,833] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,846] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,850] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,851] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,851] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:39,889] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:39,894] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2,0,3 to 2,0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:39,899] INFO [Partition topic-5-0 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:39,999] INFO [Partition topic-5-6 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:39,934] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2,0,3 to 2,0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,022] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:40,151] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:40,160] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,177] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2,3 to 2,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,179] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:40,190] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:04:40,211] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:04:40,217] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:40,231] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:04:40,236] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2,3 to 2,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,227] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 6 from offset 111. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:40,236] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:04:40,239] WARN [LeaderEpochCache topic-1-0] New epoch entry EpochEntry(epoch=6, startOffset=111) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=111)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:40,239] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:40,246] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,247] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:04:40,257] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2,0,3 to 2,0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,255] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:04:40,291] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2,3 to 2,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,308] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2,3 to 2,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,322] INFO [Partition topic-5-1 broker=0] topic-5-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,328] WARN [LeaderEpochCache topic-5-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:40,328] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2,0,3 to 2,0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,376] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2 to 2,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,376] INFO [Partition topic-7-0 broker=2] Expanding ISR from 2,3 to 2,3,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,429] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,472] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,451] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:40,513] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:40,532] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2,3,1 to 2,3,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,536] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:40,554] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2,3,1 to 2,3,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,549] INFO [Partition topic-5-5 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:40,583] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,603] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2,3,1 to 2,3,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,659] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2,3,1 to 2,3,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,663] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:40,673] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2,1 to 2,1,0 (kafka.cluster.Partition)
[2019-08-09 10:04:40,666] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:40,648] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,705] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,714] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,720] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,721] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,722] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,684] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:04:40,700] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:40,727] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:40,729] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:04:40,730] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:04:40,730] INFO [Partition topic-5-1 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:40,732] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:41,365] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2,1,0 to 2,1,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:41,377] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2,1,0 to 2,1,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:41,383] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2,1,0 to 2,1,0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:41,400] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:04:41,433] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2,0,3 to 2,0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:41,438] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,467] WARN [LeaderEpochCache __consumer_offsets-39] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,530] INFO [Partition topic-6-2 broker=0] topic-6-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:41,608] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,612] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,668] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,673] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,707] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,711] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,735] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,737] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,740] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,741] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,744] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:41,746] INFO [Partition topic-6-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:41,802] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,803] WARN [LeaderEpochCache __consumer_offsets-33] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,837] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 6 from offset 164. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,862] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,868] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:41,898] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,899] WARN [LeaderEpochCache __consumer_offsets-11] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,914] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,914] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:41,948] INFO [Partition topic-7-1 broker=0] topic-7-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:41,983] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:41,991] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:42,384] INFO [Partition topic-6-2 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:04:42,389] INFO [Partition topic-7-1 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:42,614] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:42,632] WARN [LeaderEpochCache __consumer_offsets-27] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:42,730] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:42,823] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:42,808] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:42,845] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:42,851] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:42,861] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:42,876] INFO [Partition topic-7-1 broker=0] Expanding ISR from 0,3 to 0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:42,959] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:42,980] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:42,990] INFO [Partition topic-6-0 broker=0] topic-6-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:43,211] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:43,304] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,319] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-7-1, topic-6-2, topic-4-10, topic-5-5, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,280] WARN [LeaderEpochCache __consumer_offsets-24] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,347] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-10 -> (offset=88, leaderEpoch=10), topic-4-2 -> (offset=258, leaderEpoch=10), topic-4-6 -> (offset=97, leaderEpoch=10)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,381] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,384] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,319] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-2, topic-7-1, topic-4-10, topic-6-2, topic-5-5) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,346] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-6 -> (offset=97, leaderEpoch=10), topic-4-2 -> (offset=258, leaderEpoch=10), topic-7-1 -> (offset=0, leaderEpoch=2), topic-4-10 -> (offset=88, leaderEpoch=10), topic-6-2 -> (offset=0, leaderEpoch=2), topic-5-5 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,405] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,402] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=13), topic-4-8 -> (offset=66, leaderEpoch=11), topic-4-4 -> (offset=502, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,424] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,393] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 10 from offset 97. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:43,449] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-0, topic-4-4, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:43,492] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:43,505] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,483] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,493] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 13 from offset 134. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-08-09 10:04:43,483] WARN [LeaderEpochCache topic-4-6] New epoch entry EpochEntry(epoch=10, startOffset=97) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=97)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,517] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=13, startOffset=134) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=134)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,516] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-4 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,545] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,584] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:43,579] INFO [Partition topic-6-2 broker=1] topic-6-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-09 10:04:43,581] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,592] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:04:43,588] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,599] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,581] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,618] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:04:43,629] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-5-5 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,630] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,631] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,631] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:43,632] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:43,634] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:43,591] WARN [LeaderEpochCache topic-6-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,715] INFO [Partition topic-5-2 broker=0] topic-5-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:43,738] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 12 from offset 502. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:04:43,807] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 10 from offset 88. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:43,814] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 6 from offset 4. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:43,781] WARN [LeaderEpochCache topic-4-4] New epoch entry EpochEntry(epoch=12, startOffset=502) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=502)). Cache now contains 7 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,818] WARN [LeaderEpochCache topic-4-10] New epoch entry EpochEntry(epoch=10, startOffset=88) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=88)). Cache now contains 7 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,882] INFO [Partition topic-7-1 broker=1] topic-7-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-09 10:04:43,882] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:43,888] WARN [LeaderEpochCache topic-7-1] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,888] WARN [LeaderEpochCache __consumer_offsets-2] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,881] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 11 from offset 66. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-09 10:04:43,898] WARN [LeaderEpochCache topic-4-8] New epoch entry EpochEntry(epoch=11, startOffset=66) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=66)). Cache now contains 8 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,960] INFO [Partition topic-5-5 broker=1] topic-5-5 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-09 10:04:43,958] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 9 from offset 6. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:43,965] WARN [LeaderEpochCache topic-3-0] New epoch entry EpochEntry(epoch=9, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:43,961] WARN [LeaderEpochCache topic-5-5] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,058] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,062] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,005] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:44,060] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:44,068] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-09 10:04:44,076] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:44,083] INFO [Partition topic-3-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:44,065] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:44,091] INFO [Partition topic-6-0 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:44,098] INFO [Partition topic-6-0 broker=0] Expanding ISR from 0,3 to 0,3,1 (kafka.cluster.Partition)
[2019-08-09 10:04:44,079] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 10 from offset 258. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:44,114] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,122] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,113] WARN [LeaderEpochCache topic-4-2] New epoch entry EpochEntry(epoch=10, startOffset=258) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=258)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,152] INFO [Partition topic-5-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:44,169] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,171] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,245] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,249] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,298] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,301] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,329] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:44,337] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,344] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,341] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=13), topic-4-8 -> (offset=66, leaderEpoch=11), topic-4-4 -> (offset=502, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:44,364] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:44,380] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 6 from offset 2644. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,381] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:44,388] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:44,425] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 6 from offset 7. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,428] WARN [LeaderEpochCache topic-3-1] New epoch entry EpochEntry(epoch=6, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=7)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,601] INFO [Partition topic-5-3 broker=0] topic-5-3 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:44,605] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:44,610] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:44,623] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:44,660] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,672] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,674] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:04:44,679] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:04:44,736] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,737] WARN [LeaderEpochCache __consumer_offsets-47] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,782] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,790] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,882] INFO [Partition topic-6-1 broker=0] topic-6-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:44,885] WARN [LeaderEpochCache topic-6-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,893] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:04:44,893] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:44,898] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:04:44,951] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,955] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:44,988] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:44,989] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,122] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,125] WARN [LeaderEpochCache __consumer_offsets-35] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,169] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,177] WARN [LeaderEpochCache __consumer_offsets-44] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,204] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-09 10:04:45,211] INFO [Partition topic-6-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:45,203] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:04:45,220] INFO [Partition topic-3-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:04:45,221] INFO [Partition topic-6-1 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:04:45,230] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,239] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,241] INFO [Partition topic-5-3 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:04:45,278] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,300] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,404] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,405] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,449] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,464] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,462] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs-1\log-start-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-1\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-1\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-1\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-09 10:04:45,475] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-08-09 10:04:45,475] ERROR Uncaught exception in scheduled task 'kafka-log-start-offset-checkpoint' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs-1\log-start-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-1\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-1\log-start-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:611)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1$$anonfun$apply$34.apply(LogManager.scala:605)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:605)
	at kafka.log.LogManager$$anonfun$kafka$log$LogManager$$checkpointLogStartOffsetsInDir$1.apply(LogManager.scala:604)
	at scala.Option.foreach(Option.scala:257)
	at kafka.log.LogManager.kafka$log$LogManager$$checkpointLogStartOffsetsInDir(LogManager.scala:604)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$checkpointLogStartOffsets$1.apply(LogManager.scala:577)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at kafka.log.LogManager.checkpointLogStartOffsets(LogManager.scala:577)
	at kafka.log.LogManager$$anonfun$startup$4.apply$mcV$sp(LogManager.scala:411)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\log-start-offset-checkpoint.tmp -> C:\tmp\kafka-logs-1\log-start-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 25 more
[2019-08-09 10:04:45,489] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-3-1, topic-6-0, topic-7-1, topic-4-10, topic-4-1, topic-4-8, topic-3-0, topic-5-2, topic-4-3, topic-6-2, topic-4-7, topic-4-4, topic-4-0, topic-5-5, topic-5-4, topic-4-5, topic-7-2, topic-5-0, topic-6-1, topic-5-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:45,495] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-3-1, topic-6-0, topic-7-1, topic-4-10, topic-4-1, topic-4-8, topic-3-0, topic-5-2, topic-4-3, topic-6-2, topic-4-7, topic-4-4, topic-4-0, topic-5-5, topic-5-4, topic-4-5, topic-7-2, topic-5-0, topic-6-1, topic-5-6) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-09 10:04:45,518] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions topic-4-9,topic-4-11,topic-4-6,topic-4-2,topic-3-1,topic-6-0,topic-7-1,topic-4-10,topic-4-1,topic-4-8,topic-3-0,topic-5-2,topic-4-3,topic-6-2,topic-4-7,topic-4-4,topic-4-0,topic-5-5,topic-5-4,topic-4-5,topic-7-2,topic-5-0,topic-6-1,topic-5-6 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-08-09 10:04:45,551] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-08-09 10:04:45,576] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,592] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,589] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-08-09 10:04:45,717] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,734] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,736] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,742] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,751] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,753] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,757] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,762] WARN [LeaderEpochCache __consumer_offsets-32] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,762] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,763] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,767] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,767] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,768] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,768] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,769] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,769] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,769] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,770] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,770] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,770] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,771] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,772] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,773] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,774] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,774] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,775] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,778] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,778] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,779] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,779] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,780] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,781] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,781] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,784] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,785] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,786] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,789] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,789] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,790] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,790] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,790] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,790] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,790] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,798] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,796] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,813] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,813] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=6, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,814] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,814] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,820] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,837] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,851] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,877] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,878] WARN [LeaderEpochCache topic-2-0] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,885] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,896] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,924] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:04:45,927] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:45,926] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,953] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,961] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:45,986] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:45,976] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:45,986] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,020] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,026] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,011] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,027] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,080] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,133] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-7-1, topic-6-2, topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,164] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.blr.amer.dell.com:9093) for partitions Map(topic-4-6 -> (offset=97, leaderEpoch=10), topic-4-2 -> (offset=258, leaderEpoch=10), topic-7-1 -> (offset=0, leaderEpoch=2), topic-4-10 -> (offset=88, leaderEpoch=10), topic-6-2 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,148] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,192] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,193] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,193] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,195] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,196] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,196] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,197] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,197] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,197] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,198] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,198] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,199] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:04:46,202] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.blr.amer.dell.com:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=13), topic-4-8 -> (offset=66, leaderEpoch=11), topic-4-4 -> (offset=502, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,229] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,229] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,233] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:04:46,234] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:04:46,234] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:04:46,237] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error when sending leader epoch request for Map(topic-4-6 -> (currentLeaderEpoch=Optional[10], leaderEpoch=5), topic-4-2 -> (currentLeaderEpoch=Optional[10], leaderEpoch=5), topic-4-10 -> (currentLeaderEpoch=Optional[10], leaderEpoch=5), topic-6-2 -> (currentLeaderEpoch=Optional[2], leaderEpoch=1), topic-7-1 -> (currentLeaderEpoch=Optional[2], leaderEpoch=1)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchEpochEndOffsets(ReplicaFetcherThread.scala:305)
	at kafka.server.AbstractFetcherThread.truncateToEpochEndOffsets(AbstractFetcherThread.scala:185)
	at kafka.server.AbstractFetcherThread.maybeTruncate(AbstractFetcherThread.scala:168)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:46,239] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-6 as the leader reported an error: UNKNOWN_SERVER_ERROR (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,241] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_SERVER_ERROR (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,242] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-7-1 as the leader reported an error: UNKNOWN_SERVER_ERROR (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,242] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_SERVER_ERROR (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,242] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-6-2 as the leader reported an error: UNKNOWN_SERVER_ERROR (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:46,238] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=756030923, epoch=3) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:46,243] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=756030923, epoch=3)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:46,239] WARN Exception causing close of session 0x10005432d98002b: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:46,249] INFO Closed socket connection for client /127.0.0.1:60078 which had sessionid 0x10005432d98002b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:46,240] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1851463766, epoch=4) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:46,281] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1851463766, epoch=4)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:46,693] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs\replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,697] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-08-09 10:04:46,698] ERROR [ReplicaManager broker=0] Error while writing to highwatermark file in directory C:\tmp\kafka-logs (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs\replication-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,704] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, topic-7-0, __consumer_offsets-30, __consumer_offsets-8, topic-5-7, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, topic-4-9, topic-4-11, __consumer_offsets-9, __consumer_offsets-46, topic-4-6, topic-4-2, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, topic-6-0, topic-7-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, topic-5-3, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, topic-4-10, topic-4-1, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-4-8, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, topic-5-2, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, topic-4-3, __consumer_offsets-11, topic-6-2, topic-4-7, topic-4-4, topic-4-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-5-1, topic-5-4, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, topic-4-5, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, topic-7-2, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40, topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,708] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, topic-7-0, __consumer_offsets-30, __consumer_offsets-8, topic-5-7, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, topic-4-9, topic-4-11, __consumer_offsets-9, __consumer_offsets-46, topic-4-6, topic-4-2, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, topic-6-0, topic-7-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, topic-5-3, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, topic-4-10, topic-4-1, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-4-8, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, topic-5-2, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, topic-4-3, __consumer_offsets-11, topic-6-2, topic-4-7, topic-4-4, topic-4-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-5-1, topic-5-4, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, topic-4-5, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, topic-7-2, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40, topic-6-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-09 10:04:46,716] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs\replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,744] ERROR [ReplicaManager broker=0] Error while writing to highwatermark file in directory C:\tmp\kafka-logs (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs\replication-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,750] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,topic-7-0,__consumer_offsets-30,__consumer_offsets-8,topic-5-7,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,topic-4-9,topic-4-11,__consumer_offsets-9,__consumer_offsets-46,topic-4-6,topic-4-2,topic-3-1,topic-2-0,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,topic-6-0,topic-7-1,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,topic-5-3,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,topic-4-10,topic-4-1,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,topic-4-8,topic-3-0,__consumer_offsets-15,__consumer_offsets-24,topic-5-2,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,topic-4-3,__consumer_offsets-11,topic-6-2,topic-4-7,topic-4-4,topic-4-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,topic-5-1,topic-5-4,topic-1-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,topic-4-5,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,topic-7-2,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40,topic-6-1 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-08-09 10:04:46,758] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2019-08-09 10:04:46,767] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-08-09 10:04:46,795] ERROR Error while writing to checkpoint file C:\tmp\kafka-logs-3\replication-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-3\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-3\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,816] ERROR [ReplicaManager broker=3] Error while writing to highwatermark file in directory C:\tmp\kafka-logs-3 (kafka.server.ReplicaManager)
org.apache.kafka.common.errors.KafkaStorageException: Error while writing to checkpoint file C:\tmp\kafka-logs-3\replication-offset-checkpoint
Caused by: java.nio.file.FileAlreadyExistsException: C:\tmp\kafka-logs-3\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\replication-offset-checkpoint
	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.server.checkpoints.CheckpointFile.liftedTree1$1(CheckpointFile.scala:72)
	at kafka.server.checkpoints.CheckpointFile.write(CheckpointFile.scala:50)
	at kafka.server.checkpoints.OffsetCheckpointFile.write(OffsetCheckpointFile.scala:59)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2$$anonfun$apply$50.apply(ReplicaManager.scala:1404)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1404)
	at kafka.server.ReplicaManager$$anonfun$checkpointHighWatermarks$2.apply(ReplicaManager.scala:1401)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.immutable.Map$Map1.foreach(Map.scala:116)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at kafka.server.ReplicaManager.checkpointHighWatermarks(ReplicaManager.scala:1401)
	at kafka.server.ReplicaManager$$anonfun$1.apply$mcV$sp(ReplicaManager.scala:248)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:63)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-3\replication-offset-checkpoint.tmp -> C:\tmp\kafka-logs-3\replication-offset-checkpoint
		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-08-09 10:04:46,816] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\kafka-logs-3 (kafka.server.ReplicaManager)
[2019-08-09 10:04:46,862] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-7-0, topic-5-7, topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-6-0, topic-7-1, topic-5-3, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-6-2, topic-4-7, topic-4-4, topic-4-0, topic-5-5, topic-5-1, topic-4-5, topic-5-0, topic-6-1, topic-5-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:46,868] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(topic-7-0, topic-5-7, topic-4-9, topic-4-11, topic-4-6, topic-4-2, topic-6-0, topic-7-1, topic-5-3, topic-4-10, topic-4-1, topic-4-8, topic-4-3, topic-6-2, topic-4-7, topic-4-4, topic-4-0, topic-5-5, topic-5-1, topic-4-5, topic-5-0, topic-6-1, topic-5-6) (kafka.server.ReplicaAlterLogDirsManager)
[2019-08-09 10:04:46,888] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions topic-7-0,topic-5-7,topic-4-9,topic-4-11,topic-4-6,topic-4-2,topic-6-0,topic-7-1,topic-5-3,topic-4-10,topic-4-1,topic-4-8,topic-4-3,topic-6-2,topic-4-7,topic-4-4,topic-4-0,topic-5-5,topic-5-1,topic-4-5,topic-5-0,topic-6-1,topic-5-6 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-3. (kafka.server.ReplicaManager)
[2019-08-09 10:04:46,889] INFO Stopping serving logs in dir C:\tmp\kafka-logs-3 (kafka.log.LogManager)
[2019-08-09 10:04:46,896] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-3 have failed (kafka.log.LogManager)
[2019-08-09 10:04:47,414] WARN Exception causing close of session 0x10005432d980029: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:47,472] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=501183537, epoch=4) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:47,478] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=501183537, epoch=4)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:47,419] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60058 which had sessionid 0x10005432d980029 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:47,564] WARN Exception causing close of session 0x10005432d98002a: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:47,572] INFO Closed socket connection for client /127.0.0.1:60069 which had sessionid 0x10005432d98002a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:04:49,423] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:49,426] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=756030923, epoch=INITIAL) to node 1: java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9093 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:49,431] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={topic-4-10=(fetchOffset=88, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10]), topic-4-2=(fetchOffset=258, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10]), topic-4-6=(fetchOffset=97, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=756030923, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:49,735] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:49,840] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:49,844] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:50,696] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:50,728] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=501183537, epoch=INITIAL) to node 3: java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:50,743] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={topic-4-4=(fetchOffset=502, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[12]), topic-4-0=(fetchOffset=134, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[13]), topic-4-8=(fetchOffset=66, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[11])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=501183537, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:50,947] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:51,046] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:51,130] WARN [Controller id=2, targetBrokerId=0] Connection to node 0 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:51,993] INFO Expiring session 0x10005432d980029, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:52,000] INFO Expiring session 0x10005432d98002b, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:52,001] INFO Expiring session 0x10005432d98002a, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:04:52,002] INFO Processed session termination for sessionid: 0x10005432d980029 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:52,002] INFO Processed session termination for sessionid: 0x10005432d98002b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:52,003] INFO Processed session termination for sessionid: 0x10005432d98002a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:04:52,144] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-6, topic-4-2, topic-4-10, topic-4-8, topic-4-4, topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:52,162] INFO [Partition topic-4-6 broker=2] topic-4-6 starts at Leader Epoch 11 from offset 97. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-09 10:04:52,177] WARN [LeaderEpochCache topic-4-6] New epoch entry EpochEntry(epoch=11, startOffset=97) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=97)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,231] INFO [Partition topic-4-0 broker=2] topic-4-0 starts at Leader Epoch 14 from offset 134. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-08-09 10:04:52,287] WARN [LeaderEpochCache topic-4-0] New epoch entry EpochEntry(epoch=14, startOffset=134) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=134)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,429] INFO [Partition topic-4-10 broker=2] topic-4-10 starts at Leader Epoch 11 from offset 88. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-09 10:04:52,464] WARN [LeaderEpochCache topic-4-10] New epoch entry EpochEntry(epoch=11, startOffset=88) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=88)). Cache now contains 7 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,520] INFO [Partition topic-4-4 broker=2] topic-4-4 starts at Leader Epoch 13 from offset 502. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-08-09 10:04:52,539] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (W101GKNGH2.blr.amer.dell.com/172.20.104.65:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-08-09 10:04:52,547] WARN [LeaderEpochCache topic-4-4] New epoch entry EpochEntry(epoch=13, startOffset=502) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=502)). Cache now contains 7 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,565] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=756030923, epoch=INITIAL) to node 1: java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9093 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-08-09 10:04:52,596] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={topic-4-10=(fetchOffset=88, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10]), topic-4-2=(fetchOffset=258, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10]), topic-4-6=(fetchOffset=97, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[10])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=756030923, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to W101GKNGH2.blr.amer.dell.com:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-08-09 10:04:52,621] INFO [Partition topic-4-8 broker=2] topic-4-8 starts at Leader Epoch 12 from offset 66. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:04:52,626] WARN [LeaderEpochCache topic-4-8] New epoch entry EpochEntry(epoch=12, startOffset=66) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=10, startOffset=66)). Cache now contains 8 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,667] INFO [Partition topic-4-2 broker=2] topic-4-2 starts at Leader Epoch 11 from offset 258. Previous Leader Epoch was: 10 (kafka.cluster.Partition)
[2019-08-09 10:04:52,678] WARN [LeaderEpochCache topic-4-2] New epoch entry EpochEntry(epoch=11, startOffset=258) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=258)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,730] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,737] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,737] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,751] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,759] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,759] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:04:52,769] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-7-0, topic-4-9, topic-4-11, topic-4-1, topic-4-3, topic-4-7, topic-4-5, topic-7-2) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:04:52,770] INFO [Partition topic-4-9 broker=2] topic-4-9 starts at Leader Epoch 11 from offset 83. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:52,774] WARN [LeaderEpochCache topic-4-9] New epoch entry EpochEntry(epoch=11, startOffset=83) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=83)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,831] INFO [Partition topic-4-3 broker=2] topic-4-3 starts at Leader Epoch 12 from offset 136. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:52,840] WARN [LeaderEpochCache topic-4-3] New epoch entry EpochEntry(epoch=12, startOffset=136) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=136)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,877] INFO [Partition topic-7-0 broker=2] topic-7-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-08-09 10:04:52,881] WARN [LeaderEpochCache topic-7-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:52,950] INFO [Partition topic-4-7 broker=2] topic-4-7 starts at Leader Epoch 12 from offset 133. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:52,963] WARN [LeaderEpochCache topic-4-7] New epoch entry EpochEntry(epoch=12, startOffset=133) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=133)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:53,015] INFO [Partition topic-4-1 broker=2] topic-4-1 starts at Leader Epoch 11 from offset 132. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:53,024] WARN [LeaderEpochCache topic-4-1] New epoch entry EpochEntry(epoch=11, startOffset=132) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=132)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:53,073] INFO [Partition topic-4-5 broker=2] topic-4-5 starts at Leader Epoch 12 from offset 216. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-08-09 10:04:53,077] WARN [LeaderEpochCache topic-4-5] New epoch entry EpochEntry(epoch=12, startOffset=216) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=216)). Cache now contains 6 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:53,107] INFO [Partition topic-4-11 broker=2] topic-4-11 starts at Leader Epoch 11 from offset 64. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-08-09 10:04:53,110] WARN [LeaderEpochCache topic-4-11] New epoch entry EpochEntry(epoch=11, startOffset=64) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=64)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:04:53,146] INFO [Partition topic-7-2 broker=2] topic-7-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-08-09 10:04:53,148] WARN [LeaderEpochCache topic-7-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-08-09 10:05:03,917] INFO Accepted socket connection from /127.0.0.1:52597 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:05:03,919] INFO Client attempting to establish new session at /127.0.0.1:52597 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:05:03,922] INFO Established session 0x10005432d98002c with negotiated timeout 30000 for client /127.0.0.1:52597 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:05:04,378] WARN Exception causing close of session 0x10005432d98002c: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:05:04,378] INFO Closed socket connection for client /127.0.0.1:52597 which had sessionid 0x10005432d98002c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:05:23,994] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-09 10:05:24,482] INFO starting (kafka.server.KafkaServer)
[2019-08-09 10:05:24,484] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-09 10:05:24,507] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:05:24,520] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,521] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,521] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,521] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,521] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,521] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,522] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,523] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,524] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,526] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:05:24,557] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:05:24,559] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:05:24,562] INFO Accepted socket connection from /127.0.0.1:52758 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:05:24,563] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:05:24,567] INFO Client attempting to establish new session at /127.0.0.1:52758 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:05:24,570] INFO Established session 0x10005432d98002d with negotiated timeout 6000 for client /127.0.0.1:52758 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:05:24,573] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98002d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:05:24,577] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:05:24,638] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x1 zxid:0x532 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,650] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x2 zxid:0x533 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,653] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x3 zxid:0x534 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,655] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x4 zxid:0x535 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,657] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x5 zxid:0x536 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,661] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x6 zxid:0x537 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,663] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x7 zxid:0x538 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,665] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x8 zxid:0x539 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,668] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0x9 zxid:0x53a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,672] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0xa zxid:0x53b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,674] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0xb zxid:0x53c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,676] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0xc zxid:0x53d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,678] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002d type:create cxid:0xd zxid:0x53e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:24,881] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-09 10:05:24,943] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:05:24,954] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:05:24,981] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:05:24,982] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:05:24,984] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:05:25,038] INFO Loading logs. (kafka.log.LogManager)
[2019-08-09 10:05:25,115] WARN [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-1-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-1-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565180185902}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:25,116] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,201] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,208] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:25,209] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,260] INFO [ProducerStateManager partition=topic-1-0] Writing producer snapshot at offset 111 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,315] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 111 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,320] INFO [ProducerStateManager partition=topic-1-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-1-0\00000000000000000111.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,330] INFO [Log partition=topic-1-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 111 in 250 ms (kafka.log.Log)
[2019-08-09 10:05:25,348] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:25,348] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,403] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,410] INFO [Log partition=topic-2-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-08-09 10:05:25,424] WARN [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-3-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-3-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249177417}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:25,425] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,470] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,474] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:25,474] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,523] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,555] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,560] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,566] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 152 ms (kafka.log.Log)
[2019-08-09 10:05:25,581] WARN [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249210454}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:25,582] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,628] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,631] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:25,631] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,684] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,716] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,722] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,728] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 158 ms (kafka.log.Log)
[2019-08-09 10:05:25,771] WARN [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565266550010}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:25,771] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,823] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,829] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:25,829] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,897] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,939] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 134 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:25,945] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-0\00000000000000000134.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:25,952] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 134 in 221 ms (kafka.log.Log)
[2019-08-09 10:05:26,001] WARN [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565266410071}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,001] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,048] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,051] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,051] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,103] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,125] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,129] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-1\00000000000000000132.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,133] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 132 in 171 ms (kafka.log.Log)
[2019-08-09 10:05:26,143] WARN [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,144] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,186] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,189] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,190] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,241] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,266] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 88 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,271] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-10\00000000000000000088.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,276] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 88 in 140 ms (kafka.log.Log)
[2019-08-09 10:05:26,289] WARN [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,289] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,335] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,338] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,338] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,389] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,408] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 64 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,413] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-11\00000000000000000064.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,417] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 64 in 137 ms (kafka.log.Log)
[2019-08-09 10:05:26,456] WARN [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270548438}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,457] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,505] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,508] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,509] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,564] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,587] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 258 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,591] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-2\00000000000000000258.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,595] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 258 in 175 ms (kafka.log.Log)
[2019-08-09 10:05:26,635] WARN [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268749953}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,636] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,680] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,683] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,683] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,733] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,756] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 136 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,761] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-3\00000000000000000136.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,764] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 136 in 166 ms (kafka.log.Log)
[2019-08-09 10:05:26,803] WARN [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-4\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-4\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268812855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,803] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,854] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,857] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:26,857] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,914] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,948] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 502 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:26,952] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-4\00000000000000000502.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:26,957] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 502 in 190 ms (kafka.log.Log)
[2019-08-09 10:05:26,994] WARN [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262294563}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:26,994] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,041] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,046] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,046] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,097] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,122] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 216 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,127] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-5\00000000000000000216.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,131] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 216 in 172 ms (kafka.log.Log)
[2019-08-09 10:05:27,142] WARN [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-6\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-6\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:27,143] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,186] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,189] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,190] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,242] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,266] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 97 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,270] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-6\00000000000000000097.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,276] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 97 in 141 ms (kafka.log.Log)
[2019-08-09 10:05:27,316] WARN [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268035616}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:27,316] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,363] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,368] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,368] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,423] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,445] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 133 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,449] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-7\00000000000000000133.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,453] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 133 in 174 ms (kafka.log.Log)
[2019-08-09 10:05:27,463] WARN [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:27,464] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,503] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,506] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,506] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,736] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,767] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 66 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,772] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-8\00000000000000000066.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,775] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 66 in 320 ms (kafka.log.Log)
[2019-08-09 10:05:27,785] WARN [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\topic-4-9\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\topic-4-9\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:27,785] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,826] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,829] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,829] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,873] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,892] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 83 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,897] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\topic-4-9\00000000000000000083.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:27,901] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 83 in 124 ms (kafka.log.Log)
[2019-08-09 10:05:27,918] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,919] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,972] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:27,978] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-08-09 10:05:27,993] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:27,994] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,046] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,052] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-08-09 10:05:28,064] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,064] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,115] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,120] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-09 10:05:28,130] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,130] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,181] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,187] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-08-09 10:05:28,198] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,199] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,250] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,255] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-09 10:05:28,270] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,270] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,329] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,338] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-08-09 10:05:28,351] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,351] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,410] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,416] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-08-09 10:05:28,428] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,428] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,480] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,485] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:28,499] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,499] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,551] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,556] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-09 10:05:28,569] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,570] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,624] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,629] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-09 10:05:28,639] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,640] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,686] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,692] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-09 10:05:28,703] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,704] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,758] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,764] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-08-09 10:05:28,774] WARN [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853503}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:28,774] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,819] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:28,823] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,823] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,873] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:28,912] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,916] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:28,921] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 156 ms (kafka.log.Log)
[2019-08-09 10:05:28,932] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:28,932] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,984] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:28,990] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:29,000] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,001] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,054] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,059] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:29,070] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,071] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,128] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,134] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-08-09 10:05:29,146] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,147] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,203] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,208] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-08-09 10:05:29,219] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,220] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,275] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,283] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-08-09 10:05:29,295] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,295] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,347] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,352] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:29,366] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,366] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,422] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,432] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-08-09 10:05:29,499] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,500] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,555] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,560] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 115 ms (kafka.log.Log)
[2019-08-09 10:05:29,571] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,571] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,625] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,636] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-08-09 10:05:29,646] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,647] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,701] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,707] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-09 10:05:29,719] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,719] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,785] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,791] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-08-09 10:05:29,811] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,815] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,887] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,893] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2019-08-09 10:05:29,906] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565265441688}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:29,906] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:29,973] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:29,992] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:29,993] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,076] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:30,111] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,118] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-21\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:30,124] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 229 ms (kafka.log.Log)
[2019-08-09 10:05:30,143] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,143] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,201] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,207] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-08-09 10:05:30,217] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,218] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,271] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,276] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:30,285] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,285] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,335] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,339] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-09 10:05:30,348] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,348] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,400] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,405] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-08-09 10:05:30,416] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,416] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,469] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,474] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:30,484] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,484] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,539] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,544] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-09 10:05:30,556] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,556] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,608] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,613] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:05:30,626] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,626] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,689] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,695] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-08-09 10:05:30,708] WARN [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853503}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:30,708] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,753] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:30,757] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,757] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,811] INFO [ProducerStateManager partition=__consumer_offsets-3] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:30,843] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,847] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-3\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:30,852] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 156 ms (kafka.log.Log)
[2019-08-09 10:05:30,862] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:30,862] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,915] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:30,920] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-09 10:05:30,928] WARN [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565248895721}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:30,928] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,007] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2644 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,013] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,014] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,085] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2644 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,122] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 2644 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,126] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-31\00000000000000002644.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,129] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2644 in 208 ms (kafka.log.Log)
[2019-08-09 10:05:31,138] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565242844797}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:31,139] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,182] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,185] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,186] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,234] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,267] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,272] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,276] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 146 ms (kafka.log.Log)
[2019-08-09 10:05:31,288] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,288] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,343] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,348] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-09 10:05:31,356] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,357] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,406] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,413] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-09 10:05:31,422] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,422] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,470] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,475] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-09 10:05:31,483] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,483] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,532] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,537] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-09 10:05:31,546] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,547] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,595] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,600] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-08-09 10:05:31,610] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,610] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,659] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,664] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-08-09 10:05:31,673] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249853499}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:31,673] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,713] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,716] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,716] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,764] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,796] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,804] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-39\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:31,809] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 144 ms (kafka.log.Log)
[2019-08-09 10:05:31,822] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,823] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,880] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,899] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 88 ms (kafka.log.Log)
[2019-08-09 10:05:31,909] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,910] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,966] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:31,975] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-08-09 10:05:31,987] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:31,988] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,044] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,060] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-08-09 10:05:32,072] WARN [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249253502}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:32,072] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,126] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,136] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,137] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,198] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,231] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,239] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,244] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 182 ms (kafka.log.Log)
[2019-08-09 10:05:32,261] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,261] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,323] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,332] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-08-09 10:05:32,343] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,344] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,410] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,418] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 85 ms (kafka.log.Log)
[2019-08-09 10:05:32,429] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,429] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,491] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,499] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-08-09 10:05:32,510] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,510] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,562] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,570] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-09 10:05:32,584] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,585] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,645] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,663] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-08-09 10:05:32,675] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,675] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,730] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,735] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-09 10:05:32,771] WARN [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565265072688}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:05:32,771] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,817] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 164 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,821] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,822] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,873] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 164 (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,917] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 164 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,923] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000164.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:05:32,928] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 164 in 192 ms (kafka.log.Log)
[2019-08-09 10:05:32,943] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:32,943] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:32,998] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,003] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-08-09 10:05:33,014] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:33,015] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,068] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,073] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-09 10:05:33,083] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:33,083] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,181] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,187] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 113 ms (kafka.log.Log)
[2019-08-09 10:05:33,199] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:33,199] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,272] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,280] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-08-09 10:05:33,295] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:05:33,295] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,357] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:05:33,366] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 84 ms (kafka.log.Log)
[2019-08-09 10:05:33,369] INFO Logs loading complete in 8330 ms. (kafka.log.LogManager)
[2019-08-09 10:05:33,384] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-09 10:05:33,385] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-09 10:05:33,717] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-08-09 10:05:33,769] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-09 10:05:33,805] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:33,805] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:33,805] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:33,846] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-09 10:05:33,953] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:05:33,956] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:05:33,958] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:05:34,030] INFO Expiring session 0x10005432d98002c, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:05:34,036] INFO Processed session termination for sessionid: 0x10005432d98002c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:05:34,076] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:34,077] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:34,076] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:05:34,096] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:34,098] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:34,111] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:34,118] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:15000,blockEndProducerId:15999) by writing to Zk with path version 16 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-09 10:05:34,144] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:05:34,148] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:05:34,152] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-09 10:05:34,199] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-09 10:05:34,232] INFO [SocketServer brokerId=0] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-09 10:05:34,241] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:05:34,242] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:05:34,244] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-08-09 10:05:34,368] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,375] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,384] INFO [Partition topic-4-9 broker=0] No checkpointed highwatermark is found for partition topic-4-9 (kafka.cluster.Partition)
[2019-08-09 10:05:34,384] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,385] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,385] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,386] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,394] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-08-09 10:05:34,394] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,397] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-08-09 10:05:34,397] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,402] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-08-09 10:05:34,403] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,410] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-08-09 10:05:34,411] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,412] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,412] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,415] INFO [Partition topic-4-6 broker=0] No checkpointed highwatermark is found for partition topic-4-6 (kafka.cluster.Partition)
[2019-08-09 10:05:34,415] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,415] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,419] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-08-09 10:05:34,427] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,432] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-08-09 10:05:34,433] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,438] INFO [Partition topic-5-7 broker=0] No checkpointed highwatermark is found for partition topic-5-7 (kafka.cluster.Partition)
[2019-08-09 10:05:34,438] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,443] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-08-09 10:05:34,445] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,449] INFO [Partition topic-5-4 broker=0] No checkpointed highwatermark is found for partition topic-5-4 (kafka.cluster.Partition)
[2019-08-09 10:05:34,449] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,454] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-08-09 10:05:34,456] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,457] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,459] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,483] INFO [Partition topic-4-3 broker=0] No checkpointed highwatermark is found for partition topic-4-3 (kafka.cluster.Partition)
[2019-08-09 10:05:34,489] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,496] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,509] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-08-09 10:05:34,509] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,514] INFO [Partition topic-1-0 broker=0] No checkpointed highwatermark is found for partition topic-1-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,515] INFO Replica loaded for partition topic-1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,520] INFO [Partition topic-5-1 broker=0] No checkpointed highwatermark is found for partition topic-5-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,520] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,521] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,524] INFO [Partition topic-4-0 broker=0] No checkpointed highwatermark is found for partition topic-4-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,531] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,531] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,531] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,535] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,535] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,538] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-08-09 10:05:34,539] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,543] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-08-09 10:05:34,543] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,545] INFO [Partition topic-6-2 broker=0] No checkpointed highwatermark is found for partition topic-6-2 (kafka.cluster.Partition)
[2019-08-09 10:05:34,546] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,549] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-08-09 10:05:34,550] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,553] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-08-09 10:05:34,553] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,556] INFO [Partition topic-7-0 broker=0] No checkpointed highwatermark is found for partition topic-7-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,557] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,559] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,569] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,572] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-08-09 10:05:34,572] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,578] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-08-09 10:05:34,578] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,582] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-08-09 10:05:34,582] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,589] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,593] INFO [Partition topic-4-10 broker=0] No checkpointed highwatermark is found for partition topic-4-10 (kafka.cluster.Partition)
[2019-08-09 10:05:34,594] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,594] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,594] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,598] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-08-09 10:05:34,599] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,603] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-08-09 10:05:34,606] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,606] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,609] INFO [Partition topic-4-7 broker=0] No checkpointed highwatermark is found for partition topic-4-7 (kafka.cluster.Partition)
[2019-08-09 10:05:34,610] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,610] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,610] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,612] INFO [Partition topic-7-1 broker=0] No checkpointed highwatermark is found for partition topic-7-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,613] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,615] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-08-09 10:05:34,618] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,620] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-08-09 10:05:34,621] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,624] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-08-09 10:05:34,624] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,627] INFO [Partition topic-6-0 broker=0] No checkpointed highwatermark is found for partition topic-6-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,627] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,627] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,627] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,627] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,629] INFO [Partition topic-4-4 broker=0] No checkpointed highwatermark is found for partition topic-4-4 (kafka.cluster.Partition)
[2019-08-09 10:05:34,633] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,636] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-08-09 10:05:34,636] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,639] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-08-09 10:05:34,639] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,645] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-08-09 10:05:34,646] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,650] INFO [Partition topic-4-1 broker=0] No checkpointed highwatermark is found for partition topic-4-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,650] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,650] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,650] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,651] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,653] INFO [Partition topic-5-2 broker=0] No checkpointed highwatermark is found for partition topic-5-2 (kafka.cluster.Partition)
[2019-08-09 10:05:34,653] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,660] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-08-09 10:05:34,660] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,662] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-08-09 10:05:34,663] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,665] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-08-09 10:05:34,665] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,668] INFO [Partition topic-3-0 broker=0] No checkpointed highwatermark is found for partition topic-3-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,668] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,671] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-08-09 10:05:34,671] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,673] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-08-09 10:05:34,673] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,674] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,674] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,677] INFO [Partition topic-4-8 broker=0] No checkpointed highwatermark is found for partition topic-4-8 (kafka.cluster.Partition)
[2019-08-09 10:05:34,679] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,679] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,682] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-08-09 10:05:34,682] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,685] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-08-09 10:05:34,685] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,687] INFO [Partition topic-4-5 broker=0] No checkpointed highwatermark is found for partition topic-4-5 (kafka.cluster.Partition)
[2019-08-09 10:05:34,688] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,690] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,690] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,690] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,691] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,692] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,692] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,695] INFO [Partition topic-4-2 broker=0] No checkpointed highwatermark is found for partition topic-4-2 (kafka.cluster.Partition)
[2019-08-09 10:05:34,695] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,698] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-08-09 10:05:34,698] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,702] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-08-09 10:05:34,702] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,705] INFO [Partition topic-3-1 broker=0] No checkpointed highwatermark is found for partition topic-3-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,705] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,710] INFO [Partition topic-5-3 broker=0] No checkpointed highwatermark is found for partition topic-5-3 (kafka.cluster.Partition)
[2019-08-09 10:05:34,712] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,712] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,712] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,712] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,715] INFO [Partition topic-4-11 broker=0] No checkpointed highwatermark is found for partition topic-4-11 (kafka.cluster.Partition)
[2019-08-09 10:05:34,715] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,718] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-08-09 10:05:34,718] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,720] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-08-09 10:05:34,720] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,725] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-08-09 10:05:34,726] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,726] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,729] INFO [Partition topic-7-2 broker=0] No checkpointed highwatermark is found for partition topic-7-2 (kafka.cluster.Partition)
[2019-08-09 10:05:34,729] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,730] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,736] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-08-09 10:05:34,736] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,740] INFO [Partition topic-6-1 broker=0] No checkpointed highwatermark is found for partition topic-6-1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,740] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,745] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-08-09 10:05:34,745] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,749] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-08-09 10:05:34,753] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,757] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-08-09 10:05:34,757] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,762] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-08-09 10:05:34,763] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,769] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-08-09 10:05:34,770] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,773] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-08-09 10:05:34,773] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,777] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-08-09 10:05:34,778] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,798] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-08-09 10:05:34,798] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,802] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-08-09 10:05:34,802] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,805] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-08-09 10:05:34,805] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,808] INFO [Partition topic-2-0 broker=0] No checkpointed highwatermark is found for partition topic-2-0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,810] INFO Replica loaded for partition topic-2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,813] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-08-09 10:05:34,814] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:34,816] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-4-1, topic-4-5, topic-7-0, topic-4-9, topic-4-2, topic-4-6, topic-4-10, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-7-2, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:05:34,878] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:05:34,882] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=3), topic-4-9 -> (offset=0, leaderEpoch=11), topic-4-11 -> (offset=0, leaderEpoch=11), topic-4-6 -> (offset=0, leaderEpoch=11), topic-4-2 -> (offset=0, leaderEpoch=11), topic-4-10 -> (offset=0, leaderEpoch=11), topic-4-1 -> (offset=0, leaderEpoch=11), topic-4-8 -> (offset=0, leaderEpoch=12), topic-4-3 -> (offset=0, leaderEpoch=12), topic-4-7 -> (offset=0, leaderEpoch=12), topic-4-4 -> (offset=0, leaderEpoch=13), topic-4-0 -> (offset=0, leaderEpoch=14), topic-4-5 -> (offset=0, leaderEpoch=12), topic-7-2 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:05:34,914] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:05:34,922] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:05:34,924] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:05:34,925] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:05:34,925] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:05:34,925] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:05:34,925] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:05:34,926] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:05:34,926] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:05:34,926] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:05:34,926] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:05:34,926] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:05:34,931] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, topic-5-7, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, topic-3-1, topic-2-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, topic-6-0, topic-7-1, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, topic-5-3, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, topic-3-0, __consumer_offsets-15, __consumer_offsets-24, topic-5-2, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, topic-6-2, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, topic-5-1, topic-5-4, topic-1-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40, topic-6-1) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:05:34,933] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-7-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:05:34,934] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:05:34,935] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition topic-7-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:05:34,936] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:05:34,939] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,959] INFO [Partition topic-7-0 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,964] INFO [Partition topic-7-2 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,969] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,973] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,980] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,983] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,988] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:34,987] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,993] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:34,998] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,006] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,006] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,009] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,012] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,023] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,025] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,029] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2 to 2,0 (kafka.cluster.Partition)
[2019-08-09 10:05:35,044] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,059] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,072] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,073] INFO [Partition topic-5-7 broker=0] topic-5-7 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,090] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,112] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,129] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,130] INFO [Partition topic-5-4 broker=0] topic-5-4 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,142] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,157] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,172] INFO [Partition topic-1-0 broker=0] topic-1-0 starts at Leader Epoch 8 from offset 111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,190] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,190] INFO [Partition topic-5-1 broker=0] topic-5-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,205] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,219] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,233] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,252] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,252] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,253] INFO [Partition topic-6-2 broker=0] topic-6-2 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,267] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,280] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,293] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,307] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,322] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 8 from offset 164. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,338] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,353] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,366] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,366] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,366] INFO [Partition topic-7-1 broker=0] topic-7-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,379] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,392] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,404] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,418] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,418] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,418] INFO [Partition topic-6-0 broker=0] topic-6-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,431] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,445] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,459] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,473] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,473] INFO [Partition topic-5-2 broker=0] topic-5-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,487] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,501] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,513] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,513] INFO [Partition topic-3-0 broker=0] topic-3-0 starts at Leader Epoch 12 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,528] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,541] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,554] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,570] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,584] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,598] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,610] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 8 from offset 2644. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,623] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,623] INFO [Partition topic-3-1 broker=0] topic-3-1 starts at Leader Epoch 9 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,637] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,637] INFO [Partition topic-5-3 broker=0] topic-5-3 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,650] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,664] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,677] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,692] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,692] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:05:35,692] INFO [Partition topic-6-1 broker=0] topic-6-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,707] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,721] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,735] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,750] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,767] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,780] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,792] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,814] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,828] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,842] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,859] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,876] INFO [Partition topic-2-0 broker=0] topic-2-0 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,892] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:05:35,918] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,922] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,928] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,929] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,930] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,930] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,931] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,933] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,933] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,934] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,935] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,935] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,935] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,936] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,936] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,937] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,937] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,938] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,938] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,940] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,941] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,942] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,947] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,947] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:35,947] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,030] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:36,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 94 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,039] INFO [GroupCoordinator 0]: Loading group metadata for group-1 with generation 24 (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:36,046] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,061] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,066] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,069] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,071] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,072] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,072] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,073] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,080] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,086] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,087] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,093] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,104] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,106] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,108] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,110] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,111] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,117] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,119] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,122] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,123] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,124] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,125] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,126] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,126] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,127] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,127] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,128] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,129] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,131] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:36,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:05:37,875] INFO [GroupCoordinator 0]: Preparing to rebalance group group-1 in state PreparingRebalance with old generation 24 (__consumer_offsets-49) (reason: Updating metadata for member rdkafka-428eb069-4afb-4a24-9f92-7c476aeb2a02) (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:37,881] INFO [GroupCoordinator 0]: Stabilized group group-1 generation 25 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:05:37,904] INFO [GroupCoordinator 0]: Assignment received from leader for group group-1 for generation 25 (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:06:02,477] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-09 10:06:03,008] INFO starting (kafka.server.KafkaServer)
[2019-08-09 10:06:03,010] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-09 10:06:03,040] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:03,057] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,058] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,060] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,061] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,062] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,064] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,065] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,066] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,067] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,068] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,069] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,072] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,073] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,074] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,074] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,077] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:03,109] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:03,111] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:03,114] INFO Accepted socket connection from /127.0.0.1:52815 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:06:03,115] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:03,121] INFO Client attempting to establish new session at /127.0.0.1:52815 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:03,123] INFO Established session 0x10005432d98002e with negotiated timeout 6000 for client /127.0.0.1:52815 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:03,126] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98002e, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:03,131] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:03,201] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x1 zxid:0x592 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,215] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x2 zxid:0x593 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,218] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x3 zxid:0x594 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,221] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x4 zxid:0x595 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,224] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x5 zxid:0x596 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,226] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x6 zxid:0x597 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,228] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x7 zxid:0x598 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,230] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x8 zxid:0x599 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,234] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0x9 zxid:0x59a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,237] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0xa zxid:0x59b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,240] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0xb zxid:0x59c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,242] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0xc zxid:0x59d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,245] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002e type:create cxid:0xd zxid:0x59e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:03,472] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-09 10:06:03,555] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:06:03,570] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:06:03,621] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:03,622] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:03,624] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:03,678] INFO Loading logs. (kafka.log.LogManager)
[2019-08-09 10:06:03,754] WARN [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-3-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-3-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565243085196}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:03,756] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:03,849] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:03,858] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:03,859] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:03,913] INFO [ProducerStateManager partition=topic-3-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:03,970] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:03,976] INFO [ProducerStateManager partition=topic-3-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:03,991] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 282 ms (kafka.log.Log)
[2019-08-09 10:06:04,013] WARN [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565243088233}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,014] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,068] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,072] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,073] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,125] INFO [ProducerStateManager partition=topic-3-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,149] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,155] INFO [ProducerStateManager partition=topic-3-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-3-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,160] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 160 ms (kafka.log.Log)
[2019-08-09 10:06:04,177] WARN [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,177] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,230] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,234] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,234] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,296] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,330] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 134 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,337] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-0\00000000000000000134.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,343] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 134 in 177 ms (kafka.log.Log)
[2019-08-09 10:06:04,358] WARN [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,359] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,414] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,418] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,419] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,483] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,507] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,512] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-1\00000000000000000132.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,517] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 132 in 169 ms (kafka.log.Log)
[2019-08-09 10:06:04,531] WARN [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,531] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,578] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,581] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,581] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,639] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,682] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 88 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,688] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-10\00000000000000000088.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,693] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 88 in 170 ms (kafka.log.Log)
[2019-08-09 10:06:04,707] WARN [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,707] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,757] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,761] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,763] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,837] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,858] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 64 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,862] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-11\00000000000000000064.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,867] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 64 in 171 ms (kafka.log.Log)
[2019-08-09 10:06:04,879] WARN [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:04,880] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:04,937] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:04,947] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:04,949] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,032] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,085] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 258 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,099] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-2\00000000000000000258.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,115] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 258 in 244 ms (kafka.log.Log)
[2019-08-09 10:06:05,153] WARN [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261706577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:05,156] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,224] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,230] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:05,232] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,304] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,332] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 136 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,337] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-3\00000000000000000136.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,344] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 136 in 210 ms (kafka.log.Log)
[2019-08-09 10:06:05,362] WARN [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-4\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-4\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:05,363] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,419] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,423] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:05,424] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,501] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,534] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 502 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,542] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-4\00000000000000000502.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,548] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 502 in 200 ms (kafka.log.Log)
[2019-08-09 10:06:05,565] WARN [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:05,567] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,622] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,626] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:05,626] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,715] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,744] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 216 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,750] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-5\00000000000000000216.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,756] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 216 in 202 ms (kafka.log.Log)
[2019-08-09 10:06:05,778] WARN [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-6\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-6\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:05,778] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,832] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,835] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:05,835] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,890] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,925] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 97 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:05,930] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-6\00000000000000000097.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:05,937] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 97 in 175 ms (kafka.log.Log)
[2019-08-09 10:06:05,951] WARN [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565249675776}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:05,954] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,009] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,014] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,015] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,074] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,101] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 133 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,106] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-7\00000000000000000133.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,112] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 133 in 170 ms (kafka.log.Log)
[2019-08-09 10:06:06,161] WARN [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565261979958}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:06,162] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,216] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,222] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,223] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,282] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,308] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 66 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,314] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-8\00000000000000000066.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,319] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 66 in 200 ms (kafka.log.Log)
[2019-08-09 10:06:06,337] WARN [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-1\topic-4-9\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-1\topic-4-9\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565257932334}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:06,338] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,387] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,390] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,391] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,446] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,468] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 83 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,473] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\topic-4-9\00000000000000000083.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:06,478] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 83 in 151 ms (kafka.log.Log)
[2019-08-09 10:06:06,493] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,494] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,539] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,546] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-08-09 10:06:06,562] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,562] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,619] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,625] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-08-09 10:06:06,637] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,639] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,687] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,693] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-09 10:06:06,710] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,711] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,775] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,781] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 85 ms (kafka.log.Log)
[2019-08-09 10:06:06,795] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,796] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,848] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,856] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-08-09 10:06:06,871] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,872] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,921] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:06,928] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-08-09 10:06:06,940] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:06,940] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,000] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,011] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-08-09 10:06:07,025] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:07,027] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,083] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,090] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-08-09 10:06:07,102] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:07,102] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,161] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,167] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-08-09 10:06:07,184] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:07,186] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,242] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:07,250] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-08-09 10:06:07,255] INFO Logs loading complete in 3576 ms. (kafka.log.LogManager)
[2019-08-09 10:06:07,270] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-09 10:06:07,272] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-09 10:06:07,614] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-08-09 10:06:07,671] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-09 10:06:07,706] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,706] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,712] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,724] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-09 10:06:07,811] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:07,837] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:07,840] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:07,909] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,909] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,909] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:07,930] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:06:07,931] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:06:07,934] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:06:07,950] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:16000,blockEndProducerId:16999) by writing to Zk with path version 17 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-09 10:06:07,988] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:06:07,991] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-09 10:06:07,991] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:06:08,042] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-09 10:06:08,072] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-09 10:06:08,075] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:06:08,076] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:06:08,078] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-08-09 10:06:08,178] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,184] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,204] INFO Replica loaded for partition topic-4-9 with initial high watermark 83 (kafka.cluster.Replica)
[2019-08-09 10:06:08,205] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,214] INFO Replica loaded for partition topic-4-6 with initial high watermark 97 (kafka.cluster.Replica)
[2019-08-09 10:06:08,214] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,216] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,216] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,219] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,224] INFO Replica loaded for partition topic-5-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,225] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,226] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,227] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,235] INFO Replica loaded for partition topic-4-3 with initial high watermark 136 (kafka.cluster.Replica)
[2019-08-09 10:06:08,236] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,237] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,244] INFO Replica loaded for partition topic-4-0 with initial high watermark 134 (kafka.cluster.Replica)
[2019-08-09 10:06:08,245] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,258] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,263] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,264] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,268] INFO Replica loaded for partition topic-4-10 with initial high watermark 88 (kafka.cluster.Replica)
[2019-08-09 10:06:08,269] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,269] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,270] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,275] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,275] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,278] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,278] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,280] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,285] INFO Replica loaded for partition topic-4-7 with initial high watermark 133 (kafka.cluster.Replica)
[2019-08-09 10:06:08,286] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,287] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,287] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,290] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,293] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,301] INFO Replica loaded for partition topic-4-4 with initial high watermark 502 (kafka.cluster.Replica)
[2019-08-09 10:06:08,301] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,302] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,307] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,310] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,316] INFO Replica loaded for partition topic-4-1 with initial high watermark 132 (kafka.cluster.Replica)
[2019-08-09 10:06:08,317] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,320] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,324] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,325] INFO Replica loaded for partition topic-5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,331] INFO Replica loaded for partition topic-3-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-08-09 10:06:08,332] INFO Replica loaded for partition topic-3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,333] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,334] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,334] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,337] INFO Replica loaded for partition topic-4-8 with initial high watermark 66 (kafka.cluster.Replica)
[2019-08-09 10:06:08,350] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,352] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,355] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,356] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,360] INFO Replica loaded for partition topic-4-5 with initial high watermark 216 (kafka.cluster.Replica)
[2019-08-09 10:06:08,361] INFO Replica loaded for partition topic-3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,367] INFO Replica loaded for partition topic-3-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-08-09 10:06:08,371] INFO Replica loaded for partition topic-4-2 with initial high watermark 258 (kafka.cluster.Replica)
[2019-08-09 10:06:08,372] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,372] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,373] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,374] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,378] INFO Replica loaded for partition topic-4-11 with initial high watermark 64 (kafka.cluster.Replica)
[2019-08-09 10:06:08,379] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,380] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,380] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,381] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,385] INFO Replica loaded for partition topic-7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,389] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,390] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,393] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,395] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:08,399] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-1, topic-6-0, topic-5-4, topic-4-5, topic-4-9, topic-4-2, topic-6-1, topic-5-2, topic-4-6, topic-7-1, topic-6-2, topic-4-10, topic-3-0, topic-4-3, topic-4-11, topic-4-7, topic-4-4, topic-7-2, topic-4-0, topic-4-8, topic-3-1) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:08,492] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-4-9 -> (offset=83, leaderEpoch=11), topic-4-11 -> (offset=64, leaderEpoch=11), topic-4-6 -> (offset=97, leaderEpoch=11), topic-4-2 -> (offset=258, leaderEpoch=11), topic-4-10 -> (offset=88, leaderEpoch=11), topic-4-1 -> (offset=132, leaderEpoch=11), topic-4-8 -> (offset=66, leaderEpoch=12), topic-4-3 -> (offset=136, leaderEpoch=12), topic-4-7 -> (offset=133, leaderEpoch=12), topic-4-4 -> (offset=502, leaderEpoch=13), topic-4-0 -> (offset=134, leaderEpoch=14), topic-4-5 -> (offset=216, leaderEpoch=12), topic-7-2 -> (offset=0, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:08,498] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,499] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-3-1 -> (offset=7, leaderEpoch=9), topic-6-0 -> (offset=0, leaderEpoch=5), topic-7-1 -> (offset=0, leaderEpoch=6), topic-3-0 -> (offset=6, leaderEpoch=12), topic-5-2 -> (offset=0, leaderEpoch=4), topic-6-2 -> (offset=0, leaderEpoch=6), topic-5-4 -> (offset=0, leaderEpoch=4), topic-6-1 -> (offset=0, leaderEpoch=5)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:08,508] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,549] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-1] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:06:08,549] INFO [Log partition=topic-3-1, dir=C:\tmp\kafka-logs-1] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-08-09 10:06:08,551] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-1] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:06:08,551] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs-1] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-09 10:06:08,554] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-1] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:06:08,555] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:06:08,556] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-1] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:06:08,557] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-1] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:06:08,558] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-1] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:06:08,559] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:06:08,560] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,560] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-1] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:06:08,561] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,566] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,566] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-1] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:06:08,567] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,569] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-1] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:06:08,569] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,570] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:06:08,570] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,572] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-5-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,571] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition topic-7-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,572] INFO [Log partition=topic-5-4, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,573] INFO [Log partition=topic-7-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,574] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,575] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,576] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition topic-5-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:08,578] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:08,584] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,603] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,609] INFO [Partition topic-3-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,616] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,627] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,642] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,660] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,668] INFO [Partition topic-3-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,672] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,678] INFO [Partition topic-6-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,686] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,695] INFO [Partition topic-6-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,714] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,718] INFO [Partition topic-6-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,721] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,739] INFO [Partition topic-7-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,758] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,764] INFO [Partition topic-5-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,769] INFO [Partition topic-5-4 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,767] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:08,798] INFO [Partition topic-7-2 broker=2] Expanding ISR from 2,0 to 2,0,1 (kafka.cluster.Partition)
[2019-08-09 10:06:11,618] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-09 10:06:12,163] INFO starting (kafka.server.KafkaServer)
[2019-08-09 10:06:12,165] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-09 10:06:12,193] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:12,209] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,210] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,211] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,211] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,212] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,216] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,219] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,220] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,220] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,221] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,221] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,222] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,223] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,223] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,226] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,228] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:06:12,260] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:12,261] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:12,265] INFO Accepted socket connection from /127.0.0.1:52848 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:06:12,266] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:12,274] INFO Client attempting to establish new session at /127.0.0.1:52848 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:12,276] INFO Established session 0x10005432d98002f with negotiated timeout 6000 for client /127.0.0.1:52848 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:12,278] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d98002f, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:06:12,283] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:06:12,357] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x1 zxid:0x5b7 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,372] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x2 zxid:0x5b8 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,375] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x3 zxid:0x5b9 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,378] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x4 zxid:0x5ba txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,382] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x5 zxid:0x5bb txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,385] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x6 zxid:0x5bc txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,390] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x7 zxid:0x5bd txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,393] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x8 zxid:0x5be txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,396] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0x9 zxid:0x5bf txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,399] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0xa zxid:0x5c0 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,403] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0xb zxid:0x5c1 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,407] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0xc zxid:0x5c2 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,409] INFO Got user-level KeeperException when processing sessionid:0x10005432d98002f type:create cxid:0xd zxid:0x5c3 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:06:12,669] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-09 10:06:12,748] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:06:12,761] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:06:12,806] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:12,807] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:12,812] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:06:12,871] INFO Loading logs. (kafka.log.LogManager)
[2019-08-09 10:06:13,010] WARN [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565266550010}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:13,011] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,112] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,135] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:13,137] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,217] INFO [ProducerStateManager partition=topic-4-0] Writing producer snapshot at offset 134 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,271] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 134 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,277] INFO [ProducerStateManager partition=topic-4-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-0\00000000000000000134.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,292] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 134 in 369 ms (kafka.log.Log)
[2019-08-09 10:06:13,347] WARN [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565266410071}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:13,347] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,413] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,424] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:13,424] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,491] INFO [ProducerStateManager partition=topic-4-1] Writing producer snapshot at offset 132 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,530] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 132 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,535] INFO [ProducerStateManager partition=topic-4-1] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-1\00000000000000000132.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,540] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 132 in 239 ms (kafka.log.Log)
[2019-08-09 10:06:13,556] WARN [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:13,557] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,609] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,613] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:13,613] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,671] INFO [ProducerStateManager partition=topic-4-10] Writing producer snapshot at offset 88 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,713] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 88 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,718] INFO [ProducerStateManager partition=topic-4-10] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-10\00000000000000000088.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,724] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 88 in 179 ms (kafka.log.Log)
[2019-08-09 10:06:13,740] WARN [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:13,740] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,791] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,796] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:13,798] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,864] INFO [ProducerStateManager partition=topic-4-11] Writing producer snapshot at offset 64 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,904] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 64 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:13,910] INFO [ProducerStateManager partition=topic-4-11] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-11\00000000000000000064.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:13,914] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 64 in 185 ms (kafka.log.Log)
[2019-08-09 10:06:13,961] WARN [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270548438}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:13,964] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,024] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,028] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:14,028] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,085] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52853 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:06:14,089] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52853 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:14,094] INFO Established session 0x10005432d980030 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:52853 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:14,108] INFO [ProducerStateManager partition=topic-4-2] Writing producer snapshot at offset 258 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,153] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 258 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,161] INFO [ProducerStateManager partition=topic-4-2] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-2\00000000000000000258.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,167] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 258 in 248 ms (kafka.log.Log)
[2019-08-09 10:06:14,210] WARN [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-3\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-3\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268749953}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:14,210] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,263] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,266] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:14,266] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,321] INFO [ProducerStateManager partition=topic-4-3] Writing producer snapshot at offset 136 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,356] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 136 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,362] INFO [ProducerStateManager partition=topic-4-3] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-3\00000000000000000136.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,367] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 136 in 194 ms (kafka.log.Log)
[2019-08-09 10:06:14,406] WARN [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-4\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-4\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268812855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:14,407] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,464] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,468] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:14,469] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,546] INFO [ProducerStateManager partition=topic-4-4] Writing producer snapshot at offset 502 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,582] WARN Exception causing close of session 0x10005432d980030: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:06:14,583] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52853 which had sessionid 0x10005432d980030 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:06:14,585] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 502 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,590] INFO [ProducerStateManager partition=topic-4-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-4\00000000000000000502.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,598] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 502 in 228 ms (kafka.log.Log)
[2019-08-09 10:06:14,639] WARN [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-5\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-5\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565262294563}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:14,640] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,691] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,695] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:14,695] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,759] INFO [ProducerStateManager partition=topic-4-5] Writing producer snapshot at offset 216 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,796] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 216 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,802] INFO [ProducerStateManager partition=topic-4-5] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-5\00000000000000000216.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,807] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 216 in 204 ms (kafka.log.Log)
[2019-08-09 10:06:14,824] WARN [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-6\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-6\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:14,824] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,869] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,874] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:14,874] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,930] INFO [ProducerStateManager partition=topic-4-6] Writing producer snapshot at offset 97 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,970] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 97 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:14,975] INFO [ProducerStateManager partition=topic-4-6] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-6\00000000000000000097.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:14,980] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 97 in 166 ms (kafka.log.Log)
[2019-08-09 10:06:15,029] WARN [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565268035616}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:15,032] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,081] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,085] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,086] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,153] INFO [ProducerStateManager partition=topic-4-7] Writing producer snapshot at offset 133 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,193] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 133 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,199] INFO [ProducerStateManager partition=topic-4-7] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-7\00000000000000000133.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,205] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 133 in 219 ms (kafka.log.Log)
[2019-08-09 10:06:15,221] WARN [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:15,222] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,274] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,279] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,280] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,339] INFO [ProducerStateManager partition=topic-4-8] Writing producer snapshot at offset 66 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,381] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 66 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,387] INFO [ProducerStateManager partition=topic-4-8] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-8\00000000000000000066.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,392] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 66 in 183 ms (kafka.log.Log)
[2019-08-09 10:06:15,407] WARN [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs-3\topic-4-9\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs-3\topic-4-9\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1565270386566}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-08-09 10:06:15,408] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,457] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,461] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,462] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,515] INFO [ProducerStateManager partition=topic-4-9] Writing producer snapshot at offset 83 (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,553] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 83 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,559] INFO [ProducerStateManager partition=topic-4-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs-3\topic-4-9\00000000000000000083.snapshot' (kafka.log.ProducerStateManager)
[2019-08-09 10:06:15,564] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 83 in 166 ms (kafka.log.Log)
[2019-08-09 10:06:15,583] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,583] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,638] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,644] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-08-09 10:06:15,655] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,655] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,702] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,707] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-08-09 10:06:15,719] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,719] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,773] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,779] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-08-09 10:06:15,791] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,791] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,844] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,849] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-08-09 10:06:15,864] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,864] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,921] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,927] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-08-09 10:06:15,944] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:15,945] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,990] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:15,995] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-09 10:06:16,007] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:16,007] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,059] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,066] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-08-09 10:06:16,077] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:16,077] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,123] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,128] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-08-09 10:06:16,141] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:16,142] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,188] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,195] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-08-09 10:06:16,211] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:16,211] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,258] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,264] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-08-09 10:06:16,275] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-08-09 10:06:16,276] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,320] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-08-09 10:06:16,325] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-08-09 10:06:16,330] INFO Logs loading complete in 3456 ms. (kafka.log.LogManager)
[2019-08-09 10:06:16,343] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-08-09 10:06:16,345] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-08-09 10:06:16,690] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2019-08-09 10:06:16,750] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-08-09 10:06:16,782] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:16,784] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:16,784] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:16,804] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-08-09 10:06:16,896] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:16,901] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:16,906] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(W101GKNGH2.mshome.net,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-08-09 10:06:16,953] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:16,961] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:16,966] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:16,970] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-5-0, topic-5-6, topic-5-5) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:16,982] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-5-5 -> (offset=0, leaderEpoch=5), topic-5-0 -> (offset=0, leaderEpoch=4), topic-5-6 -> (offset=0, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:16,983] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:16,984] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:16,987] INFO [Log partition=topic-5-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:16,987] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:16,988] INFO [Log partition=topic-5-6, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:16,988] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-5-5 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:16,989] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,008] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:17,019] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:17,019] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-08-09 10:06:17,054] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:06:17,059] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-08-09 10:06:17,065] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:06:17,085] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:17000,blockEndProducerId:17999) by writing to Zk with path version 18 (kafka.coordinator.transaction.ProducerIdManager)
[2019-08-09 10:06:17,124] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:06:17,128] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-08-09 10:06:17,132] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-08-09 10:06:17,181] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-08-09 10:06:17,211] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-08-09 10:06:17,216] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:06:17,216] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-08-09 10:06:17,219] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-08-09 10:06:17,288] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-5-5 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-09 10:06:17,293] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-5-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-09 10:06:17,295] ERROR [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error for partition topic-5-6 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-08-09 10:06:17,338] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,347] INFO Replica loaded for partition topic-4-9 with initial high watermark 83 (kafka.cluster.Replica)
[2019-08-09 10:06:17,350] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,351] INFO Replica loaded for partition topic-4-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,356] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,362] INFO Replica loaded for partition topic-4-6 with initial high watermark 97 (kafka.cluster.Replica)
[2019-08-09 10:06:17,363] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,366] INFO Replica loaded for partition topic-4-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,367] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,374] INFO Replica loaded for partition topic-5-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,374] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,378] INFO Replica loaded for partition topic-4-3 with initial high watermark 136 (kafka.cluster.Replica)
[2019-08-09 10:06:17,379] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,384] INFO Replica loaded for partition topic-4-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,384] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,389] INFO Replica loaded for partition topic-5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,395] INFO Replica loaded for partition topic-4-0 with initial high watermark 134 (kafka.cluster.Replica)
[2019-08-09 10:06:17,398] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,398] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,400] INFO Replica loaded for partition topic-4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,402] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,408] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,409] INFO Replica loaded for partition topic-6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,411] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,411] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,429] INFO Replica loaded for partition topic-7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,437] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,441] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,443] INFO Replica loaded for partition topic-4-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,463] INFO Replica loaded for partition topic-4-10 with initial high watermark 88 (kafka.cluster.Replica)
[2019-08-09 10:06:17,469] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,479] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,480] INFO Replica loaded for partition topic-7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,484] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,485] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,489] INFO Replica loaded for partition topic-4-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,492] INFO Replica loaded for partition topic-4-7 with initial high watermark 133 (kafka.cluster.Replica)
[2019-08-09 10:06:17,499] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,500] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,501] INFO Replica loaded for partition topic-6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,506] INFO Replica loaded for partition topic-4-4 with initial high watermark 502 (kafka.cluster.Replica)
[2019-08-09 10:06:17,509] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,510] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,510] INFO Replica loaded for partition topic-4-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,517] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,519] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,520] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,521] INFO Replica loaded for partition topic-4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,526] INFO Replica loaded for partition topic-4-1 with initial high watermark 132 (kafka.cluster.Replica)
[2019-08-09 10:06:17,530] INFO Replica loaded for partition topic-4-8 with initial high watermark 66 (kafka.cluster.Replica)
[2019-08-09 10:06:17,532] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,533] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,534] INFO Replica loaded for partition topic-4-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,539] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,542] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,545] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,548] INFO Replica loaded for partition topic-4-5 with initial high watermark 216 (kafka.cluster.Replica)
[2019-08-09 10:06:17,549] INFO Replica loaded for partition topic-4-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,550] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,551] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,555] INFO Replica loaded for partition topic-4-2 with initial high watermark 258 (kafka.cluster.Replica)
[2019-08-09 10:06:17,557] INFO Replica loaded for partition topic-4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,561] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,561] INFO Replica loaded for partition topic-5-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,562] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,562] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,566] INFO Replica loaded for partition topic-4-11 with initial high watermark 64 (kafka.cluster.Replica)
[2019-08-09 10:06:17,569] INFO Replica loaded for partition topic-4-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,575] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,575] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,576] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,580] INFO Replica loaded for partition topic-6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,584] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-4-1, topic-6-0, topic-5-1, topic-4-5, topic-7-0, topic-4-9, topic-4-2, topic-6-1, topic-4-6, topic-7-1, topic-6-2, topic-4-10, topic-4-3, topic-4-11, topic-5-3, topic-4-7, topic-4-4, topic-5-7, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:17,653] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,658] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=W101GKNGH2.blr.amer.dell.com:9094) for partitions Map(topic-7-0 -> (offset=0, leaderEpoch=3), topic-4-9 -> (offset=83, leaderEpoch=11), topic-4-11 -> (offset=64, leaderEpoch=11), topic-4-6 -> (offset=97, leaderEpoch=11), topic-4-2 -> (offset=258, leaderEpoch=11), topic-4-10 -> (offset=88, leaderEpoch=11), topic-4-1 -> (offset=132, leaderEpoch=11), topic-4-8 -> (offset=66, leaderEpoch=12), topic-4-3 -> (offset=136, leaderEpoch=12), topic-4-7 -> (offset=133, leaderEpoch=12), topic-4-4 -> (offset=502, leaderEpoch=13), topic-4-0 -> (offset=134, leaderEpoch=14), topic-4-5 -> (offset=216, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:17,665] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=0, host=W101GKNGH2.mshome.net:9092) for partitions Map(topic-5-7 -> (offset=0, leaderEpoch=4), topic-6-0 -> (offset=0, leaderEpoch=5), topic-7-1 -> (offset=0, leaderEpoch=6), topic-5-3 -> (offset=0, leaderEpoch=4), topic-6-2 -> (offset=0, leaderEpoch=6), topic-5-1 -> (offset=0, leaderEpoch=4), topic-6-1 -> (offset=0, leaderEpoch=5)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:17,671] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,680] INFO [Log partition=topic-4-11, dir=C:\tmp\kafka-logs-3] Truncating to 64 has no effect as the largest offset in the log is 63 (kafka.log.Log)
[2019-08-09 10:06:17,680] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:06:17,680] INFO [Log partition=topic-4-9, dir=C:\tmp\kafka-logs-3] Truncating to 83 has no effect as the largest offset in the log is 82 (kafka.log.Log)
[2019-08-09 10:06:17,681] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-3] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:06:17,681] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,682] INFO [Log partition=topic-4-7, dir=C:\tmp\kafka-logs-3] Truncating to 133 has no effect as the largest offset in the log is 132 (kafka.log.Log)
[2019-08-09 10:06:17,683] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,684] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:06:17,685] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,686] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,685] INFO [Log partition=topic-4-5, dir=C:\tmp\kafka-logs-3] Truncating to 216 has no effect as the largest offset in the log is 215 (kafka.log.Log)
[2019-08-09 10:06:17,687] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,688] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-3] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:06:17,692] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,692] INFO [Log partition=topic-4-3, dir=C:\tmp\kafka-logs-3] Truncating to 136 has no effect as the largest offset in the log is 135 (kafka.log.Log)
[2019-08-09 10:06:17,694] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,694] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:06:17,695] INFO [Log partition=topic-5-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,696] INFO [Log partition=topic-4-1, dir=C:\tmp\kafka-logs-3] Truncating to 132 has no effect as the largest offset in the log is 131 (kafka.log.Log)
[2019-08-09 10:06:17,697] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,697] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-3] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:06:17,698] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,700] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-5-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,703] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition topic-7-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,705] INFO [Log partition=topic-7-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,705] INFO [Log partition=topic-5-7, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,707] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition topic-6-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:06:17,708] INFO [Log partition=topic-6-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:06:17,710] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-5-5, topic-5-6, topic-5-0) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:06:17,714] INFO [Partition topic-7-0 broker=2] Expanding ISR from 2,0 to 2,0,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,719] INFO Replica loaded for partition topic-5-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,717] INFO [Partition topic-5-7 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,721] INFO [Partition topic-5-5 broker=3] topic-5-5 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:06:17,727] INFO [Partition topic-5-3 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,725] INFO [Partition topic-4-9 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,735] INFO [Partition topic-4-11 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,735] INFO [Partition topic-5-1 broker=0] Expanding ISR from 0 to 0,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,740] INFO [Partition topic-4-6 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,744] INFO [Partition topic-6-0 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,745] INFO [Partition topic-4-2 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,752] INFO [Partition topic-4-10 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,750] INFO [Partition topic-6-2 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,764] INFO [Partition topic-4-1 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,767] INFO [Partition topic-6-1 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,769] INFO Replica loaded for partition topic-5-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,771] INFO [Partition topic-5-6 broker=3] topic-5-6 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:06:17,770] INFO [Partition topic-4-8 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,773] INFO [Partition topic-7-1 broker=0] Expanding ISR from 0,1 to 0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,778] INFO [Partition topic-4-3 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,782] INFO [Partition topic-4-7 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,797] INFO Replica loaded for partition topic-5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-08-09 10:06:17,799] INFO [Partition topic-4-4 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,799] INFO [Partition topic-5-0 broker=3] topic-5-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-08-09 10:06:17,803] INFO [Partition topic-4-0 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:17,818] INFO [Partition topic-4-5 broker=2] Expanding ISR from 2,0,1 to 2,0,1,3 (kafka.cluster.Partition)
[2019-08-09 10:06:18,329] INFO [Partition topic-5-0 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:06:18,348] INFO [Partition topic-5-6 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:06:18,351] INFO [Partition topic-5-5 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-08-09 10:06:46,207] INFO Expiring session 0x10005432d980030, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:06:46,207] INFO Processed session termination for sessionid: 0x10005432d980030 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:07,597] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-08-09 10:07:08,012] INFO starting (kafka.server.KafkaServer)
[2019-08-09 10:07:08,013] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-08-09 10:07:08,039] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:07:08,052] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,055] INFO Client environment:host.name=W101GKNGH2.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,083] INFO Client environment:java.version=1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,116] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,150] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_211 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,155] INFO Client environment:java.class.path=C:\kafka_2.11-2.1.1\libs\activation-1.1.1.jar;C:\kafka_2.11-2.1.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.11-2.1.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.11-2.1.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.11-2.1.1\libs\connect-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-basic-auth-extension-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-file-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-json-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-runtime-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\connect-transforms-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\guava-20.0.jar;C:\kafka_2.11-2.1.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.11-2.1.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.11-2.1.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-1.jar;C:\kafka_2.11-2.1.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.11-2.1.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.11-2.1.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.11-2.1.1\libs\jersey-client-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-common-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.11-2.1.1\libs\jersey-server-2.27.jar;C:\kafka_2.11-2.1.1\libs\jetty-client-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-continuation-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-http-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-io-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-security-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-server-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlet-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-servlets-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jetty-util-9.4.12.v20180830.jar;C:\kafka_2.11-2.1.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.11-2.1.1\libs\kafka-clients-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-log4j-appender-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-examples-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-scala_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-streams-test-utils-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka-tools-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-javadoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-scaladoc.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test-sources.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1-test.jar.asc;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar;C:\kafka_2.11-2.1.1\libs\kafka_2.11-2.1.1.jar.asc;C:\kafka_2.11-2.1.1\libs\log4j-1.2.17.jar;C:\kafka_2.11-2.1.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.11-2.1.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.11-2.1.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.11-2.1.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.11-2.1.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.11-2.1.1\libs\reflections-0.9.11.jar;C:\kafka_2.11-2.1.1\libs\rocksdbjni-5.14.2.jar;C:\kafka_2.11-2.1.1\libs\scala-library-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\scala-logging_2.11-3.9.0.jar;C:\kafka_2.11-2.1.1\libs\scala-reflect-2.11.12.jar;C:\kafka_2.11-2.1.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.11-2.1.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.11-2.1.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.11-2.1.1\libs\zkclient-0.11.jar;C:\kafka_2.11-2.1.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.11-2.1.1\libs\zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,184] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\Program Files\RSA SecurID Token Common;C:\ProgramData\Oracle\Java\javapath;C:\Program Files\Microsoft MPI\Bin\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\ManagementStudio\;C:\Program Files\Java\jre1.8.0_161\bin;c:\Program Files (x86)\Microsoft ASP.NET\ASP.NET Web Pages\v1.0\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\110\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;C:\Program Files\Microsoft SQL Server\120\DTS\Binn\;C:\Program Files\Dell\Dell Data Protection\Encryption\;C:\sachin\autoscripts\;C:\Program Files\1E\NomadBranch\;C:\Users\sachin_kumar\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit);C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3\Scripts;C:\Users\sachin_kumar\AppData\Local\Continuum\anaconda3;C:\Users\sachin_kumar\opencv\build;C:\Users\sachin_kumar\opencv\build\python\2.7\x64;C:\Program Files\CMake\bin;C:\Program Files\nodejs\;C:\Program Files\Cloud Foundry;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\Scripts\;C:\Users\sachin_kumar\AppData\Local\Programs\Python\Python36-32\;C:\Program Files\RSA SecurID Token Common\;C:\Users\sachin_kumar\AppData\Local\Programs\Fiddler;C:\Users\sachin_kumar\AppData\Local\GitHubDesktop\bin;C:\Users\sachin_kumar\AppData\Roaming\npm;C:\Users\sachin_kumar\AppData\Local\Microsoft\WindowsApps;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Users\sachin_kumar\.dotnet\tools;C:\Program Files\SafeNet ProtectApp\FIPS;C:\Program Files\Java\jdk1.8.0_211\bin;;C:\Program Files\Microsoft Office\root\Client;. (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,214] INFO Client environment:java.io.tmpdir=C:\Users\SACHIN~1\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,248] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,255] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,285] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,290] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,319] INFO Client environment:user.name=Sachin_Kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,324] INFO Client environment:user.home=C:\Users\sachin_kumar (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,353] INFO Client environment:user.dir=C:\kafka_2.11-2.1.1 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,388] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@158d2680 (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:08,457] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:07:08,458] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:07:08,493] INFO Accepted socket connection from /127.0.0.1:49169 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:07:08,496] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:07:08,531] INFO Client attempting to establish new session at /127.0.0.1:49169 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:07:08,534] INFO Established session 0x10005432d980031 with negotiated timeout 6000 for client /127.0.0.1:49169 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:07:08,537] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10005432d980031, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:07:08,548] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:07:08,630] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x1 zxid:0x5ed txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,643] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x2 zxid:0x5ee txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,645] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x3 zxid:0x5ef txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,647] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x4 zxid:0x5f0 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,649] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x5 zxid:0x5f1 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,651] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x6 zxid:0x5f2 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,654] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x7 zxid:0x5f3 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,656] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x8 zxid:0x5f4 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,658] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0x9 zxid:0x5f5 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,660] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0xa zxid:0x5f6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,663] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0xb zxid:0x5f7 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,665] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0xc zxid:0x5f8 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,667] INFO Got user-level KeeperException when processing sessionid:0x10005432d980031 type:create cxid:0xd zxid:0x5f9 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:08,851] INFO Cluster ID = TX_mgv62TvepmJ9fSBD_Ig (kafka.server.KafkaServer)
[2019-08-09 10:07:08,911] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:07:08,927] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-08-09 10:07:08,976] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,008] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,008] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,031] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in C:\tmp\kafka-logs-2. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:240)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:236)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:97)
	at kafka.log.LogManager$.apply(LogManager.scala:990)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:237)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
[2019-08-09 10:07:09,037] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-08-09 10:07:09,076] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:07:09,078] INFO Processed session termination for sessionid: 0x10005432d980031 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:07:09,089] INFO Closed socket connection for client /127.0.0.1:49169 which had sessionid 0x10005432d980031 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:07:09,089] INFO Session: 0x10005432d980031 closed (org.apache.zookeeper.ZooKeeper)
[2019-08-09 10:07:09,091] INFO EventThread shut down for session: 0x10005432d980031 (org.apache.zookeeper.ClientCnxn)
[2019-08-09 10:07:09,093] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-08-09 10:07:09,158] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,980] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,980] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:09,980] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:11,015] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:11,015] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:11,041] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:12,020] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:12,020] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-08-09 10:07:12,055] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-08-09 10:07:12,082] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-08-09 10:07:12,119] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-08-09 10:08:39,965] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61881 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-08-09 10:08:39,969] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61881 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:08:39,979] INFO Established session 0x10005432d980032 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:61881 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:08:40,494] WARN Exception causing close of session 0x10005432d980032: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:08:40,495] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61881 which had sessionid 0x10005432d980032 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-08-09 10:09:10,565] INFO Expiring session 0x10005432d980032, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-08-09 10:09:10,565] INFO Processed session termination for sessionid: 0x10005432d980032 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-08-09 10:09:44,024] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-10, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,034] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-7-1, topic-6-2, topic-4-10, topic-5-5, topic-4-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,033] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-7-1, topic-6-2, topic-4-10, topic-3-0, topic-4-2, topic-5-2, topic-4-6) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,035] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-2 -> (offset=258, leaderEpoch=12), topic-4-6 -> (offset=97, leaderEpoch=12), topic-4-10 -> (offset=88, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,037] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-4-6, topic-4-2, topic-7-1, topic-4-10, topic-3-0, topic-5-2, topic-6-2, topic-5-5) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,047] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=97, leaderEpoch=12), topic-4-2 -> (offset=258, leaderEpoch=12), topic-7-1 -> (offset=0, leaderEpoch=7), topic-4-10 -> (offset=88, leaderEpoch=12), topic-6-2 -> (offset=0, leaderEpoch=7), topic-5-5 -> (offset=0, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,043] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,048] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,058] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(topic-6-0, topic-5-3, topic-4-8, topic-4-4, topic-4-0) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,060] INFO [Partition topic-4-0 broker=3] topic-4-0 starts at Leader Epoch 15 from offset 134. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-08-09 10:09:44,054] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,051] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=W101GKNGH2.mshome.net:9093) for partitions Map(topic-4-6 -> (offset=97, leaderEpoch=12), topic-4-2 -> (offset=258, leaderEpoch=12), topic-7-1 -> (offset=0, leaderEpoch=7), topic-4-10 -> (offset=88, leaderEpoch=12), topic-3-0 -> (offset=6, leaderEpoch=13), topic-5-2 -> (offset=0, leaderEpoch=5), topic-6-2 -> (offset=0, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,065] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=15), topic-4-4 -> (offset=502, leaderEpoch=14), topic-4-8 -> (offset=66, leaderEpoch=13)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,070] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,063] INFO [Partition topic-4-6 broker=1] topic-4-6 starts at Leader Epoch 12 from offset 97. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:09:44,074] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(topic-6-0, topic-5-3, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,065] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,086] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-6-0 -> (offset=0, leaderEpoch=6), topic-5-3 -> (offset=0, leaderEpoch=5), topic-4-8 -> (offset=66, leaderEpoch=13), topic-4-4 -> (offset=502, leaderEpoch=14), topic-4-0 -> (offset=134, leaderEpoch=15)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,086] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,098] INFO [Partition topic-6-0 broker=3] topic-6-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:09:44,103] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,104] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,104] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-4 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,107] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-8 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,110] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-2] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:09:44,111] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-4-4 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,114] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition topic-5-3 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,115] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:09:44,121] INFO [Partition topic-6-2 broker=1] topic-6-2 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-09 10:09:44,124] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,128] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,128] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:09:44,128] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,128] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-3-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,128] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-5-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,129] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-6-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,125] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,119] INFO [Partition topic-4-4 broker=3] topic-4-4 starts at Leader Epoch 14 from offset 502. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-08-09 10:09:44,129] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-2] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:09:44,131] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,126] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-10 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,148] INFO [Partition topic-4-10 broker=1] topic-4-10 starts at Leader Epoch 12 from offset 88. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:09:44,149] INFO [Partition topic-4-8 broker=3] topic-4-8 starts at Leader Epoch 13 from offset 66. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-08-09 10:09:44,151] INFO [Log partition=topic-4-6, dir=C:\tmp\kafka-logs-3] Truncating to 97 has no effect as the largest offset in the log is 96 (kafka.log.Log)
[2019-08-09 10:09:44,159] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-5-5 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,159] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition topic-4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,161] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-7-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,161] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:44,163] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition topic-6-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,164] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:44,185] INFO [Partition topic-7-1 broker=1] topic-7-1 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-08-09 10:09:44,188] INFO [Partition topic-5-3 broker=3] topic-5-3 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-09 10:09:44,201] INFO [Partition topic-5-5 broker=1] topic-5-5 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-08-09 10:09:44,224] INFO [Partition topic-5-2 broker=1] topic-5-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-08-09 10:09:44,239] INFO [Partition topic-3-0 broker=1] topic-3-0 starts at Leader Epoch 13 from offset 6. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-08-09 10:09:44,253] INFO [Partition topic-4-2 broker=1] topic-4-2 starts at Leader Epoch 12 from offset 258. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-08-09 10:09:44,276] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(topic-6-0, topic-4-4, topic-4-0, topic-4-8) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,277] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=W101GKNGH2.mshome.net:9095) for partitions Map(topic-4-0 -> (offset=134, leaderEpoch=15), topic-4-4 -> (offset=502, leaderEpoch=14), topic-6-0 -> (offset=0, leaderEpoch=6), topic-4-8 -> (offset=66, leaderEpoch=13)) (kafka.server.ReplicaFetcherManager)
[2019-08-09 10:09:44,543] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-1] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:09:44,544] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-1] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:09:44,545] INFO [Log partition=topic-4-0, dir=C:\tmp\kafka-logs-1] Truncating to 134 has no effect as the largest offset in the log is 133 (kafka.log.Log)
[2019-08-09 10:09:44,546] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition topic-6-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2019-08-09 10:09:44,547] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,122] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs-2] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:09:45,122] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs-2] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:09:45,130] INFO [Log partition=topic-6-0, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,130] INFO [Log partition=topic-4-8, dir=C:\tmp\kafka-logs] Truncating to 66 has no effect as the largest offset in the log is 65 (kafka.log.Log)
[2019-08-09 10:09:45,131] INFO [Log partition=topic-4-4, dir=C:\tmp\kafka-logs] Truncating to 502 has no effect as the largest offset in the log is 501 (kafka.log.Log)
[2019-08-09 10:09:45,132] INFO [Log partition=topic-5-3, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,188] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-2] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:09:45,188] INFO [Log partition=topic-7-1, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,189] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:09:45,193] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:09:45,193] INFO [Log partition=topic-3-0, dir=C:\tmp\kafka-logs] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-08-09 10:09:45,193] INFO [Log partition=topic-5-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,193] INFO [Log partition=topic-6-2, dir=C:\tmp\kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,189] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-2] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:09:45,222] INFO [Log partition=topic-4-10, dir=C:\tmp\kafka-logs-3] Truncating to 88 has no effect as the largest offset in the log is 87 (kafka.log.Log)
[2019-08-09 10:09:45,222] INFO [Log partition=topic-5-5, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-08-09 10:09:45,224] INFO [Log partition=topic-4-2, dir=C:\tmp\kafka-logs-3] Truncating to 258 has no effect as the largest offset in the log is 257 (kafka.log.Log)
[2019-08-09 10:10:37,620] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,620] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,625] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,635] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,638] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,648] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,651] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,660] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,663] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,673] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,676] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,686] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,691] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,701] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,706] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,716] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,719] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,730] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,734] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,743] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,746] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,755] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,758] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,768] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,771] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,781] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,784] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,784] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,793] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,796] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,797] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,805] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,809] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,818] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,821] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,830] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,833] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,842] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,852] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,853] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,855] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,864] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,866] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,867] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,876] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,879] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,880] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,888] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,891] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,899] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,903] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,912] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,916] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,917] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,925] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,929] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,930] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,938] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,942] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,942] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,951] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,953] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,954] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,962] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,965] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,976] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:10:37,985] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:12:51,596] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:15:34,804] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:16:08,552] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:16:17,656] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:22:51,595] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:25:34,804] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:26:08,555] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:26:17,659] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:32:51,599] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:35:34,806] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:36:08,557] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:36:17,660] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:42:51,602] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:45:34,808] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:46:08,559] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:46:17,663] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:52:51,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:55:34,809] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:56:08,560] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 10:56:17,663] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:02:51,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:05:34,801] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:06:08,551] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:06:17,655] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:12:51,592] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:15:34,796] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:16:08,547] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:16:17,650] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:22:51,589] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:25:34,796] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:26:08,546] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:26:17,650] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:32:51,590] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:35:34,798] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:36:08,548] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:36:17,653] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:42:51,603] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:45:34,810] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:46:08,560] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:46:17,665] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-08-09 11:52:51,606] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadatQ#Y%g